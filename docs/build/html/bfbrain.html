<!DOCTYPE html>

<html lang="en" data-content_root="./">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>bfbrain package &#8212; bfbrain 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="_static/alabaster.css?v=039e1c02" />
    <script src="_static/documentation_options.js?v=f2a433a1"></script>
    <script src="_static/doctools.js?v=888ff710"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="BFBrain" href="modules.html" />
   
  <link rel="stylesheet" href="_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <section id="bfbrain-package">
<h1>bfbrain package<a class="headerlink" href="#bfbrain-package" title="Link to this heading">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Link to this heading">¶</a></h2>
</section>
<section id="module-bfbrain.AL_Metrics">
<span id="bfbrain-al-metrics-module"></span><h2>bfbrain.AL_Metrics module<a class="headerlink" href="#module-bfbrain.AL_Metrics" title="Link to this heading">¶</a></h2>
<p>This module contains code for various performance metrics
which BFBrain can track over the course of active learning.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.process_score_fn">
<span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">process_score_fn</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#process_score_fn"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.process_score_fn" title="Link to this definition">¶</a></dt>
<dd><p>A utility function which translates a string
specifying one of the predefined acquisition
scoring functions into the corresponding
numerical method.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'random'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable.</em>) – If this function is a callable, it must have the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32)</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – <dl class="simple">
<dt>If specified, this name is returned unaltered. Otherwise,</dt><dd><p>a name will be automatically generated based on score_fn.</p>
</dd>
</dl>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>callable</em> – A valid score_fn to be used in various performance metrics.</p></li>
<li><p><em>str</em> – A string which will be used to generate a name for an
ALMetric object.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ALMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sc_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">ABC</span></code></p>
<p>A generic abstract class for computing and recording
performance metrics for active learning. All performance
metrics in BFBrain inherit from this class.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.status_history" title="Link to this definition">¶</a></dt>
<dd><p>A list which contains a record, for each round of
active learning, for whichever metric the subclass
will measure. The entries of status_history may be,
depending on the subclass, virtually any kind of data
or data structure, as long as the elements are picklable.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.sc_type">
<span class="sig-name descname"><span class="pre">sc_type</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.sc_type" title="Link to this definition">¶</a></dt>
<dd><p>A string which denotes what type of metric the ALMetric object is,
since different metrics are recorded at different
points in the active learning loop. If sc_type is ‘val’,
this metric is computed using a validation data set
immediately after each active learning round completes.
If sc_type is ‘train’, this metric is computed immediately
after new training data is generated in the active learning
loop, but before the neural network’s weights are reset and
training commences. It is evaluated using the newly-generated
training data. If sc_type is ‘pool’, this metric is computed
using the pool of candidate points from which new training samples
are drawn at each iteration. It is computed immediately after the
new training data is selected from the pool. If sc_type is model,
the a metric is computed without reference to any data set
(validation, training, or pool) present in the active learning
loop, at the end of each active learning iteration. The only
implemented metrics which have sc_type ‘model’ measure predictive
stability on some specified unlabelled set of points, namely
UnlabelledAgreement and UnlabelledDeltaFScore, but the possibility
remains that different sorts of metrics in this class, for example
the one based on error stability computed directly from the neural
network weights discussed in arXiv:2104.01836, may be desirable
for a user to implement.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>{‘val’, ‘train’, ‘pool’, ‘model’}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.name" title="Link to this definition">¶</a></dt>
<dd><p>A string which denotes a name for this metric. In a list of metrics
passed to a BFBLearner class, the names of each member of the list
should be unique.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sc_type</strong> (<em>{'val'</em><em>, </em><em>'train'</em><em>, </em><em>'pool'</em><em>, </em><em>'model'}</em>) – </p></li>
<li><p><strong>name</strong> (<em>str</em>) – </p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.record_score">
<span class="sig-name descname"><span class="pre">record_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.record_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.record_score" title="Link to this definition">¶</a></dt>
<dd><p>Appends the latest value for the performance metric to the status_history object.
This method calls an abstract method “performance_check” which will turn
whatever input is specified in the method into the metric the object is supposed
to track. The method performance_check, and therefore the arguments going into
this method, will vary depending on the specific subclass of ALMetric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.print_status">
<span class="sig-name descname"><span class="pre">print_status</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">file=&lt;_io.TextIOWrapper</span> <span class="pre">name='&lt;stdout&gt;'</span> <span class="pre">mode='w'</span> <span class="pre">encoding='utf-8'&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.print_status"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.print_status" title="Link to this definition">¶</a></dt>
<dd><p>A method which prints the last entry in status_history to a
file (or the console). Uses the method perf_message
(which is often overwritten in the child class) to identify
the metric being printed and separates status_history elements
that are tuples into different printout lines, for clarity.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>A method which prints out a message that is helpful in
identifying what metric is being reported when a user calls
print_status. Often overwritten in a child class.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.performance_check">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>An abstract class which takes some arguments (depending on
the type of performance metric) and computes the quantity or
quantities that the performance metric is supposed to track.
This method is called by record_score and its results are
appended to the status_history attribute.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>A function which reduces the status_history object to a list
of single numbers (usually some sort of figure of merit) in the
event that the members of status_history are a list or a tuple.
By default, it simply returns the full status_history list
and must be overwritten in subclasses which have lists or tuples
as entries in status_history.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*args</strong> (<em>Any</em>) – Some overwritten versions of this class can accept optional
arguments, although the method does not in the parent class.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A NumPy array featuring information from status_history for plotting.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.reset_data">
<span class="sig-name descname"><span class="pre">reset_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.reset_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.reset_data" title="Link to this definition">¶</a></dt>
<dd><p>A function which resets the metric data entirely. In some
subclasses, this must be overloaded to properly reset the class.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.get_legend">
<span class="sig-name descname"><span class="pre">get_legend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.get_legend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.get_legend" title="Link to this definition">¶</a></dt>
<dd><p>Returns a legend for a plot of the metric given by plot_metric.
Often must be overwritten in subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*args</strong> (<em>Any</em>) – Some overwritten versions of this class can accept optional
arguments, although the method does not in the parent class.
Must take the same arguments as get_metric.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of strings which are usable to specify a legend in
matplotlib.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of strings</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ALMetric.plot_metric">
<span class="sig-name descname"><span class="pre">plot_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ALMetric.plot_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ALMetric.plot_metric" title="Link to this definition">¶</a></dt>
<dd><p>Plots the performance metric as a function of the number of
active learning iterations.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> (<em>str</em><em>, </em><em>optional</em>) – If this argument is specified, then the plot of the metric
will be saved as a .png file in the directory with the name
given by filepath.</p></li>
<li><p><strong>**kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – Many subclasses of ALMetric have get_metric and get_legend
methods which take some keyword arguments– these can be
specified when calling plot_metric.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ModelMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ALMetric" title="bfbrain.AL_Metrics.ALMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALMetric</span></code></a></p>
<p>An abstract class for handling metrics which depend only on the
BFBLearner object’s model, plus some consistent internal information.
This class can be used as a “catch-all” for metrics which don’t fit
neatly into other categories– for example, we use it in
UnlabelledPredsMetric and its child classes to track the predictions
of the model on some unlabelled set of inputs.</p>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelMetric.performance_check">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelMetric.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelMetric.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>The performance_check method now specifies the arguments that
a class inheriting from TrainMetric should use.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">UnlabelledPredsMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledPredsMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ModelMetric" title="bfbrain.AL_Metrics.ModelMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelMetric</span></code></a></p>
<p>An abstract class for handling metrics which go by the predictions
of the model on some unlabelled set of quartic coefficients.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric.lams">
<span class="sig-name descname"><span class="pre">lams</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric.lams" title="Link to this definition">¶</a></dt>
<dd><p>A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points the model
will make predictions on.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric.ds">
<span class="sig-name descname"><span class="pre">ds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric.ds" title="Link to this definition">¶</a></dt>
<dd><p>A Tensorflow dataset generated from lams.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric.batch_size" title="Link to this definition">¶</a></dt>
<dd><p>The maximum size of batches of lams that will be transferred to
the GPU and computed with at one time.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=200000</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics
traced by BFBLearner.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points the
model will make predictions on.</p></li>
<li><p><strong>name</strong> (<em>str</em>) – The name will provide a unique identifier for the metric in
the list of metrics tracked by BFBLearner– this identifier
will be ‘<a href="#id14"><span class="problematic" id="id15">model_</span></a>’+name.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default=200000</em>) – The maximum size of batches of lams that will be transferred
to the GPU and computed with at one time.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledPredsMetric.performance_check">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledPredsMetric.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>The performance_check method now specifies the arguments that
a class inheriting from TrainMetric should use.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">UnlabelledAgreement</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'agreement'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledAgreement"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric" title="bfbrain.AL_Metrics.UnlabelledPredsMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">UnlabelledPredsMetric</span></code></a></p>
<p>A metric which computes agreement (Cohen’s kappa) among
the model between successive iterations of active learning
on a specified set of unlabelled points.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The entries of this status_history object will be Cohen’s
kappa between successive iterations of active learning on lams.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.old_preds">
<span class="sig-name descname"><span class="pre">old_preds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.old_preds" title="Link to this definition">¶</a></dt>
<dd><p>The previous model’s predictions on lams. Preserved to compare
to the current model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.lams">
<span class="sig-name descname"><span class="pre">lams</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.lams" title="Link to this definition">¶</a></dt>
<dd><p>A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points
the model will make predictions on.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.ds">
<span class="sig-name descname"><span class="pre">ds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.ds" title="Link to this definition">¶</a></dt>
<dd><p>A Tensorflow dataset generated from lams.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.batch_size" title="Link to this definition">¶</a></dt>
<dd><p>The maximum size of batches of lams that will be transferred
to the GPU and computed with at one time.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=200000</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics
traced by BFBLearner. By default this will be ‘model_agreement’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.n_trials" title="Link to this definition">¶</a></dt>
<dd><p>The number of forward passes through the network to get the
predictions from Monte Carlo dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=100</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points
the model will make predictions on.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>default='agreement'</em>) – The name will provide a unique identifier for the metric
in the list of metrics tracked by BFBLearner– this identifier
will be ‘<a href="#id16"><span class="problematic" id="id17">model_</span></a>’+name.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default=200000</em>) – The maximum size of batches of lams that will be transferred
to the GPU and computed with at one time.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=100</em>) – The number of forward passes through the network to get
the predictions from Monte Carlo dropout.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledAgreement.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes Cohen’s kappa for the classifier between successive
active learning iterations, on the unlabelled quartic coefficients
lams. If there is no previous model (i.e., no active learning has
been done), returns 0. and saves the current model’s predictions
as old_preds.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledAgreement.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>Simply returns Cohen’s kappa as a function of the number
of active learning iterations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledAgreement.reset_data">
<span class="sig-name descname"><span class="pre">reset_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledAgreement.reset_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledAgreement.reset_data" title="Link to this definition">¶</a></dt>
<dd><p>Resets the data in the metric.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">UnlabelledDeltaF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'delta_F'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledDeltaF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.UnlabelledPredsMetric" title="bfbrain.AL_Metrics.UnlabelledPredsMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">UnlabelledPredsMetric</span></code></a></p>
<p>A metric which computes the estimated change in F score on a
specified unlabelled set of points for the model between successive
iterations of active learning on a specified set of unlabelled points,
based on the methodology of arXiv:cs/1901.09118.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The entries of this status_history object will be the estimated
change in F score between successive iterations of active learning
on lams.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.old_preds">
<span class="sig-name descname"><span class="pre">old_preds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.old_preds" title="Link to this definition">¶</a></dt>
<dd><p>The previous model’s predictions on lams. Preserved to compare
to the current model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.lams">
<span class="sig-name descname"><span class="pre">lams</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.lams" title="Link to this definition">¶</a></dt>
<dd><p>A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points
the model will make predictions on.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.ds">
<span class="sig-name descname"><span class="pre">ds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.ds" title="Link to this definition">¶</a></dt>
<dd><p>A Tensorflow dataset generated from lams.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.data.Dataset</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.batch_size">
<span class="sig-name descname"><span class="pre">batch_size</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.batch_size" title="Link to this definition">¶</a></dt>
<dd><p>The maximum size of batches of lams that will be transferred
to the GPU and computed with at one time.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=200000</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics
traced by BFBLearner. By default this will be ‘model_delta_F’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.n_trials" title="Link to this definition">¶</a></dt>
<dd><p>The number of forward passes through the network to get the
predictions from Monte Carlo dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=100</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing sets of quartic potential
coefficients. This will be an unlabelled set of points the
model will make predictions on.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>default='delta_F'</em>) – The name will provide a unique identifier for the metric
in the list of metrics tracked by BFBLearner– this
identifier will be ‘<a href="#id18"><span class="problematic" id="id19">model_</span></a>’+name.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default=200000</em>) – The maximum size of batches of lams that will be transferred
to the GPU and computed with at one time.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=100</em>) – The number of forward passes through the network to get the
predictions from Monte Carlo dropout.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledDeltaF.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes the estimated change in F score for the classifier
between successive active learning iterations, on the unlabelled
quartic coefficients lams. If there is no previous model (i.e.,
no active learning has been done), returns np.inf and saves the
current model’s predictions as old_preds.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledDeltaF.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>Simply returns the change in F score as a function of the
number of active learning iterations.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.UnlabelledDeltaF.reset_data">
<span class="sig-name descname"><span class="pre">reset_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#UnlabelledDeltaF.reset_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.UnlabelledDeltaF.reset_data" title="Link to this definition">¶</a></dt>
<dd><p>Resets the data in the metric.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ValidationMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ALMetric" title="bfbrain.AL_Metrics.ALMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALMetric</span></code></a></p>
<p>An abstract class for handling metrics which measure performance
of the model on a validation set. This class exists primarily to
remind the user that any validation-set-based performance metrics must
have their performance_check method take the inputs
(tf.keras.Model, tf.data.Dataset)</p>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationMetric.performance_check">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationMetric.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationMetric.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>The performance_check method now specifies the arguments that
a class inheriting from ValidationMetric should use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The model in a BFBLearner object.</p></li>
<li><p><strong>ds</strong> (<em>tf.data.Dataset</em>) – A Tensorflow dataset representing the labelled validation
set.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.TrainMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">TrainMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#TrainMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.TrainMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ALMetric" title="bfbrain.AL_Metrics.ALMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALMetric</span></code></a></p>
<p>An abstract class for handling metrics which measure predictions
of the model on newly-added training data. This class exists primarily
to remind the user that any training-set-based performance metrics
must have their performance_check method take the inputs
(tf.keras.Model, tf.Tensor)</p>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.TrainMetric.performance_check">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#TrainMetric.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.TrainMetric.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>The performance_check method now specifies the arguments that
a class inheriting from TrainMetric should use.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – The model in a BFBLearner object.</p></li>
<li><p><strong>lams</strong> (<em>tf.Tensor</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic
potential coefficients. This will be all of the points
that have been newly added to the training set in a
given round of active learning.</p></li>
<li><p><strong>labels</strong> (<em>tf.Tensor</em><em>(</em><em>bool</em><em>)</em>) – A 1-D Tensorflow tensor of booleans representing the
labels of the new training data points. The ith element
of this tensor is True if the ith row of lams represents
a set of quartic potential coefficients that the oracle
has labelled as bounded-from-below, False otherwise.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetric">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">PoolMetric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetric" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ALMetric" title="bfbrain.AL_Metrics.ALMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ALMetric</span></code></a></p>
<p>An abstract class for handling metrics which measure predictions
of the model on the pools of candidate points from which new training
data is drawn. This class exists primarily to ensure that these
metrics have additional abstract methods which much be specified to
implement a class of this sort.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetric.batch_scores">
<span class="sig-name descname"><span class="pre">batch_scores</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetric.batch_scores" title="Link to this definition">¶</a></dt>
<dd><p>Because the pool of candidate points are generated in discrete
manageable batches, the metrics are computed over each individual
batch and then combined, the precise manner of which depends on
the specific metric in question. However, all pool metrics must
have this attribute to act as temporary storage of the individual
batch results before they can be combined.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetric.record_batch">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">record_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetric.record_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetric.record_batch" title="Link to this definition">¶</a></dt>
<dd><p>An abstract method which will record an individual batch’s
results to batch_scores, in a manner that must be specified
in a subclass.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetric.record_score">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">record_score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetric.record_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetric.record_score" title="Link to this definition">¶</a></dt>
<dd><p>The concrete record_score method of the ALMetric class
must be overwritten with an abstract version,
which must in turn be specified in subclasses.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">PoolMetricReduction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">red</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['mean',</span> <span class="pre">'min',</span> <span class="pre">'max']</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.PoolMetric" title="bfbrain.AL_Metrics.PoolMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">PoolMetric</span></code></a></p>
<p>An abstract class which inherits from PoolMetric, but features
methods to automatically take the mean/min/max of the scores
determined in record_batch. This is an abstract class which
shouldn’t be instantiated directly, but allows for rapid prototyping
of a variety of pool metrics.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.reduction" title="Link to this definition">¶</a></dt>
<dd><p>This is the reduction that is performed on individual batches,
and finally, among the results for all batches, to produce the
entries in status_history. If a list of reductions are applied,
then the elements of status_history will be lists with each
element being a different reduction being applied to the pool score.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>a list containing elements of {np.mean, np.min, np.max}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.red_name">
<span class="sig-name descname"><span class="pre">red_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.red_name" title="Link to this definition">¶</a></dt>
<dd><p>This list of strings will contain the same information as
reduction, but is used for labelling purposes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>a list containing elements of {‘mean’, ‘min’, ‘max’}</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<em>str</em>) – A unique identifier for the metric in the list of metrics in a
BFBLearner object.</p></li>
<li><p><strong>red</strong> (<em>{'mean'</em><em>, </em><em>'min'</em><em>, </em><em>'max'}</em><em> or </em><em>a list</em><em> of </em><em>those values</em>) – This argument specifies the reduction that is performed on
individual batches, and finally, among the results for all
batches, to produce the entries in status_history.
If a list of reductions are applied, then the elements of
status_history will be lists with each element being a different
reduction being applied to the pool score.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.record_batch">
<span class="sig-name descname"><span class="pre">record_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.record_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.record_batch" title="Link to this definition">¶</a></dt>
<dd><p>Records a score generated by performance_check (which must be
specified in a subclass) for an individual batch in the pool of
candidate points to the batch_scores list.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.record_score">
<span class="sig-name descname"><span class="pre">record_score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.record_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.record_score" title="Link to this definition">¶</a></dt>
<dd><p>Combines the metrics computed for each batch into a single
status_history entry, and append that entry to status_history.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of
the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reduction</strong> (<em>str in self.red_name</em><em>, </em><em>optional</em>) – If specified, get_metric will only return the values
corresponding to the specified reduction. If not specified,
get_metric will return the status_history object
in its entirety.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Represents some plottable set of values from status_history.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.reset_data">
<span class="sig-name descname"><span class="pre">reset_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.reset_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.reset_data" title="Link to this definition">¶</a></dt>
<dd><p>Reset the data in status_history.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolMetricReduction.get_legend">
<span class="sig-name descname"><span class="pre">get_legend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolMetricReduction.get_legend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolMetricReduction.get_legend" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_legend can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reduction</strong> (<em>str in self.red_name</em><em>, </em><em>optional</em>) – get_legend will return a legend consistent with the get_metric
result with the same reduction argument passed.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An argument to specify a legend in matplotlib.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">PoolDeltaF</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'delta_F'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolDeltaF"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.PoolMetric" title="bfbrain.AL_Metrics.PoolMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">PoolMetric</span></code></a></p>
<p>A metric for keeping track of the estimated change in F score for
successive iterations of the active learning algorithm on unlabelled
data, based on arXiv:cs/1901.09118. Each time active learning
produces a new unlabelled pool of candidate points to draw training
examples from, this metric computes the model’s predicted labels for
all of these points, and stores both the pool of points and the
predictions. Then, after another round of active learning, the metric
computes the NEW model’s predicted labels on the stored pool of
points. Then, the two sets of predictions are compared and the
estimated change in F score over the pool distribution is computed
from the level of agreement between the two sets of predictions,
following the procedure outlined in arXiv:cs/1901.09118. Predictions
are based on Monte Carlo dropout with 100 forward passes through the
neural network.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.status_history" title="Link to this definition">¶</a></dt>
<dd><p>A list which contains a record, for each round of active learning,
of the estimated change in F score.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.name" title="Link to this definition">¶</a></dt>
<dd><p>A string which denotes a name for this metric. In a list of
metrics passed to a BFBLearner class, the names of each member
of the list should be unique.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str, default=’delta_F’</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.old_pool">
<span class="sig-name descname"><span class="pre">old_pool</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.old_pool" title="Link to this definition">¶</a></dt>
<dd><p>A list of 2-D NumPy arrays, each of which represents a batch
of points generated as part of the pool of candidate points
in active learning. This array stores the points that made
up the PREVIOUS round’s pool of points, so that the current model
can make predictions on them.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.new_pool">
<span class="sig-name descname"><span class="pre">new_pool</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.new_pool" title="Link to this definition">¶</a></dt>
<dd><p>A list of 2-D NumPy arrays, each of which represents a batch of
points generated as part of the pool of candidate points in
active learning. This array stores the points that made up the
CURRENT round’s pool of points, so that the current model can make
predictions on them. After recording the status_history value for
this metric, new_pool’s values are transferred to old_pool, and
then new_pool is cleared.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.old_preds">
<span class="sig-name descname"><span class="pre">old_preds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.old_preds" title="Link to this definition">¶</a></dt>
<dd><p>A list to contain all of the PREVIOUS model’s predictions on
old_pool.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.array(np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.new_preds">
<span class="sig-name descname"><span class="pre">new_preds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.new_preds" title="Link to this definition">¶</a></dt>
<dd><p>A list to contain all of the CURRENT model’s predictions on
old_pool.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.array(np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.newer_preds">
<span class="sig-name descname"><span class="pre">newer_preds</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.newer_preds" title="Link to this definition">¶</a></dt>
<dd><p>A list to contain all of the CURRENT model’s predictions
on new_pool. After recording the status_history value for
this metric, newer_preds values are transferred to old_preds,
and then newer_preds and new_preds are both cleared.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.array(np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.old_pool_iter">
<span class="sig-name descname"><span class="pre">old_pool_iter</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.old_pool_iter" title="Link to this definition">¶</a></dt>
<dd><p>An iterator over old_pool. Replaced whenever old_pool is
overwritten.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>iter</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.record_batch">
<span class="sig-name descname"><span class="pre">record_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolDeltaF.record_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.record_batch" title="Link to this definition">¶</a></dt>
<dd><p>Records newly-generated pool points and the current model’s
prediction on them. After the first active learning iteration,
also records the current model’s predictions on the corresponding
element of old_pool, since after the first active learning
iteration the old_pool and new_pool will always have the same
number of elements.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.model</em>) – The current Tensorflow model of a BFBLearner object.</p></li>
<li><p><strong>L</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing a batch of pool points
proposed to the neural network as possible training points.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">L</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolDeltaF.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes the predictions of the neural network on an input
batch of pool points, and returns a tuple of the predictions
and the pool points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.model</em>) – The current Tensorflow model of a BFBLearner object.</p></li>
<li><p><strong>L</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing a batch of pool points
proposed to the neural network as possible training points.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>np.array(np.float32)</em> – A 1-D NumPy array of model predictions on L</p></li>
<li><p><em>np.array(np.float32, np.float32)</em> – The array L</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.record_score">
<span class="sig-name descname"><span class="pre">record_score</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolDeltaF.record_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.record_score" title="Link to this definition">¶</a></dt>
<dd><p>Combines the predictions made on individual batches
in order to produce an estimate of the change in F score on
old_pool, and appends this estimate onto status_history. Then,
overwrites old_pool with new_pool, old_preds with newer_preds,
and then resets new_pool, new_preds, and newer_preds.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The last element of status_history.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolDeltaF.reset_data">
<span class="sig-name descname"><span class="pre">reset_data</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolDeltaF.reset_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolDeltaF.reset_data" title="Link to this definition">¶</a></dt>
<dd><p>Clears all data in the metric.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ModelEvaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'accuracy'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelEvaluation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ValidationMetric" title="bfbrain.AL_Metrics.ValidationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationMetric</span></code></a></p>
<p>A metric that simply records the model.evaluate() method on a
labelled Tensorflow dataset (the validation set in our context).
BFBrain’s call to Tensorflow’s evaluate method keeps track of the
model accuracy, false positives, and false negatives via evaluate().
Note that this method does NOT use Monte Carlo dropout to compute
these quantities, but instead approximates the mean of Monte Carlo
dropout via a single pass through the network with no dropout
(and all model weights divided by 1 - &lt;dropout probability&gt;).</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The entries of status_history here will be lists of the form
[&lt;binary accuracy&gt;, &lt;false positives&gt;, &lt;false negatives&gt;],
evaluated over the validation set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of lists of np.float32</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics traced
by BFBLearner. By default, this will be ‘val_accuracy’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>default='accuracy'</em>) – The name will provide a unique identifier for the metric in the
list of metrics tracked by BFBLearner– this identifier will be
‘<a href="#id20"><span class="problematic" id="id21">val_</span></a>’+name.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelEvaluation.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>This performance_check simply calls Tensorflow’s
model.evaluate() method, and ignores the first term (the loss)</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelEvaluation.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ModelEvaluation.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ModelEvaluation.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ModelEvaluation.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>For plotting, this metric simply requests the binary accuracy
over the active learning iterations.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.MCModelEvaluation">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">MCModelEvaluation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'MC_accuracy'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#MCModelEvaluation"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.MCModelEvaluation" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ValidationMetric" title="bfbrain.AL_Metrics.ValidationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationMetric</span></code></a></p>
<p>A metric that records the same data as ModelEvaluation on a
labelled Tensorflow dataset (the validation set in our context),
but using Monte Carlo dropout with 100 forward passes through
the neural network. Otherwise functions identically to ModelEvaluation.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.MCModelEvaluation.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.MCModelEvaluation.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics traced
by BFBLearner. By default, this will be ‘val_MC_accuracy’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>name</strong> (<em>str</em><em>, </em><em>default='MC_accuracy'</em>) – The name will provide a unique identifier for the metric in the
list of metrics tracked by BFBLearner– this identifier will be
‘<a href="#id22"><span class="problematic" id="id23">val_</span></a>’+name.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.MCModelEvaluation.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#MCModelEvaluation.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.MCModelEvaluation.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>This performance_check finds the binary accuracy,
false positives, and false negatives over a validation data set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.MCModelEvaluation.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#MCModelEvaluation.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.MCModelEvaluation.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.MCModelEvaluation.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#MCModelEvaluation.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.MCModelEvaluation.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>A function which reduces the status_history object to a list
of single numbers (usually some sort of figure of merit) in the
event that the members of status_history are a list or a tuple.
By default, it simply returns the full status_history list
and must be overwritten in subclasses which have lists or tuples
as entries in status_history.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*args</strong> (<em>Any</em>) – Some overwritten versions of this class can accept optional
arguments, although the method does not in the parent class.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>A NumPy array featuring information from status_history for plotting.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">DecisionBoundaryScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">tol_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'combined_false_score'</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#DecisionBoundaryScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ValidationMetric" title="bfbrain.AL_Metrics.ValidationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationMetric</span></code></a></p>
<p>A metric which records a “decision boundary score”– for each point
that the (non-MC-dropout) neural network classifies incorrectly in a
validation set, this method uses gradient ascent/descent to determine
the angular distance on the hypersphere of quartic coeffecients to the
decision boundary. Reports the results of the mean,
standard deviation, and max of these scores in radians for both
false positives and false negatives, as well as the number of points
in both groups which exceed some input number of radians distance from
the decision boundary. This metric can be extremely computationally
intensive, and generally can reflect the deterministic forward pass’s
tendency to occasionally be incorrect and very overconfident.
However, if a user is insistent on only using a single forward pass
of the neural network to evaluate a network, this method enables them
to be somewhat confident that any points that are mislabelled will be
close in parameter space to points which are correctly labelled.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The entries of status_history here will contain a tuple of two
lists of the form [&lt;mean&gt;, &lt;std&gt;, &lt;max&gt;, # &gt; tol_dist radians],
the first for false positives and the second for false negatives.
The mean, standard deviation, and max values are computed from
the angular distance (in radians) of the incorrectly classified
points to points along the decision boundary. The final entry
is the number of points for which this distance is greater than
some user-specified cutoff, tol_dist.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of tuples of lists of np.float32</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics
traced by BFBLearner. By default, this will be
‘val_combined_false_score’.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.tol_dist">
<span class="sig-name descname"><span class="pre">tol_dist</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.tol_dist" title="Link to this definition">¶</a></dt>
<dd><p>The maximum angular distance of an incorrectly-classified point
to the decision boundary that the user considers acceptable. For
small (O(0.01)) values of this angle, it roughly corresponds to
the fractional degree of correction of the quartic coefficients
to reach the decision boundary– so an angular deformation of 0.01
represents approximately a 1% correction to the quartic coupling
coefficients.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>tol_dist</strong> (<em>float</em>) – The maximum angular distance of an incorrectly-classified point
to the decision boundary that the user considers acceptable. For
small (O(0.01)) values of this angle, it roughly corresponds to
the fractional degree of correction of the quartic coefficients
to reach the decision boundary– so an angular deformation of 0.01
represents approximately a 1% correction to the quartic coupling
coefficients.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>default='combined_false_score'</em>) – The name will provide a unique identifier for the metric in the
list of metrics tracked by BFBLearner– this identifier will be
‘<a href="#id24"><span class="problematic" id="id25">val_</span></a>’+name.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#DecisionBoundaryScore.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes the angular distances between incorrectly classified
points and the decision boundary.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#DecisionBoundaryScore.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DecisionBoundaryScore.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#DecisionBoundaryScore.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.DecisionBoundaryScore.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>Returns the number of false positives and false negatives
greater than tol_dist radians from the decision boundary
(tracked separately) for plotting over the course of active
learning.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ValidationConfusionMatrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'BALD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.95,</span> <span class="pre">1.0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationConfusionMatrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ValidationMetric" title="bfbrain.AL_Metrics.ValidationMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationMetric</span></code></a></p>
<p>A metric that finds the elements of the confusion matrix (correctly
labelled positives, false positives, correctly labelled negatives,
false negatives) for the validation set. Also calculates the confusion
matrix with points which score higher than specified quantiles on
some specified uncertainty metric, evaluated over all points which
have the same predicted classification, omitted from the validation
set. This metric in turn has all the information necessary for the
extraction of binary classifier quality metrics such as precision,
recall, or F score.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The elements status_history here are tuples of the form
(&lt;true positives&gt;, &lt;false positives&gt;, &lt;true negatives&gt;, &lt;false negatives&gt;),
where each element of the tuple is a list of length equal to the
length of the attribute quantiles. Each element of the lists are
the values of that observable assuming that we only include points
with an uncertainty score (given by score_fn) less than or equal
to the corresponding quantile (evaluated for all points of the
same predicted class) in quantiles.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of tuples of lists of ints</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics traced
by BFBLearner. By default this will be ‘val_&lt;score_fn&gt;_confusion’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.score_fn">
<span class="sig-name descname"><span class="pre">score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.score_fn" title="Link to this definition">¶</a></dt>
<dd><p>A callable of the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).
The pre-implemented functions for different uncertainty metrics
can be specified in the constructor by using any of
‘BALD’ (mutual information), ‘MaxEntropy’ (Shannon entropy),
‘variation_ratios’ (variation ratios),
‘predictive_variance’ (variance of the prediction distribution),
or ‘QBDC’ (score*(1-score), where score is the Monte Carlo
dropout-evaluated prediction for an input)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.tf_score_fn">
<span class="sig-name descname"><span class="pre">tf_score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.tf_score_fn" title="Link to this definition">¶</a></dt>
<dd><p>Tensorflow jit-compiled version of score_fn.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jit-compiled callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.n_trials" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or None</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Specifies the score function that the metric will apply to the
pool of candidate points. If a callable (corresponding to a custom
score function) is used, it must have the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether or not n_trials is specified.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Allows for a custom name of the metric. If this argument is not
specified, a name will be automatically generated as
‘val_&lt;score_fn&gt;_confusion’.</p></li>
<li><p><strong>quantiles</strong> (<em>list</em><em> of </em><em>floats</em><em>, </em><em>default=</em><em>[</em><em>0.95</em><em>, </em><em>1.</em><em>]</em>) – The uncertainty quantiles for which the metric is tracked (see
the status_history documentation)</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>optional</em>) – For score_fn arguments that take a n_trials argument, which
includes every pre-implemented score_fn except ‘random’, this
argument can be specified here. If it is not specified, the
default value for the given score_fn is used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationConfusionMatrix.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Finds the confusion matrix (true positives, false positives,
true negatives, false negatives) for the model over the validation
set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationConfusionMatrix.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationConfusionMatrix.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>quantile</strong> (<em>float in self.quantiles</em><em>, </em><em>optional</em>) – If specified, get_metric will only return the values
corresponding to the false positives and false negatives
found with uncertainty scores less than or equal to the
given quantile. Otherwise, all false positives and false
negatives for all quantiles will be returned for plotting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Represents some plottable set of values from status_history.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationConfusionMatrix.get_legend">
<span class="sig-name descname"><span class="pre">get_legend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationConfusionMatrix.get_legend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix.get_legend" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>quantile</strong> (<em>float in self.quantiles</em><em>, </em><em>optional</em>) – The method will return a legend appropriate for plotting
get_metric, when get_metric is given the same arguments.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of strings representing a plot legend for matplotlib.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ValidationFScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'BALD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quantiles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[0.95,</span> <span class="pre">1.0]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationFScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.ValidationConfusionMatrix" title="bfbrain.AL_Metrics.ValidationConfusionMatrix"><code class="xref py py-class docutils literal notranslate"><span class="pre">ValidationConfusionMatrix</span></code></a></p>
<p>A metric that finds the precision, recall, and F score for the
validation set. Also calculates the confusion matrix with points
which score higher than specified quantiles on some specified
uncertainty metric, evaluated over all points which have the same
predicted classification, omitted from the validation set. This metric
in turn has all the information necessary for the extraction of binary
classifier quality metrics such as precision, recall, or F score.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.status_history" title="Link to this definition">¶</a></dt>
<dd><p>The elements of the status_history object here are lists of the
form [&lt;precision&gt;, &lt;recall&gt;, &lt;F score&gt;], where each element of the
tuple is a list of length equal to the length of the attribute
quantiles. Each element of the lists are the values of that
observable assuming that we only include points with an uncertainty
score (given by score_fn) less than or equal to the corresponding
quantile (evaluated for all points of the same predicted class)
in quantiles.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of lists of lists of floats</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.name" title="Link to this definition">¶</a></dt>
<dd><p>The unique identifier for the metric in the list of metrics traced
by BFBLearner. By default this will be ‘val_&lt;score_fn&gt;_fscore’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.score_fn">
<span class="sig-name descname"><span class="pre">score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.score_fn" title="Link to this definition">¶</a></dt>
<dd><p>A callable of the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).
The pre-implemented functions for different uncertainty metrics
can be specified in the constructor by using any of
‘BALD’ (mutual information), ‘MaxEntropy’ (Shannon entropy),
‘variation_ratios’ (variation ratios),
‘predictive_variance’ (variance of the prediction distribution),
or ‘QBDC’ (score*(1-score), where score is the Monte Carlo
dropout-evaluated prediction for an input)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.tf_score_fn">
<span class="sig-name descname"><span class="pre">tf_score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.tf_score_fn" title="Link to this definition">¶</a></dt>
<dd><p>Tensorflow jit-compiled version of score_fn.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jit-compiled callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.n_trials" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or None</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Specifies the score function that the metric will apply to the pool
of candidate points. If a callable (corresponding to a custom
score function) is used, it must have the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether or not n_trials is specified.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Allows for a custom name of the metric. If this argument is not
specified, a name will be automatically generated as
‘val_&lt;score_fn&gt;_fscore’.</p></li>
<li><p><strong>quantiles</strong> (<em>list</em><em> of </em><em>floats</em><em>, </em><em>default=</em><em>[</em><em>0.95</em><em>, </em><em>1.</em><em>]</em>) – The uncertainty quantiles for which the metric is tracked
(see the status_history documentation)</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>optional</em>) – For score_fn arguments that take a n_trials argument, which
includes every pre-implemented score_fn except ‘random’, this
argument can be specified here. If it is not specified, the
default value for the given score_fn is used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationFScore.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes the precision, recall, and F score over the validation
set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationFScore.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationFScore.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>quantile</strong> (<em>float in self.quantiles</em><em>, </em><em>optional</em>) – If specified, get_metric will only return the values
corresponding to the F score found with uncertainty scores
less than or equal to the given quantile. Otherwise, all
F scores for all quantiles will be returned for plotting.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Represents some plottable set of values from status_history.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ValidationFScore.get_legend">
<span class="sig-name descname"><span class="pre">get_legend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">quantile</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ValidationFScore.get_legend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ValidationFScore.get_legend" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>quantile</strong> (<em>float in self.quantiles</em><em>, </em><em>optional</em>) – The method will return a legend appropriate for plotting
get_metric, when get_metric is given the same arguments.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of strings representing a plot legend for matplotlib.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">PoolScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'BALD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['mean',</span> <span class="pre">'min',</span> <span class="pre">'max']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.PoolMetricReduction" title="bfbrain.AL_Metrics.PoolMetricReduction"><code class="xref py py-class docutils literal notranslate"><span class="pre">PoolMetricReduction</span></code></a></p>
<p>A metric which applies the function score_fn to the pool of
candidate points at every active learning iteration, before the
model is trained on any new data drawn from the pool.
Evaluates score_fn on the pool points and records specified reductions
of these scores.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.status_history" title="Link to this definition">¶</a></dt>
<dd><p>Each entry in this status_history object has entries corresponding
to the score_fn results applied to each active learning
iteration’s pool of candidate points, with reduction(s) specified
in the constructor. If the constructor specifies multiple
reductions, each entry is a list with each value’s reduction
(so an entry will be [&lt;mean&gt;, &lt;max&gt;, &lt;min&gt;], for example).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of lists of floats (or np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.name" title="Link to this definition">¶</a></dt>
<dd><p>A string which denotes a name for this metric. In a list of
metrics passed to a BFBLearner class, the names of each member
of the list should be unique. By default will be ‘pool_&lt;score_fn&gt;’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.score_fn">
<span class="sig-name descname"><span class="pre">score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.score_fn" title="Link to this definition">¶</a></dt>
<dd><p>A callable of the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).
The pre-implemented functions for different uncertainty metrics
can be specified in the constructor by using any of
‘BALD’ (mutual information), ‘MaxEntropy’ (Shannon entropy),
‘variation_ratios’ (variation ratios),
‘predictive_variance’ (variance of the prediction distribution),
or ‘QBDC’ (score*(1-score), where score is the Monte Carlo
dropout-evaluated prediction for an input)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.tf_score_fn">
<span class="sig-name descname"><span class="pre">tf_score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.tf_score_fn" title="Link to this definition">¶</a></dt>
<dd><p>Tensorflow jit-compiled version of score_fn.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jit-compiled callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.n_trials" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or None</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Specifies the score function that the metric will apply to the
pool of candidate points. If a callable (corresponding to a custom
score function) is used, it must have the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether or not n_trials is specified.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Allows for a custom name of the metric. If this argument is not
specified, a name will be automatically generated as
‘pool_&lt;score_fn&gt;’.</p></li>
<li><p><strong>reduction</strong> (<em>{'mean'</em><em>, </em><em>'min'</em><em>, </em><em>'max'}</em><em> or </em><em>a list</em><em> of </em><em>these values</em><em>, </em><em>default=</em><em>[</em><em>'mean'</em><em>,</em><em>'min'</em><em>,</em><em>'max'</em><em>]</em>) – Specifies what reductions should be done on the scores computed
for the pool candidate points. If a list is specified, all
reductions in the list are computed.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>optional</em>) – For score_fn arguments that take a n_trials argument, which
includes every pre-implemented score_fn except ‘random’, this
argument can be specified here. If it is not specified, the
default value for the given score_fn is used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.PoolScore.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#PoolScore.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.PoolScore.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>performance_check for this metric records the score function
evaluated on a pool of candidate points, subject to the
reduction(s) specified in the constructor.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>*args</strong> (<em>(</em><em>tf.keras.Model</em><em>, </em><em>tf.tensor</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em><em>) or </em><em>tf.tensor</em><em>(</em><em>tf.float32</em><em>)</em>) – If the class’s score_fn were already evaluated as part of
active learning (namely, if the score_fn corresponds to the
one used as the acquisition function in active learning),
then this method can take an already-evaluated Tensorflow
tensor consisting of a list of scores. If not, then we can
pass the arguments appropriate for score_fn in order to
evaluate the results directly.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A list of the specified reductions in the score function for
a batch of pool candidate points. These are then combined into
a single entry into status_history using the methods in the
parent class.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of np.float32</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">NewDataScore</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'BALD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">name</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">red</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">['mean',</span> <span class="pre">'min',</span> <span class="pre">'max']</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#NewDataScore"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.TrainMetric" title="bfbrain.AL_Metrics.TrainMetric"><code class="xref py py-class docutils literal notranslate"><span class="pre">TrainMetric</span></code></a></p>
<p>A metric which applies the function score_fn to the set of points
that are added to the training set at every active learning iteration,
before the model is trained on the new data. Evaluates score_fn on
these points and records specified reductions of these scores.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.status_history">
<span class="sig-name descname"><span class="pre">status_history</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.status_history" title="Link to this definition">¶</a></dt>
<dd><p>Each entry in this status_history object has entries corresponding
to the score_fn results applied to each active learning
iteration’s new training data, with reduction(s) specified in the
constructor. If the constructor specifies multiple reductions,
each entry is a list with each value’s reduction (so an entry
will be [&lt;mean&gt;, &lt;max&gt;, &lt;min&gt;], for example).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of lists of floats (or np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.name">
<span class="sig-name descname"><span class="pre">name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.name" title="Link to this definition">¶</a></dt>
<dd><p>A string which denotes a name for this metric. In a list of
metrics passed to a BFBLearner class, the names of each member
of the list should be unique. By default will be ‘train_&lt;score_fn&gt;’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.score_fn">
<span class="sig-name descname"><span class="pre">score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.score_fn" title="Link to this definition">¶</a></dt>
<dd><p>A callable of the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).
The pre-implemented functions for different uncertainty metrics
can be specified in the constructor by using any of
‘BALD’ (mutual information), ‘MaxEntropy’ (Shannon entropy),
‘variation_ratios’ (variation ratios),
‘predictive_variance’ (variance of the prediction distribution),
or ‘QBDC’ (score*(1-score), where score is the Monte Carlo
dropout-evaluated prediction for an input)</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.tf_score_fn">
<span class="sig-name descname"><span class="pre">tf_score_fn</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.tf_score_fn" title="Link to this definition">¶</a></dt>
<dd><p>Tensorflow jit-compiled version of score_fn.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jit-compiled callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.n_trials">
<span class="sig-name descname"><span class="pre">n_trials</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.n_trials" title="Link to this definition">¶</a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.reduction" title="Link to this definition">¶</a></dt>
<dd><p>This is the reduction that is performed on the scores to produce
the entries in status_history. If a list of reductions are
applied, then the elements of status_history will be lists
with each element being a different reduction being applied
to the scores.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>a list containing elements of {np.mean, np.min, np.max}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.red_name">
<span class="sig-name descname"><span class="pre">red_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.red_name" title="Link to this definition">¶</a></dt>
<dd><p>This list of strings will contain the same information as
reduction, but is used for labelling purposes.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>a list containing elements of {‘mean’, ‘min’, ‘max’}</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Specifies the score function that the metric will apply to the
pool of candidate points. If a callable (corresponding to a
custom score function) is used, it must have the signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether or not n_trials is specified.</p></li>
<li><p><strong>name</strong> (<em>str</em><em>, </em><em>optional</em>) – Allows for a custom name of the metric. If this argument is not
specified, a name will be automatically generated as
‘train_&lt;score_fn&gt;’.</p></li>
<li><p><strong>red</strong> (<em>{'mean'</em><em>, </em><em>'min'</em><em>, </em><em>'max'}</em><em> or </em><em>a list</em><em> of </em><em>these values</em><em>, </em><em>default=</em><em>[</em><em>'mean'</em><em>,</em><em>'min'</em><em>,</em><em>'max'</em><em>]</em>) – Specifies what reductions should be done on the scores computed
for the new training data. If a list is specified, all reductions
in the list are computed.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>optional</em>) – For score_fn arguments that take a n_trials argument, which
includes every pre-implemented score_fn except ‘random’, this
argument can be specified here. If it is not specified,
the default value for the given score_fn is used.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.performance_check">
<span class="sig-name descname"><span class="pre">performance_check</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#NewDataScore.performance_check"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.performance_check" title="Link to this definition">¶</a></dt>
<dd><p>Computes score_fn on the points added to the training set with
each active learning iteration, and then records the specified
reductions.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.perf_message">
<span class="sig-name descname"><span class="pre">perf_message</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#NewDataScore.perf_message"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.perf_message" title="Link to this definition">¶</a></dt>
<dd><p>The perf_message method labels any printed output of the metric.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.get_metric">
<span class="sig-name descname"><span class="pre">get_metric</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#NewDataScore.get_metric"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.get_metric" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_metric can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reduction</strong> (<em>str in self.red_name</em><em>, </em><em>optional</em>) – If specified, get_metric will only return the values
corresponding to the specified reduction. If not specified,
get_metric will return the status_history object in its
entirety.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Represents some plottable set of values from status_history.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.NewDataScore.get_legend">
<span class="sig-name descname"><span class="pre">get_legend</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#NewDataScore.get_legend"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.NewDataScore.get_legend" title="Link to this definition">¶</a></dt>
<dd><p>In this subclass, get_legend can take a keyword argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>reduction</strong> (<em>str in self.red_name</em><em>, </em><em>optional</em>) – get_legend will return a legend consistent with the get_metric
result with the same reduction argument passed.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An argument to specify a legend in matplotlib.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of str</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.StoppingCondition">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">StoppingCondition</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metric_func</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#StoppingCondition"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.StoppingCondition" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A generic class for implementing early stopping conditions
for active learning. A StoppingCondition object is called each round
immediately after the metric it follows is evaluated. Then, if the
call returns True, the active learning loop is terminated.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.StoppingCondition.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.StoppingCondition.metric_name" title="Link to this definition">¶</a></dt>
<dd><p>Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.StoppingCondition.metric_func">
<span class="sig-name descname"><span class="pre">metric_func</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.StoppingCondition.metric_func" title="Link to this definition">¶</a></dt>
<dd><p>A callable which takes a metric and an (optional) integer index
as input and returns True if the stopping condition has been met,
and False otherwise. Note that if one wishes to use the method
find_stopping_index, the metric_func function MUST be capable of
accommodating the optional integer argument. If this argument
won’t be called, it’s acceptable to use an existing argument.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric_name</strong> (<em>str</em>) – Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p></li>
<li><p><strong>metric_func</strong> (<em>callable</em>) – A callable which takes a metric and an (optional) integer index as
input and returns True if the stopping condition has been met,
and False otherwise.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.StoppingCondition.find_stopping_index">
<span class="sig-name descname"><span class="pre">find_stopping_index</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metrics_dict</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#StoppingCondition.find_stopping_index"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.StoppingCondition.find_stopping_index" title="Link to this definition">¶</a></dt>
<dd><p>Computes the index (active learning iteration) at which this
StoppingCondition WOULD have stopped active learning if it were
applied to the metrics for an already-trained BFBLearner object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>metrics_dict</strong> (<em>dict</em>) – A dictionary relating the names of ALMetric objects (or rather
child classes of this class) to the objects themselves,
extracted from a trained BFBLearner object.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An integer representing the active learning round at which
the StoppingCondition would have stopped active learning, if
it had been implemented during training. If the condition
would not have been met, returns -1.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ScoreNotDecreasing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">ScoreNotDecreasing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reduction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'mean'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#ScoreNotDecreasing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.ScoreNotDecreasing" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.StoppingCondition" title="bfbrain.AL_Metrics.StoppingCondition"><code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCondition</span></code></a></p>
<p>A stopping condition based on when an uncertainty score (in
particular BALD or variation ratios) is not decreasing over some data
set (usually the pool of candidate points proposed by the classifier
or the set of training points added as training data). Because
mutual information, variation ratios, and predictive variance are all
in theory metrics of epistemic uncertainty (or in the case of the
second, at least highly sensitive to it), some measurement of
these scores should be decreasing as more data is added. If it’s not,
then the network probably reached close to the highest performance
it’s capable of attaining.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ScoreNotDecreasing.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ScoreNotDecreasing.metric_name" title="Link to this definition">¶</a></dt>
<dd><p>Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ScoreNotDecreasing.metric_func">
<span class="sig-name descname"><span class="pre">metric_func</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ScoreNotDecreasing.metric_func" title="Link to this definition">¶</a></dt>
<dd><p>A callable which takes a metric and an (optional) integer index
as input and returns True if the stopping condition has been met,
and False otherwise. In this case, metric_func checks to see if
a specified uncertainty score on some set of points hasn’t
achieved a new minimum over some specified number of rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ScoreNotDecreasing.reduction">
<span class="sig-name descname"><span class="pre">reduction</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ScoreNotDecreasing.reduction" title="Link to this definition">¶</a></dt>
<dd><p>Must be some reduction over the score that the metric specified
by metric_name has evaluated. This is the specific quantity that
the stopping condition monitors.’</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>{‘mean’, ‘min’, ‘max’, ‘std’}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.ScoreNotDecreasing.patience">
<span class="sig-name descname"><span class="pre">patience</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.ScoreNotDecreasing.patience" title="Link to this definition">¶</a></dt>
<dd><p>The number of rounds without achieving a new minimum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=5</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric_name</strong> (<em>str</em>) – Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track.</p></li>
<li><p><strong>reduction</strong> (<em>{'mean'</em><em>, </em><em>'min'</em><em>, </em><em>'max'</em><em>, </em><em>'std'}</em>) – Must be some reduction over the score that the metric specified
by metric_name has evaluated. This is the specific quantity that
the stopping condition monitors.’</p></li>
<li><p><strong>patience</strong> (<em>int</em><em>, </em><em>default=5</em>) – The number of rounds without achieving a new minimum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.AccuracyNotImproving">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">AccuracyNotImproving</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#AccuracyNotImproving"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.AccuracyNotImproving" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.StoppingCondition" title="bfbrain.AL_Metrics.StoppingCondition"><code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCondition</span></code></a></p>
<p>A stopping condition that monitors either a ModelEvaluation or
MCModelEvaluation metric and stops the active learning after some
number of rounds have passed without achieving a new maximum accuracy.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.AccuracyNotImproving.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.AccuracyNotImproving.metric_name" title="Link to this definition">¶</a></dt>
<dd><p>Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.AccuracyNotImproving.metric_func">
<span class="sig-name descname"><span class="pre">metric_func</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.AccuracyNotImproving.metric_func" title="Link to this definition">¶</a></dt>
<dd><p>A callable which takes a metric and an (optional) integer index as
input and returns True if the stopping condition has been met, and
False otherwise. In this case, metric_func checks to see if the
accuracy entry for a ModelEvaluation or MCModelEvaluation metric
hasn’t achieved a new maximum over some specified number of rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.AccuracyNotImproving.patience">
<span class="sig-name descname"><span class="pre">patience</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.AccuracyNotImproving.patience" title="Link to this definition">¶</a></dt>
<dd><p>The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=5</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric_name</strong> (<em>str</em>) – Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track.</p></li>
<li><p><strong>patience</strong> (<em>int</em><em>, </em><em>default=5</em>) – The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.FScoreNotImproving">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">FScoreNotImproving</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">quant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#FScoreNotImproving"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.FScoreNotImproving" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.StoppingCondition" title="bfbrain.AL_Metrics.StoppingCondition"><code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCondition</span></code></a></p>
<p>A stopping condition that monitors a ValidationConfusionMatrix or
ValidationFScore metric and stops the active learning after some
number of rounds have passed without achieving a new maximum F score.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.FScoreNotImproving.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.FScoreNotImproving.metric_name" title="Link to this definition">¶</a></dt>
<dd><p>Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.FScoreNotImproving.metric_func">
<span class="sig-name descname"><span class="pre">metric_func</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.FScoreNotImproving.metric_func" title="Link to this definition">¶</a></dt>
<dd><p>A callable which takes a metric and an (optional) integer index
as input and returns True if the stopping condition has been met,
and False otherwise. In this case, metric_func checks to see if
the F score evaluated over some uncertainty quantile
(see ValidationConfusionMatrix and ValidationFScore documentation
for details) hasn’t achieved a new maximum in patience rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.FScoreNotImproving.quant">
<span class="sig-name descname"><span class="pre">quant</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.FScoreNotImproving.quant" title="Link to this definition">¶</a></dt>
<dd><p>The uncertainty quantile that the stopping condition should check.
Default is 1.0, meaning the entire validation set is considered.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float, default=1.0</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.FScoreNotImproving.patience">
<span class="sig-name descname"><span class="pre">patience</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.FScoreNotImproving.patience" title="Link to this definition">¶</a></dt>
<dd><p>The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=5</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric_name</strong> (<em>str</em>) – Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p></li>
<li><p><strong>quant</strong> (<em>float</em><em>, </em><em>default=1.0</em>) – The uncertainty quantile that the stopping condition should check.
Default is 1.0, meaning the entire validation set is considered.</p></li>
<li><p><strong>patience</strong> (<em>int</em><em>, </em><em>default=5</em>) – The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates
before halting active learning.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DeltaFNotDecreasing">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.AL_Metrics.</span></span><span class="sig-name descname"><span class="pre">DeltaFNotDecreasing</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metric_name</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/AL_Metrics.html#DeltaFNotDecreasing"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.AL_Metrics.DeltaFNotDecreasing" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="#bfbrain.AL_Metrics.StoppingCondition" title="bfbrain.AL_Metrics.StoppingCondition"><code class="xref py py-class docutils literal notranslate"><span class="pre">StoppingCondition</span></code></a></p>
<p>A stopping condition that monitors a PoolDeltaF or UnlabelledDeltaF
metric and stops active learning once the classifier’s estimated
change in F score has not decreased for a specified number of rounds.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DeltaFNotDecreasing.metric_name">
<span class="sig-name descname"><span class="pre">metric_name</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DeltaFNotDecreasing.metric_name" title="Link to this definition">¶</a></dt>
<dd><p>Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>str</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DeltaFNotDecreasing.metric_func">
<span class="sig-name descname"><span class="pre">metric_func</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DeltaFNotDecreasing.metric_func" title="Link to this definition">¶</a></dt>
<dd><p>A callable which takes a metric and an (optional) integer index
as input and returns True if the stopping condition has been met,
and False otherwise. In this case, metric_func checks to see if
the estimated change in F score has not achieved a new minimum
in patience rounds.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.AL_Metrics.DeltaFNotDecreasing.patience">
<span class="sig-name descname"><span class="pre">patience</span></span><a class="headerlink" href="#bfbrain.AL_Metrics.DeltaFNotDecreasing.patience" title="Link to this definition">¶</a></dt>
<dd><p>The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int, default=5</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metric_name</strong> (<em>str</em>) – Denotes the name of the performance metric (that is, the ALMetric
object’s name str) that the StoppingCondition should track</p></li>
<li><p><strong>patience</strong> (<em>int</em><em>, </em><em>default=5</em>) – The number of rounds without achieving a new maximum for its
monitored quantity that the stopping condition tolerates before
halting active learning.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-bfbrain.BFB_Learner">
<span id="bfbrain-bfb-learner-module"></span><h2>bfbrain.BFB_Learner module<a class="headerlink" href="#module-bfbrain.BFB_Learner" title="Link to this heading">¶</a></h2>
<p>This module contains the core of BFBrain’s training capabilities, in
particular the class BFBLearner, the object which contains the neural
network classifier and methods to execute the active learning training
loop.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.create_seq_network">
<span class="sig-prename descclassname"><span class="pre">bfbrain.BFB_Learner.</span></span><span class="sig-name descname"><span class="pre">create_seq_network</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lam_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">N</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#create_seq_network"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.create_seq_network" title="Link to this definition">¶</a></dt>
<dd><p>Create a sequential Bayesian neural network approximated by
concrete dropout.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lam_len</strong> (<em>int</em>) – The number of quartic coefficients needed to uniquely specify a
potential in the model.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – The number of hidden layers of neurons to include in the model.
Generally recommended to be O(a few)</p></li>
<li><p><strong>n_neurons</strong> (<em>int</em>) – The number of neurons in each dense layer.
Recommended to be O(100).</p></li>
<li><p><strong>l</strong> (<em>float</em>) – The prior length scale parameter of the neural network. Weights
have a prior distribution of N(0, 1/l**2).</p></li>
<li><p><strong>N</strong> (<em>int</em>) – The number of entries in the training data. Needed to determine
the appropriate loss regularization terms in concrete dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Returns a neural network</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.keras.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.BFB_Learner.</span></span><span class="sig-name descname"><span class="pre">AL_history</span></span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#AL_history"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Holds cumulative information about the model performance at each
epoch. An instance of this class is saved as part of the BFBLearner
object.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.losses">
<span class="sig-name descname"><span class="pre">losses</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.losses" title="Link to this definition">¶</a></dt>
<dd><p>Represents the loss values at each training epoch of the neural
network model, calculated over the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list(float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.accuracy">
<span class="sig-name descname"><span class="pre">accuracy</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.accuracy" title="Link to this definition">¶</a></dt>
<dd><p>Represents the binary accuracy at each training epoch of the
neural network model, calculated over the training set.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list(float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.val_losses">
<span class="sig-name descname"><span class="pre">val_losses</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.val_losses" title="Link to this definition">¶</a></dt>
<dd><p>Represents the loss values at each training epoch of the neural
network model, calculated over the validation set. Only tracked
if the validation performance is tracked during the call to
model.fit during training, which the current
BFBrain.BFBLearner.AL_loop method doesn’t do.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list(float)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.val_accuracy">
<span class="sig-name descname"><span class="pre">val_accuracy</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.val_accuracy" title="Link to this definition">¶</a></dt>
<dd><p>Represents the binary accuracy at each training epoch of the
neural network model, calculated over the validation set.
Only tracked if the validation performance is tracked during the
call to model.fit during training, which the current
BFBrain.BFBLearner.AL_loop method doesn’t do.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list(float)</p>
</dd>
</dl>
</dd></dl>

<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>None</strong> – </p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.append_history">
<span class="sig-name descname"><span class="pre">append_history</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">history</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#AL_history.append_history"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.append_history" title="Link to this definition">¶</a></dt>
<dd><p>Merges information from the latest active learning iteration,
extracted from the output of the Tensorflow fit method, into the
AL_history object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>history</strong> (<em>Tensorflow history object</em>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.AL_history.plot_history">
<span class="sig-name descname"><span class="pre">plot_history</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#AL_history.plot_history"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.AL_history.plot_history" title="Link to this definition">¶</a></dt>
<dd><p>Plots the data stored in AL_history.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>filepath</strong> (<em>str</em><em>, </em><em>optional</em>) – If specified, saves the resulting plots as .png images to the
directory named in filepath. If not specified, the method just
displays them on the console.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.BFB_Learner.</span></span><span class="sig-name descname"><span class="pre">BFBLearner</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_train</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data_val</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">history</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rand_fraction</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">idx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l_constant</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Class which controls the active learning loop. Holds the model, the
training and validation data, and some information about the training
so far, and includes methods which perform the training loop and
save the model for further training or exporting.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.dm">
<span class="sig-name descname"><span class="pre">dm</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.dm" title="Link to this definition">¶</a></dt>
<dd><p>The DataManager object that handles the generation and labelling
of new training and validation data.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.Data_Manager.DataManager" title="bfbrain.Data_Manager.DataManager">DataManager</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.model">
<span class="sig-name descname"><span class="pre">model</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.model" title="Link to this definition">¶</a></dt>
<dd><p>The sequential neural network that classifies potentials as
bounded-from-below.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.keras.Sequential</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.data_train">
<span class="sig-name descname"><span class="pre">data_train</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.data_train" title="Link to this definition">¶</a></dt>
<dd><p>The data on which the neural network is trained. Is periodically
augmented during the active learning loop.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data">np_data</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.data_val">
<span class="sig-name descname"><span class="pre">data_val</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.data_val" title="Link to this definition">¶</a></dt>
<dd><p>A separate np_data object on which the neural network performance
can be tested. If metrics doesn’t include any performance metrics
on validation data, this should be None.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data">np_data</a> or None</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.metrics">
<span class="sig-name descname"><span class="pre">metrics</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.metrics" title="Link to this definition">¶</a></dt>
<dd><p>A list of objects which inherit from the abstract class ALMetric.
These will represent the performance metrics that are tracked
over each active learning iteration.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list(BFBrain.ALMetric)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.history">
<span class="sig-name descname"><span class="pre">history</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.history" title="Link to this definition">¶</a></dt>
<dd><p>An AL_history object which tracks the training loss and binary
accuracy over each epoch.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.BFB_Learner.AL_history" title="bfbrain.BFB_Learner.AL_history">AL_history</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.learning_rate">
<span class="sig-name descname"><span class="pre">learning_rate</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.learning_rate" title="Link to this definition">¶</a></dt>
<dd><p>The learning rate used for the Adam optimizer during neural
network training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.hop_dist">
<span class="sig-name descname"><span class="pre">hop_dist</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.hop_dist" title="Link to this definition">¶</a></dt>
<dd><p>The distance scale used to generate new training points in the
vicinity of existing bounded-from-below points, given as the
hop_dist argument to DataManager’s generate_L function.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.rand_fraction">
<span class="sig-name descname"><span class="pre">rand_fraction</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.rand_fraction" title="Link to this definition">¶</a></dt>
<dd><p>The percentage of points generated by DataManager’s generate_L
function that are randomly sampled instead of sampled in the
vicinity of positively labelled points.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.idx">
<span class="sig-name descname"><span class="pre">idx</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.idx" title="Link to this definition">¶</a></dt>
<dd><p>The number of active learning rounds that the model has completed.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.l_constant">
<span class="sig-name descname"><span class="pre">l_constant</span></span><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.l_constant" title="Link to this definition">¶</a></dt>
<dd><p>The prior length scale for the neural network weights. The neural
network is constructed so that the prior distribution on the
weights is N(0, 1/l**2).</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.init_for_first_run">
<span class="sig-name descname"><span class="pre">init_for_first_run</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.init_for_first_run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.init_for_first_run" title="Link to this definition">¶</a></dt>
<dd><p>The recommended constructor for initializing a BFBLearner object
from scratch.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.from_file">
<span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.from_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.from_file" title="Link to this definition">¶</a></dt>
<dd><p>The constructor for loading a saved BFBLearner object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.save_AL_state">
<span class="sig-name descname"><span class="pre">save_AL_state</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.save_AL_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.save_AL_state" title="Link to this definition">¶</a></dt>
<dd><p>Used to save the BFBLearner object.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.redefine_model">
<span class="sig-name descname"><span class="pre">redefine_model</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.redefine_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.redefine_model" title="Link to this definition">¶</a></dt>
<dd><p>Used to replace the neural network with a new one (for example
adjusting weight priors, or changing the number
of hidden neurons/layers). A use case would be generating a single
BFBLearner object with a large labelled validation set, saving
the object with an untrained neural network, and then loading
the object in different contexts to experiment with different
neural network architectures and hyperparameters.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.set_l_constant">
<span class="sig-name descname"><span class="pre">set_l_constant</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.set_l_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.set_l_constant" title="Link to this definition">¶</a></dt>
<dd><p>Sets l_constant to a new value. Same use case as redefine_model.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.add_metrics">
<span class="sig-name descname"><span class="pre">add_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.add_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.add_metrics" title="Link to this definition">¶</a></dt>
<dd><p>Adds new children of the ALMetric class to the BFBLearner object.
Use this method rather than directly appending objects to the
metrics attribute, since otherwise errors can occur, for example
from adding a metric which requires a validation data set when
the BFBLearner object had no previous validation data set.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.plot_metrics">
<span class="sig-name descname"><span class="pre">plot_metrics</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.plot_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.plot_metrics" title="Link to this definition">¶</a></dt>
<dd><p>Creates simple plots of all the metrics recorded in metrics.
Useful to get a quick visual sense of the performance of the
model after active learning finishes.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.AL_loop">
<span class="sig-name descname"><span class="pre">AL_loop</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.AL_loop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.AL_loop" title="Link to this definition">¶</a></dt>
<dd><p>The core active learning function. Executes the active learning
loop to train the classifier. Highly customizable.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id0">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.from_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id0" title="Link to this definition">¶</a></dt>
<dd><p>A constructor which loads an instance of BFBLearner from
a folder.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>directory</strong> (<em>str</em>) – Should denote a directory into which a previous BFBLearner
object was saved.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id1">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">init_for_first_run</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">dm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nlams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nlams_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rand_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_dist</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l_constant</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth_label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">use_truth_for_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">balance_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.init_for_first_run"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id1" title="Link to this definition">¶</a></dt>
<dd><p>The recommended constructor when not loading a saved
BFBLearner object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>dm</strong> (<a class="reference internal" href="#bfbrain.Data_Manager.DataManager" title="bfbrain.Data_Manager.DataManager"><em>DataManager</em></a>) – The DataManager object that will handle the generation and
processing of training and validation data.</p></li>
<li><p><strong>n_layers</strong> (<em>int</em>) – The number of layers of hidden layers in the neural network.</p></li>
<li><p><strong>n_neurons</strong> (<em>int</em>) – The number of neurons in each hidden layer.</p></li>
<li><p><strong>metrics</strong> (<em>list</em><em>(</em><em>BFBrain.ALMetric</em><em>)</em>) – A list of objects which inherit from the abstract class
ALMetric. These will represent the performance metrics that
are tracked over each active learning iteration.</p></li>
<li><p><strong>nlams</strong> (<em>int</em>) – The number of sets of quartic potential coefficients to
generate to produce the initial training data.</p></li>
<li><p><strong>nlams_val</strong> (<em>int</em><em>, </em><em>optional</em>) – The number of sets of quartic potential coefficients to
generate to produce the validation data. If not specified,
the value 100*nlams is used.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>default=0.001</em>) – The learning rate used for the Adam optimizer during neural
network training.</p></li>
<li><p><strong>rand_fraction</strong> (<em>float</em><em>, </em><em>default=0.</em>) – The percentage of points generated by DataManager’s generate_L
function that are randomly sampled instead of sampled in the
vicinity of positively labelled points.</p></li>
<li><p><strong>hop_dist</strong> (<em>float</em><em>, </em><em>optional</em>) – The distance scale used to generate new training points in the
vicinity of existing bounded-from-below points, given as the
hop_dist argument to DataManager’s generate_L function.
If not specified, the value is estimated using
BFBrain.Active_Learning._get_hop_dist</p></li>
<li><p><strong>l_constant</strong> (<em>float</em><em>, </em><em>default=0.1</em>) – The prior length scale for the neural network weights. The
neural network is constructed so that the prior distribution
on the weights is N(0, 1/l**2).</p></li>
<li><p><strong>truth_label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – Must take a 1-D NumPy array representing a single set of
quartic coefficients and return a Boolean True if the
potential they describe is bounded from below, False otherwise.
If this argument is specified, the method will use this
callable to label the validation data set instead of
DataManager’s oracle, and if use_truth_for_train is True, then
it will also use this function to label the initial training
data. This is used in specific instances when a fast symbolic
expression for the bounded-from-below constraints is known,
and the performance of the classifier training loop can be
evaluated in the absence of noise due to the approximate
labeller. Obviously the use case of the classifier is for
potentials where such a symbolic expression is NOT known, so
the real-world model building usefulness of this option
is limited.</p></li>
<li><p><strong>use_truth_for_train</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, use truth_label_fn to label the initial training data
instead of the DataManager’s oracle function. Has no effect
unless truth_label_fn is specified.</p></li>
<li><p><strong>val_label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – An alternate set of keyword arguments for the oracle that can
be specified when labelling the validation data instead of
using the settings in the DataManager object. Useful if,
for example, a less expensive oracle can be used for the
validation labelling than for labelling the training data, or
if trying to gauge the effect of using a noisier oracle
during training while still verifying performance with
reliably labelled validation data.</p></li>
<li><p><strong>balance_val</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, balance the validation data set between positive and
negative examples using DataManager’s balance_array method,
making binary accuracy of the classifier more informative at
the cost of rendering the generating distribution for the
validation data considerably more opaque. Generally
recommended to leave False, since other performance metrics,
such as F score, can help gauge the classifier performance
without needing to rebalance the validation data.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id2">
<span class="sig-name descname"><span class="pre">set_l_constant</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">l_constant</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.set_l_constant"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id2" title="Link to this definition">¶</a></dt>
<dd><p>Sets the weight prior length scale l to a new value and updates
the network to reflect it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>l_constant</strong> (<em>float</em>) – The new value for the class attribute l_constant, the weight
prior length scale.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id3">
<span class="sig-name descname"><span class="pre">save_AL_state</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">directory</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.save_AL_state"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id3" title="Link to this definition">¶</a></dt>
<dd><p>A method for saving all the relevant states for the BFBLearner
object in a directory for later retrieval.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>directory</strong> (<em>str</em>) – A string denoting a directory to which the data needed to
reconstruct the BFBLearner object will be saved.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id4">
<span class="sig-name descname"><span class="pre">redefine_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_layers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_neurons</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.redefine_model"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id4" title="Link to this definition">¶</a></dt>
<dd><p>A method for redefining the parameters of the neural network.
Should ONLY be called if the neural network is entirely untrained.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_layers</strong> (<em>int</em>) – The number of hidden layers of neurons to include in the
model. Generally recommended to be O(a few).</p></li>
<li><p><strong>n_neurons</strong> (<em>int</em>) – The number of neurons in each hidden layer.
Recommended to be O(100).</p></li>
<li><p><strong>l</strong> (<em>float</em><em>, </em><em>optional</em>) – The prior length scale parameter of the neural network.
Weights have a prior distribution of N(0, 1/l**2).
If l isn’t specified, the BFBLearner object’s current
value for the parameter is used.</p></li>
<li><p><strong>learning_rate</strong> (<em>float</em><em>, </em><em>default=0.001</em>) – The learning rate of the Adam optimizer for neural network
training.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id5">
<span class="sig-name descname"><span class="pre">add_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">metrics</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nlams_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.add_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id5" title="Link to this definition">¶</a></dt>
<dd><p>add new metrics to the BFBLearner instance after
initialization. Appends any metric or list of metrics specified
to self.metrics. If an added metric involves measuring the
classifier performance on a validation set, and the ActiveLearning
instance doesn’t have a validation set yet, this method will
generate one.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>metrics</strong> (<a class="reference internal" href="#bfbrain.AL_Metrics.ALMetric" title="bfbrain.AL_Metrics.ALMetric"><em>ALMetric</em></a><em> or </em><em>list</em><em> of </em><em>ALMetrics</em>) – A metric or list of objects which inherit from the
BFBrain.ALMetric abstract class.</p></li>
<li><p><strong>nlams_val</strong> (<em>int</em><em>, </em><em>default=100000</em>) – The number of points to be created and labelled to produce a
validation set, if a new validation set needs to be generated.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id6">
<span class="sig-name descname"><span class="pre">plot_metrics</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.plot_metrics"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id6" title="Link to this definition">¶</a></dt>
<dd><p>A method to plot all metrics being recorded in the
BFBLearner’s metrics object.</p>
<section id="parameter">
<h3>Parameter<a class="headerlink" href="#parameter" title="Link to this heading">¶</a></h3>
<dl class="simple">
<dt>filepath<span class="classifier">str, optional</span></dt><dd><p>If specified, the method will save the plots to the folder
specified in filepath (provided that folder exists). If not
specified, simply prints the plots to the console.</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.BFB_Learner.BFBLearner.get_calibration_uncertainties">
<span class="sig-name descname"><span class="pre">get_calibration_uncertainties</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">score_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nlams</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.get_calibration_uncertainties"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.BFB_Learner.BFBLearner.get_calibration_uncertainties" title="Link to this definition">¶</a></dt>
<dd><p>A function which gets a sense of the range of uncertainty
values (and what constitutes a highly uncertain point). It does
this by creating a large sample of unlabelled data points by
uniformly sampling the unit hypersphere, and getting the outputs
of a specified uncertainty score over the points in the
distribution which the model predicts to be positive.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Either a string which denotes which of the implemented
strategies for scoring points to add to the training set to
employ, or a callable representing a custom function to
perform this role. Any custom functions must have a signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether n_trials is specified or not. The string
inputs correspond to scoring based on, in order:
Mutual information, Shannon entropy, variation ratios, a
random score, query by dropout committee (QBDC), and standard
deviation of the neural network predictions.</p></li>
<li><p><strong>nlams</strong> (<em>int</em><em>, </em><em>default=1000000</em>) – The number of sets of quartic potential coefficients that the
method should generate</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>optional</em>) – Many of the implemented score_fn methods (‘BALD’,
‘MaxEntropy’, ‘variation_ratios’, ‘QBDC’, and
‘predictive_variance’) have an optional argument controlling
the number of forward passes through the network to compute
their values. This parameter allows this value to be specified
for score_fn’s evaluations.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default=200000</em>) – The size of batches of the elements of lams that are
transferred to the GPU simultaneously.
If OOM errors are encountered, it is recommended to reduce
batch_size.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="id7">
<span class="sig-name descname"><span class="pre">AL_loop</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">filepath</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'saved_AL'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">500</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K_batch_num</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">K_factor</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'BALD'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">nstop</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">full_train_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epoch_limit</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">200000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">val_batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">-1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_interval</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stopping_cond</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_score_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth_label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">score_ntrials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">prob_score_ntrials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">reinitialize_weights</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rebalance_train_data</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">L_probability_weighting</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">plot_metrics</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/BFB_Learner.html#BFBLearner.AL_loop"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#id7" title="Link to this definition">¶</a></dt>
<dd><p>The core function for the active learning loop. Performs active
learning for a specified number of rounds with a customizable
query strategy and a number of options exposed to the user.
BFBrain analysis principally consist of execution(s) of this
method to train the BFBLearner’s classifier.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filepath</strong> (<em>str</em><em>, </em><em>default='saved_AL'</em>) – A string describing the name of a directory (which will be
created, if it doesn’t exist) into which the Active_Learning
object will be saved after training.</p></li>
<li><p><strong>K_batch_size</strong> (<em>int</em><em>, </em><em>default=500</em>) – Additional training data, called K, is generated in batches
of K_batch_size entries. After each cycle of training,
K_batch_num batches, each with K_batch_size entries, are
generated and added to the training data.</p></li>
<li><p><strong>K_batch_num</strong> (<em>int</em><em>, </em><em>default 10</em>) – The number of batches, of batch_size K_batch_size, of
additional training data that is generated after each cycle
of training.</p></li>
<li><p><strong>K_factor</strong> (<em>int</em><em>, </em><em>default 100</em>) – To generate each batch of K_batch_size entries,
K_factor*K_batch_size candidate points are generated and the
top K_batch_size points are selected to be added to K.</p></li>
<li><p><strong>score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Either a string which denotes which of the implemented
strategies for scoring points to add to the training set to
employ, or a callable representing a custom function to
perform this role. Any custom functions must have a signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether score_ntrials is specified or not. The
string inputs correspond to scoring based on, in order:
Mutual information, Shannon entropy, variation ratios, a
random score, expected gradient length,
query by dropout committee (QBDC), and variance of the
neural network predictions.</p></li>
<li><p><strong>nstop</strong> (<em>int</em><em>, </em><em>default=20</em>) – The number of total cycles (generating new training data,
fitting the neural network to the training data, and recording
metrics) to perform.</p></li>
<li><p><strong>full_train_interval</strong> (<em>int</em><em>, </em><em>default=1</em>) – The active learning function will train over the entire
training data set every full_train_interval cycles.
Otherwise, it will only train the network on the most
recently generated set of new training data, for a much
smaller number of epochs. Recommended setting is 1, so that
dropout approximation to a Bayesian neural network holds
rigorously.</p></li>
<li><p><strong>epoch_patience</strong> (<em>int</em><em>, </em><em>default=100</em>) – A parameter for the training in individual cycles. The
neural network will stop training early in each cycle if
the network’s performance on the validation data has not
improved for epoch_patience epochs.</p></li>
<li><p><strong>epoch_limit</strong> (<em>int</em><em>, </em><em>default=20000</em>) – The maximum number of epochs for the neural network to
train each cycle.</p></li>
<li><p><strong>batch_size</strong> (<em>int</em><em>, </em><em>default=200000</em>) – The size of batches of training data that are transferred to
the GPU simultaneously. If OOM errors are encountered, it is
recommended to reduce batch_size. Some discussion of batch
size is in order. We find that for greatest training
stability, it is best to have a batch_size larger than the
maximum number of training examples that will be included
in an active learning iteration– so for starting at 1000
initial points, with 5000 points added at each iteration
and 20 iterations executed, a batch_size &gt; 101000 may be
recommended. This will maximize training stability. However,
if instead more training examples must be considered than can
realistically fit into GPU memory, we recommend batch_size
parameters of approximately the number of points added during
each active learning iteration, to avoid different active
learning iterations suddenly exhibiting radically different
performance as the number of batches abruptly changes for
the first time late into active learning. Experimentation
regarding small batch size for different potentials is
recommended.</p></li>
<li><p><strong>val_batch_size</strong> (<em>int</em><em>, </em><em>optional</em>) – The size of batches of validation data that are transferred
to the GPU simultaneously. May be useful if small batches
are used for training, but much larger batches can be
accomodated during validation. If not specified, batch_size
will be used to batch the validation data.</p></li>
<li><p><strong>save_interval</strong> (<em>int</em><em>, </em><em>default=5</em>) – Every save_interval active learning iterations, the function
will save the BFBLearner object to the directory specified
in filepath.</p></li>
<li><p><strong>stopping_cond</strong> (<em>BFBrain.StoppingCondition object</em><em> or </em><em>subclass</em>) – This object allows a user to specify conditions under which
active learning should terminate before nstop iterations
have been performed. See the BFBrain.StoppingCondition
documentation for more details.</p></li>
<li><p><strong>prob_score_fn</strong> (<em>{'BALD'</em><em>, </em><em>'MaxEntropy'</em><em>, </em><em>'variation_ratios'</em><em>, </em><em>'random'</em><em>, </em><em>'QBDC'</em><em>, </em><em>'predictive_variance'}</em><em> or </em><em>callable</em>) – Either a string which denotes which of the implemented
strategies for scoring points to add to the training set,
or a callable representing a custom function to perform this
role. Any custom functions must have a signature
(tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)
or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),
depending on whether score_ntrials is specified or not.
Unlike score_fn, this function is employed when weighting
points to sample around to generate new training data, so that
an algorithm might preferentially sample around points with
high mutual information (with prob_score_fn = ‘BALD’), but
decide which points to add to the training set based on
Shannon entropy (score_fn = ‘MaxEntropy’), for example.
Has no effect if L_probability_weighting is False.</p></li>
<li><p><strong>truth_label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – If a callable, must take a 1-D NumPy array representing a
single set of quartic coefficients and return a Boolean True
if the potential they describe is bounded from below, False
otherwise. If specified, training data will be labelled using
this callable instead of the oracle in the DataManager object.</p></li>
<li><p><strong>score_ntrials</strong> (<em>int</em><em>, </em><em>optional</em>) – Many of the implemented score_fn methods (‘BALD’, ‘MaxEntropy’, ‘variation_ratios’, ‘QBDC’, and ‘predictive_variance’) have an optional argument controlling the number of forward passes
through the network to compute their values. This parameter
allows this value to be specified for score_fn’s evaluations.</p></li>
<li><p><strong>prob_score_ntrials</strong> (<em>int</em><em>, </em><em>optional</em>) – Same as score_ntrials, but for prob_score_fn. Does not have
any effect if prob_score_fn is not specified.</p></li>
<li><p><strong>reinitialize_weights</strong> (<em>bool</em><em>, </em><em>default=True</em>) – If True, randomize the neural network weights before each new
round of active learning (unless the algorithm is not training
on the full training data set– see full_train_interval).
The recommended setting is True, to prevent potential
overfitting on the points sampled earlier and maintain the
dropout approximation of the Bayesian neural network
rigorously.</p></li>
<li><p><strong>rebalance_train_data</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, the training set will be rebalanced every iteration
by adding new bounded from below points to correct an
overabundance of points which are not bounded from below.</p></li>
<li><p><strong>L_probability_weighting</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, the selection of existing bounded-from-below training
points to sample around for generating new points will be
weighted based on prob_score_fn.</p></li>
<li><p><strong>plot_metrics</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, all metrics will be plotted in the command line as
well as saved to the output filepath when training completes.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, print out information about the progress and
performance of the active learning loop throughout the run
to the console. Otherwise data on the neural network
performance after each iteration is still saved to a file
‘output.txt’ in the filepath directory.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-bfbrain.Custom_Layers">
<span id="bfbrain-custom-layers-module"></span><h2>bfbrain.Custom_Layers module<a class="headerlink" href="#module-bfbrain.Custom_Layers" title="Link to this heading">¶</a></h2>
<p>This module contains the various neural network layers used by BFBrain.</p>
<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.HypersphereProjectionLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.Custom_Layers.</span></span><span class="sig-name descname"><span class="pre">HypersphereProjectionLayer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#HypersphereProjectionLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.HypersphereProjectionLayer" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Layer</span></code></p>
<p>A custom neural network preprocessing layer which projects any
input quartic coefficients onto the unit hypersphere.</p>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.HypersphereProjectionLayer.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#HypersphereProjectionLayer.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.HypersphereProjectionLayer.build" title="Link to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call. It is invoked automatically before
the first execution of <cite>call()</cite>.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses
(at the discretion of the subclass implementer).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.HypersphereProjectionLayer.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#HypersphereProjectionLayer.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.HypersphereProjectionLayer.get_config" title="Link to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.HypersphereProjectionLayer.from_config">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_config</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#HypersphereProjectionLayer.from_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.HypersphereProjectionLayer.from_config" title="Link to this definition">¶</a></dt>
<dd><p>Creates a layer from its config.</p>
<p>This method is the reverse of <cite>get_config</cite>,
capable of instantiating the same layer from the config
dictionary. It does not handle layer connectivity
(handled by Network), nor weights (handled by <cite>set_weights</cite>).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> – A Python dictionary, typically the
output of get_config.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A layer instance.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.HypersphereProjectionLayer.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#HypersphereProjectionLayer.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.HypersphereProjectionLayer.call" title="Link to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first
invocation, wrapping the creation of variables or other resources in
<cite>tf.init_scope()</cite>).  It is recommended to create state, including
<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>
<blockquote>
<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>
</div></blockquote>
<p>called automatically before <cite>call()</cite> executes for the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as
tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite>
only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask
generated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come
from a layer that generated a corresponding mask, i.e. if it came
from a Keras layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.get_weight_regularizer">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Custom_Layers.</span></span><span class="sig-name descname"><span class="pre">get_weight_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">l</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.01</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#get_weight_regularizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.get_weight_regularizer" title="Link to this definition">¶</a></dt>
<dd><p>Determines the weight decay constant which should be applied in the
loss function with a given precision, prior length scale, and number
of training data points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – The number of data points in the training data.</p></li>
<li><p><strong>l</strong> (<em>float</em><em>, </em><em>default=1e-2</em>) – </p></li>
<li><p><strong>tau</strong> (<em>float</em><em>, </em><em>defulat = 0.1</em>) – neural network precision. For classification networks this is just
set to 1.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.get_dropout_regularizer">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Custom_Layers.</span></span><span class="sig-name descname"><span class="pre">get_dropout_regularizer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">N</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tau</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cross_entropy_loss</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#get_dropout_regularizer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.get_dropout_regularizer" title="Link to this definition">¶</a></dt>
<dd><p>Controls the regularization term associated with the entropy
of the cells’ dropout probabilities.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>N</strong> (<em>int</em>) – The number of data points in the training data.</p></li>
<li><p><strong>tau</strong> (<em>float</em><em>, </em><em>defulat = 0.1</em>) – neural network precision. For classification networks this is just
set to 1.</p></li>
<li><p><strong>cross_entropy_loss</strong> (<em>bool</em><em>, </em><em>default=False</em>) – Should be True if the loss function is cross entropy (so the
neural network is a classifier), and False otherwise.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.ConcreteDenseDropout">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.Custom_Layers.</span></span><span class="sig-name descname"><span class="pre">ConcreteDenseDropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#ConcreteDenseDropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.ConcreteDenseDropout" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Dense</span></code></p>
<p>Code for the implementation of concrete dropout. Based
heavily on <a class="reference external" href="https://github.com/aurelio-amerio/ConcreteDropout">https://github.com/aurelio-amerio/ConcreteDropout</a>,
a Tensorflow 2.0 implementation of the concrete dropout algorithm
described in arXiv:1705.07832. Modified from that implementation in
order to save the model more easily at the expense of some
flexibility. IMPORTANT: these layers perform dropout BEFORE the
wrapped operation.</p>
<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.ConcreteDenseDropout.build">
<span class="sig-name descname"><span class="pre">build</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_shape</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#ConcreteDenseDropout.build"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.ConcreteDenseDropout.build" title="Link to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call. It is invoked automatically before
the first execution of <cite>call()</cite>.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses
(at the discretion of the subclass implementer).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.ConcreteDenseDropout.spatial_concrete_dropout">
<span class="sig-name descname"><span class="pre">spatial_concrete_dropout</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">p</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#ConcreteDenseDropout.spatial_concrete_dropout"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.ConcreteDenseDropout.spatial_concrete_dropout" title="Link to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.ConcreteDenseDropout.call">
<span class="sig-name descname"><span class="pre">call</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">inputs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">training</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#ConcreteDenseDropout.call"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.ConcreteDenseDropout.call" title="Link to this definition">¶</a></dt>
<dd><p>This is where the layer’s logic lives.</p>
<p>The <cite>call()</cite> method may not create state (except in its first
invocation, wrapping the creation of variables or other resources in
<cite>tf.init_scope()</cite>).  It is recommended to create state, including
<cite>tf.Variable</cite> instances and nested <cite>Layer</cite> instances,</p>
<blockquote>
<div><p>in <cite>__init__()</cite>, or in the <cite>build()</cite> method that is</p>
</div></blockquote>
<p>called automatically before <cite>call()</cite> executes for the first time.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>inputs</strong> – <p>Input tensor, or dict/list/tuple of input tensors.
The first positional <cite>inputs</cite> argument is subject to special rules:
- <cite>inputs</cite> must be explicitly passed. A layer cannot have zero</p>
<blockquote>
<div><p>arguments, and <cite>inputs</cite> cannot be provided via the default value
of a keyword argument.</p>
</div></blockquote>
<ul>
<li><p>NumPy array or Python scalar values in <cite>inputs</cite> get cast as
tensors.</p></li>
<li><p>Keras mask metadata is only collected from <cite>inputs</cite>.</p></li>
<li><p>Layers are built (<cite>build(input_shape)</cite> method)
using shape info from <cite>inputs</cite> only.</p></li>
<li><p><cite>input_spec</cite> compatibility is only checked against <cite>inputs</cite>.</p></li>
<li><p>Mixed precision input casting is only applied to <cite>inputs</cite>.
If a layer has tensor arguments in <cite>*args</cite> or <cite>**kwargs</cite>, their
casting behavior in mixed precision should be handled manually.</p></li>
<li><p>The SavedModel input specification is generated using <cite>inputs</cite>
only.</p></li>
<li><p>Integration with various ecosystem packages like TFMOT, TFLite,
TF.js, etc is only supported for <cite>inputs</cite> and not for tensors in
positional and keyword arguments.</p></li>
</ul>
</p></li>
<li><p><strong>*args</strong> – Additional positional arguments. May contain tensors, although
this is not recommended, for the reasons above.</p></li>
<li><p><strong>**kwargs</strong> – <p>Additional keyword arguments. May contain tensors, although
this is not recommended, for the reasons above.
The following optional keyword arguments are reserved:
- <cite>training</cite>: Boolean scalar tensor of Python boolean indicating</p>
<blockquote>
<div><p>whether the <cite>call</cite> is meant for training or inference.</p>
</div></blockquote>
<ul>
<li><p><cite>mask</cite>: Boolean input mask. If the layer’s <cite>call()</cite> method takes a
<cite>mask</cite> argument, its default value will be set to the mask
generated for <cite>inputs</cite> by the previous layer (if <cite>input</cite> did come
from a layer that generated a corresponding mask, i.e. if it came
from a Keras layer with masking support).</p></li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A tensor or list/tuple of tensors.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Custom_Layers.ConcreteDenseDropout.get_config">
<span class="sig-name descname"><span class="pre">get_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Custom_Layers.html#ConcreteDenseDropout.get_config"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Custom_Layers.ConcreteDenseDropout.get_config" title="Link to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<p>Note that <cite>get_config()</cite> does not guarantee to return a fresh copy of
dict every time it is called. The callers should make a copy of the
returned dict if they want to modify it.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-bfbrain.Data_Manager">
<span id="bfbrain-data-manager-module"></span><h2>bfbrain.Data_Manager module<a class="headerlink" href="#module-bfbrain.Data_Manager" title="Link to this heading">¶</a></h2>
<p>A module containing the DataManager class, which handles the generation
and labelling of training and validation data for the BFBLearner class.</p>
<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.Data_Manager.</span></span><span class="sig-name descname"><span class="pre">labeller_wrapper</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">{'niter':</span> <span class="pre">250}</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#labeller_wrapper"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Wrapper for the labelling function which serves as the active
learning oracle.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.func">
<span class="sig-name descname"><span class="pre">func</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.func" title="Link to this definition">¶</a></dt>
<dd><p>A numeric function for the potential. This is a numeric function
generated by the class DataManager in its init method. It will
take numeric arrays (of a format depending on the DataManager
class) representing a scalar vev and a set of quartic potential
coefficients and return the numerical value of the quartic part
of the potential function and its gradient with respect to the vev.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.phi_len">
<span class="sig-name descname"><span class="pre">phi_len</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.phi_len" title="Link to this definition">¶</a></dt>
<dd><p>The number of real parameters necessary to uniquely specify a vev
in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.lam_len">
<span class="sig-name descname"><span class="pre">lam_len</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.lam_len" title="Link to this definition">¶</a></dt>
<dd><p>The number of independent real quartic coefficients in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.rng">
<span class="sig-name descname"><span class="pre">rng</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.rng" title="Link to this definition">¶</a></dt>
<dd><p>The random number generator which governs any random processes
that the oracle may use.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.random.Generator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.polar">
<span class="sig-name descname"><span class="pre">polar</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.polar" title="Link to this definition">¶</a></dt>
<dd><p>If True, then the analysis of the potential will be conducted with
a polar coordinate parameterization of the vev parameters.
If False, then Cartesian coordinates will be used, albeit with the
vev parameters restricted to a phi_len-dimensional unit
hypersphere.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.label_fn">
<span class="sig-name descname"><span class="pre">label_fn</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.label_fn" title="Link to this definition">¶</a></dt>
<dd><p>A function that takes a 2-D NumPy array of quartic coefficients
and returns a list of Boolean labels for them. This is for
implementing customized oracle functions. Must have the signature
(func: Callable, phi_len: int, polar: bool, rng: NumpyGenerator, lam: np.array(np.float, np.float), <a href="#id8"><span class="problematic" id="id9">**</span></a>kwargs) -&gt; np.array(bool)
If this argument is not specified, the default oracle
BFBrain.Jax_Oracle.label_func is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable, optional.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.label_check">
<span class="sig-name descname"><span class="pre">label_check</span></span><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.label_check" title="Link to this definition">¶</a></dt>
<dd><p>A function that can be used to test the reliability of a custom
oracle given by label_fn, or if label_fn is None, the default
oracle BFBrain.Jax_Oracle.label_func. Must have the same signature
as label_fn, up to additional keyword arguments. If this argument
is not specified, the a tester for the default oracle is used:
BFBrain.Jax_Oracle.test_labeller</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">\*\*label_kwargs</span></span></dt>
<dd><p>A dictionary of additional keyword arguments needed for the
labelling function label_func. The default values are applicable
for the default oracle function, BFBrain.Jax_Oracle.label_func</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict, default=dict(niter = 250)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.do_labelling">
<span class="sig-name descname"><span class="pre">do_labelling</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#labeller_wrapper.do_labelling"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.do_labelling" title="Link to this definition">¶</a></dt>
<dd><p>Performs labelling using the class’s oracle function.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lam</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of sets of quartic potential coefficients.</p></li>
<li><p><strong>label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – An optional alternative set of oracle keyword arguments. If
not specified, the class instance’s label_kwargs
attribute is used.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D NumPy array of labels for lam, for which points that
are bounded from below are labelled “True” and points which
are not are labelled “False”.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.labeller_wrapper.check_labeller">
<span class="sig-name descname"><span class="pre">check_labeller</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tester_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#labeller_wrapper.check_labeller"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.labeller_wrapper.check_labeller" title="Link to this definition">¶</a></dt>
<dd><p>Tests the reliability of the labelling– calls
self.label_check. Depending on the methodology of label_func,
this function may or may not be useful. For example, a rigorous
computation of boundedness-from-below based on resultants would
not require any consistency or reliability checks.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lam</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of sets of quartic potential coefficients.</p></li>
<li><p><strong>tester_kwargs</strong> (<em>dict</em>) – A set of keyword arguments for self.label_check.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Will return what self.label_check returns.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.Data_Manager.</span></span><span class="sig-name descname"><span class="pre">np_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">pos</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">neg</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#np_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.np_data" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Holds labelled sets of quartic coefficients in CPU memory in a
format that’s easy to save, load, and manipulate.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.pos">
<span class="sig-name descname"><span class="pre">pos</span></span><a class="headerlink" href="#bfbrain.Data_Manager.np_data.pos" title="Link to this definition">¶</a></dt>
<dd><p>A 2-D NumPy array of sets of quartic coefficients in the
potential, which the labeller has determined are
bounded-from-below.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.neg">
<span class="sig-name descname"><span class="pre">neg</span></span><a class="headerlink" href="#bfbrain.Data_Manager.np_data.neg" title="Link to this definition">¶</a></dt>
<dd><p>A 2-D NumPy array of sets of quartic coefficients in the
potential, which the labeller has determined are NOT
bounded-from-below.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.from_file">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_file</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#np_data.from_file"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.np_data.from_file" title="Link to this definition">¶</a></dt>
<dd><p>A constructor for loading an np_data object from a .npz file
(see NumPy documentation), likely created in a previous BFBrain
analysis.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – A string with a file name. ‘.npz’ is appended to the end of
the string, and should not be included in path.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data">np_data</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.save_data">
<span class="sig-name descname"><span class="pre">save_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#np_data.save_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.np_data.save_data" title="Link to this definition">¶</a></dt>
<dd><p>Saves the data object to the filepath specified as an npz
object (see NumPy documentation)</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>path</strong> (<em>str</em>) – A string with a file name. If .npz is not at the end of the
string, it is appended to it.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.append_data">
<span class="sig-name descname"><span class="pre">append_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">new_data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#np_data.append_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.np_data.append_data" title="Link to this definition">¶</a></dt>
<dd><p>Given another np_data object, appends its data to this
object in place.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>new_data</strong> (<a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data"><em>np_data</em></a>) – </p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.np_data.n_elements">
<span class="sig-name descname"><span class="pre">n_elements</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#np_data.n_elements"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.np_data.n_elements" title="Link to this definition">¶</a></dt>
<dd><p>Computes the total number of sets of quartic coefficients in
the object (both bounded-from-below and not bounded-from-below)</p>
<dl class="field-list simple">
<dt class="field-odd">Returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>The total number of sets of quartic coefficients in the
np_data object.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>int</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">bfbrain.Data_Manager.</span></span><span class="sig-name descname"><span class="pre">DataManager</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sym_expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sym_grad_expr</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phisym_var</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamsym</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdify_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'jax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">label_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager" title="Link to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>A class containing methods which process and generate data.
Note that this class contains all the random number generation that’s
not specifically associated with the neural network and its optimizer.
Generally one should use the ‘from_seed’ or ‘from_file’ constructor
rather than constructing from the base initialization method.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.phi_len">
<span class="sig-name descname"><span class="pre">phi_len</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.phi_len" title="Link to this definition">¶</a></dt>
<dd><p>The number of independent real parameters needed to uniquely
specify a vev in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.lam_len">
<span class="sig-name descname"><span class="pre">lam_len</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.lam_len" title="Link to this definition">¶</a></dt>
<dd><p>The number of independent real quartic potential coefficients
in the model.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.rng">
<span class="sig-name descname"><span class="pre">rng</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.rng" title="Link to this definition">¶</a></dt>
<dd><p>A list of NumPy random number generators which control all the
random generation related to the generation and labelling of data.
In total there are 6 random number generators, each differently
seeded using NumPy’s SeedSequence.spawn method. Each random number
generator is used only for one specific task: Generating training
data, generating validation data, generating random points in the
vicinity of other points (two rng’s are used here, one for
rotation direction and the other for rotation angle),
doing random number generation associated with labelling, and
shuffling data for training.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>list of numpy.random.Generator</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.polar">
<span class="sig-name descname"><span class="pre">polar</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.polar" title="Link to this definition">¶</a></dt>
<dd><p>If true, the potential is analyzed with the vev coordinates
converted to a polar form. If false, they are analyzed in their
Cartesian form.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>bool</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.sym_expr">
<span class="sig-name descname"><span class="pre">sym_expr</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.sym_expr" title="Link to this definition">¶</a></dt>
<dd><p>Represents the potential function in a form that is both picklable
and can easily be used to generate the gradient symbolically.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>SymPy expression</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.sym_grad_expr">
<span class="sig-name descname"><span class="pre">sym_grad_expr</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.sym_grad_expr" title="Link to this definition">¶</a></dt>
<dd><p>Represents the gradient of the potential function in a form that
is both picklable and can easily be used to generate the gradient
symbolically.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>SymPy expression</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.phisym_var">
<span class="sig-name descname"><span class="pre">phisym_var</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.phisym_var" title="Link to this definition">¶</a></dt>
<dd><p>The symbols representing the quartic potential coefficients in
sym_expr.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>sympy.Array</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.lamsym">
<span class="sig-name descname"><span class="pre">lamsym</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.lamsym" title="Link to this definition">¶</a></dt>
<dd><p>The symbols representing the quartic potential coefficients in
sym_expr.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>sympy.Array</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.lambdify_mode">
<span class="sig-name descname"><span class="pre">lambdify_mode</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.lambdify_mode" title="Link to this definition">¶</a></dt>
<dd><p>Passed directly as the argument “modules” in sympy.lambdify, the
function used to generate numerical functions from the symbolic
expression for the scalar potential. Default value is ‘jax’,
consistent with the default oracle function,
BFBrain.Jax_Oracle.label_func</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>{‘jax’, ‘numpy’, ‘scipy’, ‘math’, ‘mpmath’, ‘numexpr’, ‘sympy’, ‘tensorflow’}</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.label_fn">
<span class="sig-name descname"><span class="pre">label_fn</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.label_fn" title="Link to this definition">¶</a></dt>
<dd><p>A function that takes a 2-D NumPy array of quartic coefficients
and returns a list of Boolean labels for them. This is for
implementing customized oracle functions. Must have the signature
(func: Callable, phi_len: int, polar: bool, rng: NumpyGenerator, lam: np.array(np.float, np.float), <a href="#id10"><span class="problematic" id="id11">**</span></a>kwargs) -&gt; np.array(bool)
If this argument is not specified, the default oracle
BFBrain.Jax_Oracle.label_func is used.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.label_check">
<span class="sig-name descname"><span class="pre">label_check</span></span><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.label_check" title="Link to this definition">¶</a></dt>
<dd><p>A function that can be used to test the reliability of a custom
oracle given by label_fn, or if label_fn is None, the default
oracle BFBrain.Jax_Oracle.label_func. Must have the same signature
as label_fn, up to additional keyword arguments. If this argument
is not specified, the a tester for the default oracle is used:
BFBrain.Jax_Oracle.test_labeller</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>callable, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py">
<span class="sig-name descname"><span class="pre">\*\*label_kwargs</span></span></dt>
<dd><p>A dictionary of additional keyword arguments needed for the
labelling function label_func.</p>
<dl class="field-list simple">
<dt class="field-odd">Type<span class="colon">:</span></dt>
<dd class="field-odd"><p>dict, optional</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.from_func">
<em class="property"><span class="pre">classmethod</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">from_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sym_func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lambdify_mode</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'jax'</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_check</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">label_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.from_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.from_func" title="Link to this definition">¶</a></dt>
<dd><p>Preferred constructor for initializing DataManager.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>sym_func</strong> (<em>SymPy function.</em>) – A SymPy function that expresses the quartic part of the
potential. Must have the signature
(sympy.Array, sympy.Array) -&gt; sympy.Expr, where the first
sympy.Array object corresponds to the vev configuration
and the second corresponds to the quartic coefficients
in the potential.</p></li>
<li><p><strong>phi_len</strong> (<em>int</em>) – The number of real parameters needed to uniquely specify the
vev in the model.</p></li>
<li><p><strong>lam_len</strong> (<em>int</em>) – The number of independent real quartic coupling coefficients
in the model’s potential function.</p></li>
<li><p><strong>seed</strong> (<em>int</em><em>, </em><em>optional</em>) – A random number seed. Used to spawn a sequence of random
generators with SeedSequence.</p></li>
<li><p><strong>polar</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If true, the potential is analyzed with the vev coordinates
converted to a polar form. If false, they are analyzed in
their Cartesian form.</p></li>
<li><p><strong>lambdify_mode</strong> (<em>{'jax'</em><em>, </em><em>'numpy'</em><em>, </em><em>'scipy'</em><em>, </em><em>'math'</em><em>, </em><em>'mpmath'</em><em>, </em><em>'numexpr'</em><em>, </em><em>'sympy'</em><em>, </em><em>'tensorflow'}</em>) – The “module” input to sympy.lambdify, used to extract
numerical expressions from the symbolic SymPy function.
See SymPy documentation for details.</p></li>
<li><p><strong>label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function that takes a 2-D NumPy array of quartic
coefficients and returns a list of Boolean labels for them.
This is for implementing customized oracle functions. Must have the signature
(func: Callable, phi_len: int, polar: bool, rng: numpy.random.Generator, lam: np.array(np.float, np.float), <a href="#id12"><span class="problematic" id="id13">**</span></a>kwargs) -&gt; np.array(bool)
If this argument is not specified, the default oracle
BFBrain.Jax_Oracle.label_func is used.</p></li>
<li><p><strong>label_check</strong> (<em>callable</em><em>, </em><em>optional</em>) – A function that can be used to test the reliability of a
custom oracle given by label_fn, or if label_fn is None, the
default oracle BFBrain.Jax_Oracle.label_func. Must have the
same signature as label_fn, up to additional keyword arguments.
If this argument is not specified, the a tester for the
default oracle is used: BFBrain.Jax_Oracle.test_labeller</p></li>
<li><p><strong>**label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – A dictionary of additional keyword arguments needed for the
labelling function label_func.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.create_random_lambdas">
<span class="sig-name descname"><span class="pre">create_random_lambdas</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nlams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.create_random_lambdas"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.create_random_lambdas" title="Link to this definition">¶</a></dt>
<dd><p>Create a list of random sets of quartic potential coefficients
(but don’t label them yet). Use independent uncorrelated rng’s for
the generation of a validation and training set. Notice that these
lambdas are Cartesian coordinates that uniformly sample the
unit hypersphere.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nlams</strong> (<em>int</em>) – The number of sets of quartic coefficients to generate
randomly.</p></li>
<li><p><strong>validation</strong> (<em>bool</em><em>, </em><em>default=False</em>) – A flag denoting which random number generator to use,
ensuring independently-generated validation and training sets.
If True, use the random number generator for the
validation set, while if False, use the random number
generator for the training set.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D NumPy array representing a list of sets of quartic
coefficients for the potential.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.check_labeller">
<span class="sig-name descname"><span class="pre">check_labeller</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nlams</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">tester_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.check_labeller"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.check_labeller" title="Link to this definition">¶</a></dt>
<dd><p>A wrapper for calling the labeller’s check_labeller function.
Generates sample quartic coefficients randomly before running
labeller.check_labeller on them.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nlams</strong> (<em>int</em>) – The number of sets of quartic coefficients to randomly
generate for testing the labeller function’s consistency.</p></li>
<li><p><strong>tester_kwargs</strong> (<em>dict</em>) – Additional keyword arguments required by the check_labeller
function. If the default oracle and tester are used, possible
keyword arguments are niter_step, count_success, max_iter,
verbose. See BFBrain.Jax_Oracle.test_labeller for details.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><em>Same type as labeller.check_labeller, which may be a</em></p></li>
<li><p><em>user-written function. If the default oracle and tester are</em></p></li>
<li><p><em>used, this function will be BFBrain.Jax_Oracle.test_labeller.</em></p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.checklam_all">
<span class="sig-name descname"><span class="pre">checklam_all</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth_label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.checklam_all"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.checklam_all" title="Link to this definition">¶</a></dt>
<dd><p>Labels sets of quartic potential coefficients with True
(for bounded from below) or False (not bounded from below).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of quartic coefficients of the potential.
Each entry along the 0 axis corresponds to a single set of
quartic potential coefficients specifying a potential
function.</p></li>
<li><p><strong>truth_label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – Must take a 1-D NumPy array representing a single set of
quartic coefficients and return a Boolean True if the
potential they describe is bounded from below, False
otherwise. If this argument is specified, the method
will use this callable to label lams instead of the labeller
class. This is used in specific instances when a fast symbolic
expression for the bounded-from-below constraints is known,
and the performance of the classifier training loop can be
evaluated in the absence of noise due to the approximate
labeller. Obviously the use case of the classifier is for
potentials where such a symbolic expression is NOT known,
so the real-world model building usefulness of this option
is limited.</p></li>
<li><p><strong>label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – If these are specified, the oracle will use the keyword
arguments given here instead of the keyword arguments
specified in the DataManager constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A Boolean NumPy array of labels for each set of coefficients
in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.create_data">
<span class="sig-name descname"><span class="pre">create_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth_label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.create_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.create_data" title="Link to this definition">¶</a></dt>
<dd><p>Given an unlabelled 2-D NumPy array of sets of quartic
coefficients, label them and return an np_data object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of quartic coefficients of the potential.
Each entry along the 0 axis corresponds to a single set of
quartic potential coefficients specifying a
potential function.</p></li>
<li><p><strong>truth_label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – Must take a 1-D NumPy array representing a single set of
quartic coefficients and return a Boolean True if the
potential they describe is bounded from below, False
otherwise. If this argument is specified, the method will use
this callable to label lams instead of the labeller class.
This is used in specific instances when a fast symbolic
expression for the bounded-from-below constraints is known,
and the performance of the classifier training loop can be
evaluated in the absence of noise due to the approximate
oracle. Obviously the use case of the classifier is for
potentials where such a symbolic expression is NOT known,
so the real-world model building usefulness of this option
is limited.</p></li>
<li><p><strong>label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – If these are specified, the oracle will use the keyword
arguments given here instead of the keyword arguments
specified in the DataManager constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An np_data object representing the labelled contents of the
input array lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data">np_data</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.create_random_data">
<span class="sig-name descname"><span class="pre">create_random_data</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nlams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">truth_label_fn</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.create_random_data"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.create_random_data" title="Link to this definition">¶</a></dt>
<dd><p>Creates a random sample of Cartesian lambda coefficients and
labels them, then storing the results in an np_data object.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nlams</strong> (<em>int</em>) – The number of sets of quartic potential coefficients to
generate.</p></li>
<li><p><strong>validation</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, use the validation random number generator to
generate the random coefficients. If False, use the training
random number generator.</p></li>
<li><p><strong>truth_label_fn</strong> (<em>callable</em><em>, </em><em>optional</em>) – Must take a 1-D NumPy array representing a single set of
quartic coefficients and return a Boolean True if the
potential they describe is bounded from below, False
otherwise. If this argument is specified, the method will use
this callable to label lams instead of the labeller class.
This is used in specific instances when a fast symbolic
expression for the bounded-from-below constraints is known,
and the performance of the classifier training loop can be
evaluated in the absence of noise due to the approximate
labeller. Obviously the use case of the classifier is for
potentials where such a symbolic expression is NOT known,
so the real-world model building usefulness of this option
is limited.</p></li>
<li><p><strong>label_kwargs</strong> (<em>dict</em><em>, </em><em>optional</em>) – If these are specified, the oracle will use the keyword
arguments given here instead of the keyword arguments
specified in the DataManager constructor.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>An np_data object that represents the labelled sets of
quartic coefficients that was randomly generated.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data">np_data</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.check_accuracy_with_better_labeller">
<span class="sig-name descname"><span class="pre">check_accuracy_with_better_labeller</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label_kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.check_accuracy_with_better_labeller"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.check_accuracy_with_better_labeller" title="Link to this definition">¶</a></dt>
<dd><p>A method for evaluating the accuracy of a labeller which is
capable of mislabelling some False points as True, like the
default oracle, which is based on global minimization of the
quartic part of the potential.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_data</strong> (<a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data"><em>np_data</em></a>) – An np_data object, labelled with an oracle that can
mislabel some False points as True (but not the reverse).</p></li>
<li><p><strong>label_kwargs</strong> (<em>dict</em>) – A dictionary which specifies the keyword arguments for the
oracle, which must be selected to yield significantly more
accurate labels than the ones specified by in_data.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The precision (fraction of positively labelled points that
are true positives) of the oracle which originally labelled
in_data.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>float</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.balance_array">
<span class="sig-name descname"><span class="pre">balance_array</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.balance_array"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.balance_array" title="Link to this definition">¶</a></dt>
<dd><p>Given an np_data object that has more negative (not
bounded-from-below) points than positives (bounded-from-below),
rebalance data to include new positive points generated by
leveraging the convexity of the space of bounded-from-below points.
If there are as many or more positive points as negative points
in the np_data object, leaves the np_data object unmodified.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>data</strong> (<a class="reference internal" href="#bfbrain.Data_Manager.np_data" title="bfbrain.Data_Manager.np_data"><em>np_data</em></a>) – The np_data object that has many more negatively-labelled
points (that is, points which are not bounded-from-below)
than positives.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.create_dataset">
<span class="sig-name descname"><span class="pre">create_dataset</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.create_dataset"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.create_dataset" title="Link to this definition">¶</a></dt>
<dd><p>Given an np_data object, creates a Tensorflow dataset object
for training.</p>
<section id="paramaters">
<h3>Paramaters<a class="headerlink" href="#paramaters" title="Link to this heading">¶</a></h3>
<p>data : np_data</p>
<dl class="simple">
<dt>validation<span class="classifier">bool, default=False</span></dt><dd><p>If True, don’t shuffle the dataset. Useful for keeping track
of agreement on the validation set for the model after
successive active learning rounds.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">returns<span class="colon">:</span></dt>
<dd class="field-odd"><p>This dataset is NOT batched, but is randomly shuffled on the
CPU. To use for training, it is necessary to batch the dataset
object with tf.data.Dataset’s batch method.</p>
</dd>
<dt class="field-even">rtype<span class="colon">:</span></dt>
<dd class="field-even"><p>tf.data.Dataset</p>
</dd>
</dl>
</section>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="bfbrain.Data_Manager.DataManager.generate_L">
<span class="sig-name descname"><span class="pre">generate_L</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">nL</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hop_dist</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">probs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rand_fraction</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Data_Manager.html#DataManager.generate_L"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Data_Manager.DataManager.generate_L" title="Link to this definition">¶</a></dt>
<dd><p>Randomly generate a sample of new points in the vicinity of
some existing points. Given some set of existing points, samples
new points by making random hops of an angle given by a draw from
a normal distribution in a random direction along the
unit hypersphere in quartic coefficient space.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>nL</strong> (<em>int</em>) – The number of new sets of quartic coefficients to generate.</p></li>
<li><p><strong>lams</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array representing sets of quartic potential
coefficients. New points will be sampled in the vicinity
of these.</p></li>
<li><p><strong>hop_dist</strong> (<em>float</em>) – The distance scale for sampling around the coefficients in
lams. Newly-generated points are taken from input points
by randomly rotating points in lams by an angle taken from
a normal distribution with standard deviation hop_dist.</p></li>
<li><p><strong>probs</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>)</em><em>, </em><em>optional</em>) – A 1-D NumPy array, should be an array of nonnegative floats
which sum to 1, representing the probability of the function
selecting each index of lams to generate new points around.
If not specified, a uniform selection probability for all
points in lams is used.</p></li>
<li><p><strong>rand_fraction</strong> (<em>float</em><em>, </em><em>optional</em>) – Must be a non-negative float between 0 and 1. If specified,
then the method will sample that fraction of its points as
uniformly distributed draws from the surface of the unit
hypersphere in quartic coefficient space, instead of sampling
in the vicinity of points in lams. If not specified, all
generated points will be sampled in the vicinity of points
in lams.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D NumPy array representing a list of sets of quartic
coefficients for the potential.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-bfbrain.False_Proximity_Test">
<span id="bfbrain-false-proximity-test-module"></span><h2>bfbrain.False_Proximity_Test module<a class="headerlink" href="#module-bfbrain.False_Proximity_Test" title="Link to this heading">¶</a></h2>
<p>These are a series of functions used to score models based on how
distant their false positives and false negatives over some data set are
from the model’s decision boundary. The only function used externally is
combined_false_score, which discusses how the scoring is done. All other
functions in this file are only used internally by combined_false_score
and the functions that it calls.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.False_Proximity_Test.combined_false_score">
<span class="sig-prename descclassname"><span class="pre">bfbrain.False_Proximity_Test.</span></span><span class="sig-name descname"><span class="pre">combined_false_score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dist=&lt;tf.Tensor:</span> <span class="pre">shape=()</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype=float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">numpy=0.05&gt;</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/False_Proximity_Test.html#combined_false_score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.False_Proximity_Test.combined_false_score" title="Link to this definition">¶</a></dt>
<dd><p>A method to evaluate how “wrong” the model’s predictions of the
validation set actually are, based on how far false positives and
false negatives are from the decision boundary. Returns two sets
of information for the false positives and the false negatives.
For false positives (negatives), uses _find_accurate_points to find
nearby sets of coefficients that are correctly classified as
negative (positive). The angular distance between these new points
and the corresponding false positive (negative) points is then
computed in radians. The function returns the mean,
standard deviation, and maximum of these distances for both
false positives and negatives, as well as the number of points for
which the angular distance exceeds a specified angle in radians.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>ds</strong> (<em>tf.data.Dataset</em>) – A labelled Tensorflow dataset of sets of quartic potential
coefficients.</p></li>
<li><p><strong>dist</strong> (<em>tf.float32</em>) – A maximum angular distance in radians between an incorrectly
classified point and the classifier’s decision boundary that the
user deems acceptable. For small values of dist, this corresponds
to the maximum difference in a (normalized) quartic potential
coefficient between an incorrectly classified point and a
correctly classified one.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Each list contains the mean, standard deviation, and maximum of
the angular distance between incorrectly classified points in ds
and correctly classified ones generated with
_find_accurate_points. The final element of each list gives the
number of incorrectly classified points that are greater than
dist radians away from a correctly classified one.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of lists of floats.</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.False_Proximity_Test.get_false_pos_and_neg_tf">
<span class="sig-prename descclassname"><span class="pre">bfbrain.False_Proximity_Test.</span></span><span class="sig-name descname"><span class="pre">get_false_pos_and_neg_tf</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">ds</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/False_Proximity_Test.html#get_false_pos_and_neg_tf"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.False_Proximity_Test.get_false_pos_and_neg_tf" title="Link to this definition">¶</a></dt>
<dd><p>A function which extracts all sets of quartic coefficients in a
Tensorflow dataset that the neural network classifies incorrectly,
either false positives (points it incorrectly classifies as
bounded-from-below) or false negatives (points it incorrectly
classifies as NOT bounded-from-below).</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>ds</strong> (<em>tf.data.Dataset</em>) – A Tensorflow dataset representing labelled sets of quartic
potential coefficients.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>Two 2-D tensors representing the sets of false positive and false
negative quartic coefficients, respectively.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tuple of tf.Tensors</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-bfbrain.Hypersphere_Formulas">
<span id="bfbrain-hypersphere-formulas-module"></span><h2>bfbrain.Hypersphere_Formulas module<a class="headerlink" href="#module-bfbrain.Hypersphere_Formulas" title="Link to this heading">¶</a></h2>
<p>This module contains code for some basic manipulations to translate between n-dimensional polar and Cartesian coordinates.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.convert_from_polar">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">convert_from_polar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#convert_from_polar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.convert_from_polar" title="Link to this definition">¶</a></dt>
<dd><p>Converts an array of inputs in the range [0,pi) into an array of inputs in a Cartesian form</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>v</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of points in polar coordinates</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D NumPy array of points in Cartesian coordinates on the surface of the unit hypersphere.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.convert_to_polar">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">convert_to_polar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#convert_to_polar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.convert_to_polar" title="Link to this definition">¶</a></dt>
<dd><p>Converts an array of inputs in Cartesian form into a lower-dimensional angular parameterization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>v</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>, </em><em>np.float32</em><em>)</em>) – A 2-D NumPy array of points in Cartesian coordinates</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D NumPy array of points in polar coordinates.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.jax_convert_to_polar">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">jax_convert_to_polar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#jax_convert_to_polar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.jax_convert_to_polar" title="Link to this definition">¶</a></dt>
<dd><p>Converts an array of inputs in Cartesian form into a lower-dimensional angular parameterization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>v</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A 1-D Jax NumPy array representing a point in Cartesian coordinates.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D Jax NumPy array of points in polar coordinates.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jnp.array(jnp.float32, jnp.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.jax_convert_from_polar">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">jax_convert_from_polar</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#jax_convert_from_polar"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.jax_convert_from_polar" title="Link to this definition">¶</a></dt>
<dd><p>Converts an array of inputs in the range [0,pi) into an array of inputs in a Cartesian form</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>v</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A 1-D Jax NumPy array represenging a point in polar coordinates.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D Jax NumPy array of points in Cartesian coordinates on the surface of the unit hypersphere.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jnp.array(jnp.float32, jnp.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.rand_nsphere">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">rand_nsphere</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">n_points</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_dims</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#rand_nsphere"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.rand_nsphere" title="Link to this definition">¶</a></dt>
<dd><p>Randomly generates points sampled uniformly from the surface of a unit hypersphere of specified dimension.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>n_points</strong> (<em>int</em>) – The number of points the method should generate.</p></li>
<li><p><strong>n_dims</strong> (<em>int</em>) – The dimensionality of the hypersphere that the method should sample on the surface of.</p></li>
<li><p><strong>rng</strong> (<em>np.random.Generator</em>) – </p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D NumPy array representing sets of points uniformly sampled from the surface of the n_dims-dimensional unit hypersphere.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(np.float32, np.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.cumprod_sym">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">cumprod_sym</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">j</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#cumprod_sym"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.cumprod_sym" title="Link to this definition">¶</a></dt>
<dd><p>Computes the cumulative product of some subset of elements of a 1-D SymPy array.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<em>sympy.Array</em>) – A 1-D SymPy array of symbols.</p></li>
<li><p><strong>j</strong> (<em>int</em>) – The cumulative product will be computed by taking the product of the 0th through jth element of the array.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>sympy.symbol</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Hypersphere_Formulas.convert_from_polar_sym">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Hypersphere_Formulas.</span></span><span class="sig-name descname"><span class="pre">convert_from_polar_sym</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">v</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Hypersphere_Formulas.html#convert_from_polar_sym"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Hypersphere_Formulas.convert_from_polar_sym" title="Link to this definition">¶</a></dt>
<dd><p>Converts symbolic polar coordinates into symbolic Cartesian coordinates.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>v</strong> (<em>sympy.Array</em>) – A 1-D SymPy array of symbols representing a set of polar coordinates.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p>sympy.Array</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-bfbrain.Jax_Oracle">
<span id="bfbrain-jax-oracle-module"></span><h2>bfbrain.Jax_Oracle module<a class="headerlink" href="#module-bfbrain.Jax_Oracle" title="Link to this heading">¶</a></h2>
<p>The code in this module contains BFBrain’s default algorithm for
labelling if a point is bounded from below. It is designed to work with
the methods in Active_Learning.py. The fundamental strategy of this
labelling method is to take a quartic part of the potential function with
fixed quartic coefficients, and attempt many consecutive local
optimizations with respect to the scalar vev with random initial starting
points. If it can find a point where the potential is negative, it will
label the set of quartic coefficients as not bounded from below, while
if after some user-specified number of local minimization iterations the
found minima are always positive, the set will be labelled as bounded
from below.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.take_step">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">take_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#take_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.take_step" title="Link to this definition">¶</a></dt>
<dd><p>Return a tuple of phi, key (in that order) after randomly
generating phi as a vev point on the unit hypersphere.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x0</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A Jax NumPy array that tells the function what shape the vev input
arrays should be.</p></li>
<li><p><strong>key</strong> (<em>Jax PRNGGKey</em>) – A key object used to generate random numbers in Jax. Will be
consumed over the running of the function and a new key will be
returned.</p></li>
<li><p><strong>polar</strong> (<em>bool</em>) – A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the unit hypersphere (True).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>rand_phi</strong> (<em>jnp.array(jnp.float32).</em>) – A 1-D Jax Numpy array representing a single point in vev space.</p></li>
<li><p><strong>new_key</strong> (<em>Jax PRNGKey</em>) – A key object used to generate random numbers in Jax. Supplied to
replace the consumed key.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.run_one_step">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">run_one_step</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stepper</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#run_one_step"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.run_one_step" title="Link to this definition">¶</a></dt>
<dd><p>Takes a single local minimization step. This consists of randomly
generating a starting point, running the local minimizer from that
starting point, and extracting the potential value after minimization.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>key</strong> (<em>Jax PRNGKey</em>) – A key object used to generate random numbers in Jax. Will be
consumed over the running of the function and a new key will be
returned.</p></li>
<li><p><strong>minimizer</strong> (<em>JaxOpt Projected Gradient optimizer object.</em>) – </p></li>
<li><p><strong>stepper</strong> (<em>callable</em>) – The function take_step, wrapped to require only a PRNGKey object
as input.</p></li>
<li><p><strong>lam</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A 1-D Jax Numpy array representing a set of quartic coefficients
in the scalar potential.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><ul class="simple">
<li><p><strong>energy_after_quench</strong> (<em>jnp.float32</em>) – The minimum value of the potential found by minimizer after
starting from a random starting position generated with key.</p></li>
<li><p><strong>new_key</strong> (<em>Jax PRNGKey</em>) – A key object used to generate random numbers in Jax. Supplied to
replace the consumed key.</p></li>
</ul>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.jax_basinhopping">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">jax_basinhopping</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng_key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">minimizer</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#jax_basinhopping"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.jax_basinhopping" title="Link to this definition">¶</a></dt>
<dd><p>Iterate over run_one_step a large number of times.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>lam</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A 1-D Jax Numpy array representing a set of quartic coefficients
in the scalar potential.</p></li>
<li><p><strong>rng_key</strong> (<em>Jax PRNGKey</em>) – Used to generate random numbers.</p></li>
<li><p><strong>x0</strong> (<em>jnp.array</em><em>(</em><em>jnp.float32</em><em>)</em>) – A Jax NumPy array that tells the function what shape the vev input
arrays should be.</p></li>
<li><p><strong>minimizer</strong> (<em>JaxOpt Projected Gradient optimizer object.</em>) – </p></li>
<li><p><strong>niter</strong> (<em>int</em>) – The maximum number of run_one_step iterations to perform in an
attempt to find a negative local minimum of the potential.</p></li>
<li><p><strong>polar</strong> (<em>bool</em>) – A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the phi_len-dimensional unit hypersphere (True).</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p><strong>new_min_energy</strong> – The smallest local minimum that the optimizer found after its
iterations.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>jnp.float32</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.vectorized_minTest">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">vectorized_minTest</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">key</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#vectorized_minTest"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.vectorized_minTest" title="Link to this definition">¶</a></dt>
<dd><p>Vectorized version of vectorized_minTest. Takes similar arguments as vectorized_minTest but with additional array axes over which vectorized_minTest is mapped.</p>
<p>Original documentation:</p>
<p>A vectorized version of jax_basinhopping.</p>
<blockquote>
<div><dl class="simple">
<dt>func<span class="classifier">callable</span></dt><dd><p>A Jax Numpy function that returns the quartic potential and its
gradient with respect to the vev parameters. This function will
be generated by a BFBrain.DataManager object.</p>
</dd>
<dt>lam<span class="classifier">jnp.array(jnp.float32, jnp.float32)</span></dt><dd><p>A 2-D Jax NumPy array representing multiple sets of quartic
coefficients for the potential.</p>
</dd>
</dl>
<p>key : Jax PRNGKey</p>
<dl class="simple">
<dt>x0<span class="classifier">jnp.array(jnp.float32)</span></dt><dd><p>A Jax NumPy array that informs the function about the shape of
the vev input.</p>
</dd>
<dt>niter<span class="classifier">int</span></dt><dd><p>The maximum number of local minimization iterations the minimizer
should perform for each set of quartic coefficients in lam,
searching for a negative minimum potential value.</p>
</dd>
<dt>tol<span class="classifier">jnp.float32</span></dt><dd><p>The tolerance for the local minimizer to stop.</p>
</dd>
<dt>polar<span class="classifier">bool</span></dt><dd><p>A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the phi_len-dimensional unit hypersphere (True).</p>
</dd>
</dl>
<dl class="simple">
<dt>jnp.array(jnp.float32)</dt><dd><p>An array of minimum energy values found for the potentials
specified by the elements of lam.</p>
</dd>
</dl>
</div></blockquote>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.label_func">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">label_func</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#label_func"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.label_func" title="Link to this definition">¶</a></dt>
<dd><p>The function which interfaces directly with BFBrain.DataManager’s
methods for handling oracles.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em>) – The Jax Numpy function that returns the quartic part of the
potential and the gradient.</p></li>
<li><p><strong>phi_len</strong> (<em>int</em>) – The number of real parameters necessary to uniquely specify a vev.</p></li>
<li><p><strong>polar</strong> (<em>bool</em>) – A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the phi_len-dimensional unit hypersphere (True).</p></li>
<li><p><strong>rng</strong> (<em>np.random.Generator</em>) – The NumPy random number generator which will generate the initial
PRNGKey used by this oracle.</p></li>
<li><p><strong>lam</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>,</em><em>np.float32</em><em>)</em>) – A 2-D Numpy array of quartic potential coefficients.</p></li>
<li><p><strong>niter</strong> (<em>int</em><em>, </em><em>default=100</em>) – The number of local minimizations to perform on the potential
before declaring it to be bounded-from-below.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=0.001</em>) – The tolerance for the local minimizer.</p></li>
<li><p><strong>cutoff</strong> (<em>int</em><em>, </em><em>default=150000</em>) – The maximum size of a batch of coefficient values to pass to the
GPU at one time. If lam consists of more sets of coefficient
values than this, the method will split it into digestible batches.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a 1-D NumPy array of labels for each set of quartic coefficients
in lam. Labels False for points where the labeller found a
negative local minimum and True otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.label_func_do_batch">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">label_func_do_batch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#label_func_do_batch"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.label_func_do_batch" title="Link to this definition">¶</a></dt>
<dd><p>The method usedy by label_func to transfer the coefficient data to
the GPU and perform the jit-compiled analysis with Jax.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em>) – The Jax Numpy function that returns the quartic part of the
potential and the gradient.</p></li>
<li><p><strong>phi_len</strong> (<em>int</em>) – The number of real parameters necessary to uniquely specify a vev.</p></li>
<li><p><strong>polar</strong> (<em>bool</em>) – A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the phi_len-dimensional unit hypersphere (True).</p></li>
<li><p><strong>rng</strong> (<em>np.random.Generator</em>) – The NumPy random number generator which will generate the initial
PRNGKey used by this oracle.</p></li>
<li><p><strong>lam</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>,</em><em>np.float32</em><em>)</em>) – A 2-D Numpy array of quartic potential coefficients.</p></li>
<li><p><strong>niter</strong> (<em>int</em>) – The number of local minimizations to perform on the potential
before declaring it to be bounded-from-below.</p></li>
<li><p><strong>tol</strong> (<em>float</em>) – The tolerance for the local minimizer.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>a 1-D NumPy array of labels for each set of quartic coefficients
in lam. Labels False for points where the labeller found a
negative local minimum and True otherwise.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>np.array(bool)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Jax_Oracle.test_labeller">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Jax_Oracle.</span></span><span class="sig-name descname"><span class="pre">test_labeller</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phi_len</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">polar</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">rng</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">tol</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cutoff</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">150000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">niter_step</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">50</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">count_success</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">5</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_iter</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">20</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">verbose</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Jax_Oracle.html#test_labeller"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Jax_Oracle.test_labeller" title="Link to this definition">¶</a></dt>
<dd><p>A method to test the accuracy of the oracle. Will perform
label_func repeatedly for the same 2-D NumPy array of quartic
coefficients, but with niter increased each time, until the same
labels are returned for for a specified consecutive number of
iterations, or some maximum number of labellings has been completed
without finding consistent results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>func</strong> (<em>callable</em>) – The Jax Numpy function that returns the quartic part of the
potential and the gradient.</p></li>
<li><p><strong>phi_len</strong> (<em>int</em>) – The number of real parameters necessary to uniquely specify a vev.</p></li>
<li><p><strong>polar</strong> (<em>bool</em>) – A flag denoting whether the labeller should use Cartesian
coordinates for the vev (False) or convert them into polar
coordinates on the phi_len-dimensional unit hypersphere (True).</p></li>
<li><p><strong>rng</strong> (<em>np.random.Generator</em>) – The NumPy random number generator which will generate the initial
PRNGKey used by this oracle.</p></li>
<li><p><strong>lam</strong> (<em>np.array</em><em>(</em><em>np.float32</em><em>,</em><em>np.float32</em><em>)</em>) – A 2-D Numpy array of quartic potential coefficients.</p></li>
<li><p><strong>niter</strong> (<em>int</em><em>, </em><em>default=100</em>) – The initial number of local minimizations to perform on the
potential before declaring it to be bounded-from-below– this
value will be incremented over the running of the method.</p></li>
<li><p><strong>tol</strong> (<em>float</em><em>, </em><em>default=0.001</em>) – The tolerance for the local minimizer.</p></li>
<li><p><strong>cutoff</strong> (<em>int</em><em>, </em><em>default=150000</em>) – The maximum size of a batch of coefficient values to pass to the
GPU at one time. If lam consists of more sets of coefficient
values than this, the method will split it into digestible batches.</p></li>
<li><p><strong>niter_step</strong> (<em>int</em><em>, </em><em>default=50</em>) – The amount to increment the niter parameter of label_func with
each successive attempt at labelling lam.</p></li>
<li><p><strong>count_success</strong> (<em>int</em><em>, </em><em>default=5</em>) – The number of consecutive labelling attempts that must yield
identical labels for the function to declare that increasing
niter is no longer affecting the results of label_func.</p></li>
<li><p><strong>max_iter</strong> (<em>int</em><em>, </em><em>default=20</em>) – The maximum number of labelling attempts that the method will
make. If no consistent results are found before that time, the
test ends in failure.</p></li>
<li><p><strong>verbose</strong> (<em>bool</em><em>, </em><em>default=False</em>) – If True, print out statements informing the user of the progress
of the method.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The minimum niter parameter such that count_success consecutive
attempts to label lam with increasing niter yielded the same
label. If max_iter attempts are made without running into
count_success consecutive identical label results, -1 is returned.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>int</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-bfbrain.Potential_Functions">
<span id="bfbrain-potential-functions-module"></span><h2>bfbrain.Potential_Functions module<a class="headerlink" href="#module-bfbrain.Potential_Functions" title="Link to this heading">¶</a></h2>
<p>This module contains a number of SymPy functions for the quartic parts
of scalar potentials which the program can parse for analysis. Any other
potential functions you may want to use can be implemented by writing them
in the same format as these.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Potential_Functions.V_Precustodial">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Potential_Functions.</span></span><span class="sig-name descname"><span class="pre">V_Precustodial</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Potential_Functions.html#V_Precustodial"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Potential_Functions.V_Precustodial" title="Link to this definition">¶</a></dt>
<dd><p>The “precustodial” generalization of the Georgi-Machacheck
model given in arXiv:hep-ph/2012.13947. The quartic coefficients are
parameterized in the same manner as Eq.(3.4) of that work.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Potential_Functions.V_GM">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Potential_Functions.</span></span><span class="sig-name descname"><span class="pre">V_GM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Potential_Functions.html#V_GM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Potential_Functions.V_GM" title="Link to this definition">¶</a></dt>
<dd><p>The Georgi-Machacheck potential, following the conventions of
Eq.(5) of arXiv:hep-ph/1404.2640</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Potential_Functions.V_2HDM">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Potential_Functions.</span></span><span class="sig-name descname"><span class="pre">V_2HDM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Potential_Functions.html#V_2HDM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Potential_Functions.V_2HDM" title="Link to this definition">¶</a></dt>
<dd><p>The most general 2-Higgs doublet model, following the conventions
of Eq.(1) of hep-ph/0609018</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Potential_Functions.V_3HDM">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Potential_Functions.</span></span><span class="sig-name descname"><span class="pre">V_3HDM</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Potential_Functions.html#V_3HDM"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Potential_Functions.V_3HDM" title="Link to this definition">¶</a></dt>
<dd><p>A 3HDM with Z2xZ2 symmetry, for which no BFB conditions are known.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Potential_Functions.V_3HDM_U1">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Potential_Functions.</span></span><span class="sig-name descname"><span class="pre">V_3HDM_U1</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phi</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lam</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Potential_Functions.html#V_3HDM_U1"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Potential_Functions.V_3HDM_U1" title="Link to this definition">¶</a></dt>
<dd><p>A 3HDM with U1xU1 symmetry.</p>
</dd></dl>

</section>
<section id="module-bfbrain.Score_Functions">
<span id="bfbrain-score-functions-module"></span><h2>bfbrain.Score_Functions module<a class="headerlink" href="#module-bfbrain.Score_Functions" title="Link to this heading">¶</a></h2>
<p>This module contains different methods to extract uncertainty estimates
from a trained neural network. It also contains two useful analysis
functions, MC_call_fast and MC_call_full, which execute Monte Carlo
dropout with the neural networks that BFBrain produces.</p>
<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.MC_call_full">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">MC_call_full</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#MC_call_full"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.MC_call_full" title="Link to this definition">¶</a></dt>
<dd><p>Perform predictions on a given input using Monte Carlo dropout.
Evaluates the output of model on the input repeatedly, with random
dropout applied, and returns all results.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em>) – Specifies the number of forward passes through the neural network
to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 2-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams. Each entry along the zero axis
represents the results of a different forward pass of the
same inputs.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32, tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.MC_call_fast">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">MC_call_fast</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#MC_call_fast"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.MC_call_fast" title="Link to this definition">¶</a></dt>
<dd><p>perform predictions on a given input using Monte Carlo dropout
when only the average output is required. Evaluates the output of
model on the input lams n_trials times and takes the average output
for each point. Schematically equivalent to
tf.reduce_mean(MC_call_full(model, lams, n_trials), axis = 0),
but faster.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em>) – Specifies the number of forward passes through the neural network
to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.QBDC">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">QBDC</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#QBDC"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.QBDC" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points by
“query by dropout committee”. Averages the result of many evaluations
with dropout enabled in the network and gives the highest scores to
points which are closest to the decision boundary. This should
estimate total predictive uncertainty, that is both aleatoric
(from ambiguity of the underlying input) and epistemic (from lack
of training data in the vicinity of the input) uncertainties.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=100</em>) – Specifies the number of forward passes through the neural
network to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.Max_Entropy">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">Max_Entropy</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#Max_Entropy"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.Max_Entropy" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points by
Shannon entropy. Averages the result of many evaluations with dropout
enabled in the network and gives the highest scores to points which
have the largest entropy. This should estimate total predictive
uncertainty, that is both aleatoric (from ambiguity of the underlying
input) and epistemic (from lack of training data in the vicinity of
the input) uncertainties.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=100</em>) – Specifies the number of forward passes through the neural network
to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.BALD">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">BALD</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#BALD"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.BALD" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points by
mutual information (as is done in Bayesian Active Learning by
Disagreement, or BALD). This should estimate solely epistemic
(stemming from lack of training data in the vicinity of the input)
uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=1000</em>) – Specifies the number of forward passes through the neural
network to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.Predictive_Variance">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">Predictive_Variance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#Predictive_Variance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.Predictive_Variance" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points by
variance of the predicted score. This should estimate solely
epistemic (stemming from lack of training data in the vicinity
of the input) uncertainty.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=1000</em>) – Specifies the number of forward passes through the neural
network to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.Variation_Ratios">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">Variation_Ratios</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_trials</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#Variation_Ratios"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.Variation_Ratios" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points by
variation ratios (the fraction of evaluations which give the opposite
classification to the mode). This should be sensitive to total
predictive uncertainty, that is both aleatoric (from ambiguity
of the underlying input) and epistemic (from lack of training data
in the vicinity of the input) uncertainties</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
<li><p><strong>n_trials</strong> (<em>int</em><em>, </em><em>default=1000</em>) – Specifies the number of forward passes through the neural
network to perform when doing Monte Carlo dropout.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic
potential coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="bfbrain.Score_Functions.Random_AL">
<span class="sig-prename descclassname"><span class="pre">bfbrain.Score_Functions.</span></span><span class="sig-name descname"><span class="pre">Random_AL</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lams</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/bfbrain/Score_Functions.html#Random_AL"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#bfbrain.Score_Functions.Random_AL" title="Link to this definition">¶</a></dt>
<dd><p>Score an ensemble of possible additional training points randomly.
This can act as a control to confirm that active learning strategies
outperform a randomly generated ensemble of training points.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>model</strong> (<em>tf.keras.Model</em>) – </p></li>
<li><p><strong>lams</strong> (<em>tf.constant</em><em>(</em><em>tf.float32</em><em>, </em><em>tf.float32</em><em>)</em>) – A 2-D Tensorflow tensor representing sets of quartic potential
coefficients.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>A 1-D Tensorflow tensor of scores for each set of quartic potential
coefficients in lams.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>tf.constant(tf.float32)</p>
</dd>
</dl>
</dd></dl>

</section>
<section id="module-bfbrain">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-bfbrain" title="Link to this heading">¶</a></h2>
</section>
</section>


          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="index.html">bfbrain</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial.html">Tutorial and User Guide</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">BFBrain</a><ul class="current">
<li class="toctree-l2 current"><a class="current reference internal" href="#">bfbrain package</a></li>
</ul>
</li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="index.html">Documentation overview</a><ul>
  <li><a href="modules.html">BFBrain</a><ul>
      <li>Previous: <a href="modules.html" title="previous chapter">BFBrain</a></li>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, George Wojcik.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
      |
      <a href="_sources/bfbrain.rst.txt"
          rel="nofollow">Page source</a>
    </div>

    

    
  </body>
</html>