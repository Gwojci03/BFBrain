<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>bfbrain.AL_Metrics &#8212; bfbrain 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=039e1c02" />
    <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for bfbrain.AL_Metrics</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;This module contains code for various performance metrics</span>
<span class="sd">which BFBrain can track over the course of active learning.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>
<span class="kn">from</span> <span class="nn">os</span> <span class="kn">import</span> <span class="n">sys</span>
<span class="kn">from</span> <span class="nn">bfbrain.Score_Functions</span> <span class="kn">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">bfbrain.False_Proximity_Test</span> <span class="kn">import</span> <span class="n">combined_false_score</span>
<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>

<span class="n">scoring_funcs</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;BALD&#39;</span><span class="p">:</span><span class="n">BALD</span><span class="p">,</span> <span class="s1">&#39;QBDC&#39;</span><span class="p">:</span><span class="n">QBDC</span><span class="p">,</span> 
                 <span class="s1">&#39;random&#39;</span><span class="p">:</span><span class="n">Random_AL</span><span class="p">,</span> <span class="s1">&#39;MaxEntropy&#39;</span><span class="p">:</span><span class="n">Max_Entropy</span><span class="p">,</span>
                   <span class="s1">&#39;variation_ratios&#39;</span><span class="p">:</span><span class="n">Variation_Ratios</span><span class="p">,</span> 
                   <span class="s1">&#39;predictive_variance&#39;</span><span class="p">:</span><span class="n">Predictive_Variance</span><span class="p">}</span>

<span class="n">valid_sc_types</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="s1">&#39;model&#39;</span><span class="p">]</span>

<span class="n">metric_reductions</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;mean&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">,</span> 
                     <span class="s1">&#39;min&#39;</span><span class="p">:</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">,</span> <span class="s1">&#39;std&#39;</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">std</span><span class="p">}</span>

<div class="viewcode-block" id="process_score_fn">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.process_score_fn">[docs]</a>
<span class="k">def</span> <span class="nf">process_score_fn</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A utility function which translates a string </span>
<span class="sd">    specifying one of the predefined acquisition </span>
<span class="sd">    scoring functions into the corresponding </span>
<span class="sd">    numerical method.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_fn : {&#39;BALD&#39;, &#39;QBDC&#39;, &#39;random&#39;, &#39;MaxEntropy&#39;, &#39;variation_ratios&#39;, &#39;predictive_variance&#39;} or callable.</span>
<span class="sd">        If this function is a callable, it must have the signature</span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32)</span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32)</span>

<span class="sd">    name : str, optional</span>
<span class="sd">        If specified, this name is returned unaltered. Otherwise,</span>
<span class="sd">          a name will be automatically generated based on score_fn.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    callable</span>
<span class="sd">        A valid score_fn to be used in various performance metrics.</span>

<span class="sd">    str</span>
<span class="sd">        A string which will be used to generate a name for an </span>
<span class="sd">        ALMetric object.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">callable</span><span class="p">(</span><span class="n">score_fn</span><span class="p">):</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">scoring_funcs</span><span class="o">.</span><span class="n">keys</span><span class="p">())[</span><span class="nb">list</span><span class="p">(</span><span class="n">scoring_funcs</span><span class="o">.</span><span class="n">values</span><span class="p">())</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">score_fn</span><span class="p">)]</span>
            <span class="k">except</span> <span class="ne">ValueError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
                <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;score&#39;</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;score_fn must be a string which acts as a key in the dict scoring_funcs in score_functions.py, or a callable.&#39;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">name</span> <span class="o">=</span> <span class="n">score_fn</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">score_fn</span> <span class="o">=</span> <span class="n">scoring_funcs</span><span class="p">[</span><span class="n">score_fn</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;score_fn was a string, but was not recognized as corresponding to a known metric. Valid string inputs are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">scoring_funcs</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
    <span class="k">return</span> <span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span></div>


<span class="k">def</span> <span class="nf">_get_reduction</span><span class="p">(</span><span class="n">red_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A utility method to connect a string or list of</span>
<span class="sd">    strings specifying certain reductions of a 1-D NumPy</span>
<span class="sd">    array to the corresponding functions.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    red_name : {&#39;mean&#39;, &#39;max&#39;, &#39;min&#39;, &#39;std&#39;} or list of these strings.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    list of callables</span>
<span class="sd">        A list of callables (possibly of length 1) which</span>
<span class="sd">          correspond to the reduction(s) named in red_name</span>

<span class="sd">    list of str</span>
<span class="sd">        red_name. If red_name was a single str object,</span>
<span class="sd">          it is returned as a list of str with length 1.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">red_name</span><span class="p">,</span> <span class="nb">str</span><span class="p">):</span>
            <span class="n">reduction</span> <span class="o">=</span> <span class="p">[</span><span class="n">metric_reductions</span><span class="p">[</span><span class="n">red_name</span><span class="p">]]</span>
            <span class="n">red_name</span> <span class="o">=</span> <span class="p">[</span><span class="n">red_name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">reduction</span> <span class="o">=</span> <span class="p">[</span><span class="n">metric_reductions</span><span class="p">[</span><span class="n">red</span><span class="p">]</span> <span class="k">for</span> <span class="n">red</span> <span class="ow">in</span> <span class="n">red_name</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">reduction</span><span class="p">,</span> <span class="n">red_name</span>
    <span class="k">except</span> <span class="ne">KeyError</span> <span class="k">as</span> <span class="n">error</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Unrecognized value for argument &quot;reduction&quot;. Must be one of </span><span class="si">{}</span><span class="s1"> or a list of those values.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">metric_reductions</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>

<span class="k">def</span> <span class="nf">_check_reduction</span><span class="p">(</span><span class="n">reduction</span><span class="p">,</span> <span class="n">red_name</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A utility function which checks that an input</span>
<span class="sd">    string is in a list of strings (specifically</span>
<span class="sd">    keys in metric_reductions), and raises an </span>
<span class="sd">    error if it&#39;s not.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    reduction : str</span>
<span class="sd">    red_name : list of str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">reduction</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">red_name</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Please specify a reduction that the metric has recorded. Options are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">red_name</span><span class="p">))</span>


<div class="viewcode-block" id="ALMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric">[docs]</a>
<span class="k">class</span> <span class="nc">ALMetric</span><span class="p">(</span><span class="n">ABC</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A generic abstract class for computing and recording</span>
<span class="sd">    performance metrics for active learning. All performance</span>
<span class="sd">    metrics in BFBrain inherit from this class.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list</span>
<span class="sd">        A list which contains a record, for each round of</span>
<span class="sd">        active learning, for whichever metric the subclass </span>
<span class="sd">        will measure. The entries of status_history may be,</span>
<span class="sd">        depending on the subclass, virtually any kind of data</span>
<span class="sd">        or data structure, as long as the elements are picklable.</span>

<span class="sd">    sc_type : {&#39;val&#39;, &#39;train&#39;, &#39;pool&#39;, &#39;model&#39;}</span>
<span class="sd">        A string which denotes what type of metric the ALMetric object is,</span>
<span class="sd">        since different metrics are recorded at different</span>
<span class="sd">        points in the active learning loop. If sc_type is &#39;val&#39;,</span>
<span class="sd">        this metric is computed using a validation data set</span>
<span class="sd">        immediately after each active learning round completes.</span>
<span class="sd">        If sc_type is &#39;train&#39;, this metric is computed immediately</span>
<span class="sd">        after new training data is generated in the active learning </span>
<span class="sd">        loop, but before the neural network&#39;s weights are reset and </span>
<span class="sd">        training commences. It is evaluated using the newly-generated</span>
<span class="sd">        training data. If sc_type is &#39;pool&#39;, this metric is computed </span>
<span class="sd">        using the pool of candidate points from which new training samples </span>
<span class="sd">        are drawn at each iteration. It is computed immediately after the </span>
<span class="sd">        new training data is selected from the pool. If sc_type is model, </span>
<span class="sd">        the a metric is computed without reference to any data set </span>
<span class="sd">        (validation, training, or pool) present in the active learning </span>
<span class="sd">        loop, at the end of each active learning iteration. The only </span>
<span class="sd">        implemented metrics which have sc_type &#39;model&#39; measure predictive</span>
<span class="sd">        stability on some specified unlabelled set of points, namely </span>
<span class="sd">        UnlabelledAgreement and UnlabelledDeltaFScore, but the possibility </span>
<span class="sd">        remains that different sorts of metrics in this class, for example </span>
<span class="sd">        the one based on error stability computed directly from the neural </span>
<span class="sd">        network weights discussed in arXiv:2104.01836, may be desirable </span>
<span class="sd">        for a user to implement.</span>

<span class="sd">    name : str</span>
<span class="sd">        A string which denotes a name for this metric. In a list of metrics</span>
<span class="sd">        passed to a BFBLearner class, the names of each member of the list </span>
<span class="sd">        should be unique.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    sc_type : {&#39;val&#39;, &#39;train&#39;, &#39;pool&#39;, &#39;model&#39;}</span>

<span class="sd">    name : str</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">sc_type</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">if</span> <span class="n">sc_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">valid_sc_types</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;sc_type must be a string, and must be one of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">valid_sc_types</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">sc_type</span> <span class="o">=</span> <span class="n">sc_type</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">sc_type</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="n">name</span>

<div class="viewcode-block" id="ALMetric.record_score">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.record_score">[docs]</a>
    <span class="k">def</span> <span class="nf">record_score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Appends the latest value for the performance metric to the status_history object.</span>
<span class="sd">        This method calls an abstract method &quot;performance_check&quot; which will turn</span>
<span class="sd">        whatever input is specified in the method into the metric the object is supposed</span>
<span class="sd">        to track. The method performance_check, and therefore the arguments going into </span>
<span class="sd">        this method, will vary depending on the specific subclass of ALMetric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">performance_check</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">))</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>

    
<div class="viewcode-block" id="ALMetric.print_status">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.print_status">[docs]</a>
    <span class="k">def</span> <span class="nf">print_status</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">file</span> <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">stdout</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A method which prints the last entry in status_history to a </span>
<span class="sd">        file (or the console). Uses the method perf_message </span>
<span class="sd">        (which is often overwritten in the child class) to identify </span>
<span class="sd">        the metric being printed and separates status_history elements </span>
<span class="sd">        that are tuples into different printout lines, for clarity. </span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">last_status</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">out_message</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">perf_message</span><span class="p">()</span>
        <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span> <span class="o">==</span> <span class="nb">tuple</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">stat</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">last_status</span><span class="p">):</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">out_message</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">file</span> <span class="o">=</span> <span class="n">file</span><span class="p">)</span>
                <span class="nb">print</span><span class="p">(</span><span class="n">stat</span><span class="p">,</span> <span class="n">file</span> <span class="o">=</span> <span class="n">file</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">out_message</span><span class="p">,</span> <span class="n">file</span> <span class="o">=</span> <span class="n">file</span><span class="p">)</span>
            <span class="nb">print</span><span class="p">(</span><span class="n">last_status</span><span class="p">,</span> <span class="n">file</span> <span class="o">=</span> <span class="n">file</span><span class="p">)</span></div>


    <span class="c1"># A method which prints out the message </span>
<div class="viewcode-block" id="ALMetric.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A method which prints out a message that is helpful in </span>
<span class="sd">        identifying what metric is being reported when a user calls </span>
<span class="sd">        print_status. Often overwritten in a child class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;:&#39;</span></div>


<div class="viewcode-block" id="ALMetric.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.performance_check">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;An abstract class which takes some arguments (depending on</span>
<span class="sd">        the type of performance metric) and computes the quantity or </span>
<span class="sd">        quantities that the performance metric is supposed to track.</span>
<span class="sd">        This method is called by record_score and its results are </span>
<span class="sd">        appended to the status_history attribute.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

    
<div class="viewcode-block" id="ALMetric.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;A function which reduces the status_history object to a list</span>
<span class="sd">        of single numbers (usually some sort of figure of merit) in the</span>
<span class="sd">        event that the members of status_history are a list or a tuple.</span>
<span class="sd">        By default, it simply returns the full status_history list</span>
<span class="sd">        and must be overwritten in subclasses which have lists or tuples</span>
<span class="sd">        as entries in status_history.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : Any</span>
<span class="sd">            Some overwritten versions of this class can accept optional</span>
<span class="sd">            arguments, although the method does not in the parent class.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        A NumPy array featuring information from status_history for plotting.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="nb">tuple</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]]))</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]))</span></div>

    
<div class="viewcode-block" id="ALMetric.reset_data">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.reset_data">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        A function which resets the metric data entirely. In some </span>
<span class="sd">        subclasses, this must be overloaded to properly reset the class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span> <span class="o">=</span> <span class="p">[]</span></div>


<div class="viewcode-block" id="ALMetric.get_legend">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.get_legend">[docs]</a>
    <span class="k">def</span> <span class="nf">get_legend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns a legend for a plot of the metric given by plot_metric.</span>
<span class="sd">        Often must be overwritten in subclasses.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : Any</span>
<span class="sd">            Some overwritten versions of this class can accept optional </span>
<span class="sd">            arguments, although the method does not in the parent class. </span>
<span class="sd">            Must take the same arguments as get_metric.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of strings</span>
<span class="sd">            A list of strings which are usable to specify a legend in </span>
<span class="sd">            matplotlib.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">]</span></div>

    
<div class="viewcode-block" id="ALMetric.plot_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ALMetric.plot_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">plot_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">filepath</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Plots the performance metric as a function of the number of </span>
<span class="sd">        active learning iterations.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        filepath : str, optional</span>
<span class="sd">            If this argument is specified, then the plot of the metric </span>
<span class="sd">            will be saved as a .png file in the directory with the name </span>
<span class="sd">            given by filepath.</span>

<span class="sd">        **kwargs : dict, optional</span>
<span class="sd">            Many subclasses of ALMetric have get_metric and get_legend </span>
<span class="sd">            methods which take some keyword arguments-- these can be </span>
<span class="sd">            specified when calling plot_metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metrics</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_metric</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">legend</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_legend</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">metrics</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">legend</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;AL Iterations&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">filepath</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">):</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">filepath</span><span class="o">+</span> <span class="s1">&#39;/&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;.png&#39;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">()</span></div>
</div>


<div class="viewcode-block" id="ModelMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelMetric">[docs]</a>
<span class="k">class</span> <span class="nc">ModelMetric</span><span class="p">(</span><span class="n">ALMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class for handling metrics which depend only on the</span>
<span class="sd">    BFBLearner object&#39;s model, plus some consistent internal information.</span>
<span class="sd">    This class can be used as a &quot;catch-all&quot; for metrics which don&#39;t fit</span>
<span class="sd">    neatly into other categories-- for example, we use it in</span>
<span class="sd">    UnlabelledPredsMetric and its child classes to track the predictions </span>
<span class="sd">    of the model on some unlabelled set of inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sc_type</span> <span class="o">=</span> <span class="s1">&#39;model&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>

<div class="viewcode-block" id="ModelMetric.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelMetric.performance_check">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The performance_check method now specifies the arguments that</span>
<span class="sd">        a class inheriting from TrainMetric should use.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</div>


<div class="viewcode-block" id="UnlabelledPredsMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledPredsMetric">[docs]</a>
<span class="k">class</span> <span class="nc">UnlabelledPredsMetric</span><span class="p">(</span><span class="n">ModelMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class for handling metrics which go by the predictions</span>
<span class="sd">    of the model on some unlabelled set of quartic coefficients.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential </span>
<span class="sd">        coefficients. This will be an unlabelled set of points the model </span>
<span class="sd">        will make predictions on.</span>

<span class="sd">    ds : tf.data.Dataset</span>
<span class="sd">        A Tensorflow dataset generated from lams.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred to</span>
<span class="sd">        the GPU and computed with at one time.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics</span>
<span class="sd">        traced by BFBLearner.</span>
<span class="sd">        </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential </span>
<span class="sd">        coefficients. This will be an unlabelled set of points the </span>
<span class="sd">        model will make predictions on.</span>

<span class="sd">    name : str</span>
<span class="sd">        The name will provide a unique identifier for the metric in</span>
<span class="sd">        the list of metrics tracked by BFBLearner-- this identifier</span>
<span class="sd">        will be &#39;model_&#39;+name.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred</span>
<span class="sd">        to the GPU and computed with at one time.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lams</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200000</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lams</span> <span class="o">=</span> <span class="n">lams</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200000</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span>
    
<div class="viewcode-block" id="UnlabelledPredsMetric.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledPredsMetric.performance_check">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
        <span class="k">pass</span></div>


    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to pickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;ds&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>
    
    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to unpickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">ds</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">Dataset</span><span class="o">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">batch</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">prefetch</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">AUTOTUNE</span><span class="p">)</span><span class="o">.</span><span class="n">cache</span><span class="p">()</span></div>

    
<div class="viewcode-block" id="UnlabelledAgreement">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledAgreement">[docs]</a>
<span class="k">class</span> <span class="nc">UnlabelledAgreement</span><span class="p">(</span><span class="n">UnlabelledPredsMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric which computes agreement (Cohen&#39;s kappa) among</span>
<span class="sd">    the model between successive iterations of active learning</span>
<span class="sd">    on a specified set of unlabelled points.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of floats</span>
<span class="sd">        The entries of this status_history object will be Cohen&#39;s</span>
<span class="sd">        kappa between successive iterations of active learning on lams.</span>

<span class="sd">    old_preds : np.array(np.float32)</span>
<span class="sd">        The previous model&#39;s predictions on lams. Preserved to compare</span>
<span class="sd">        to the current model.</span>

<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential </span>
<span class="sd">        coefficients. This will be an unlabelled set of points </span>
<span class="sd">        the model will make predictions on.</span>

<span class="sd">    ds : tf.data.Dataset</span>
<span class="sd">        A Tensorflow dataset generated from lams.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred</span>
<span class="sd">        to the GPU and computed with at one time.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics</span>
<span class="sd">        traced by BFBLearner. By default this will be &#39;model_agreement&#39;</span>

<span class="sd">    n_trials : int, default=100</span>
<span class="sd">        The number of forward passes through the network to get the</span>
<span class="sd">        predictions from Monte Carlo dropout.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential</span>
<span class="sd">        coefficients. This will be an unlabelled set of points </span>
<span class="sd">        the model will make predictions on.</span>

<span class="sd">    name : str, default=&#39;agreement&#39;</span>
<span class="sd">        The name will provide a unique identifier for the metric</span>
<span class="sd">        in the list of metrics tracked by BFBLearner-- this identifier</span>
<span class="sd">        will be &#39;model_&#39;+name.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred</span>
<span class="sd">        to the GPU and computed with at one time.</span>

<span class="sd">    n_trials : int, default=100</span>
<span class="sd">        The number of forward passes through the network to get</span>
<span class="sd">        the predictions from Monte Carlo dropout.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lams</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;agreement&#39;</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200000</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lams</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="kc">None</span>

<div class="viewcode-block" id="UnlabelledAgreement.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledAgreement.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes Cohen&#39;s kappa for the classifier between successive</span>
<span class="sd">        active learning iterations, on the unlabelled quartic coefficients</span>
<span class="sd">        lams. If there is no previous model (i.e., no active learning has</span>
<span class="sd">        been done), returns 0. and saves the current model&#39;s predictions</span>
<span class="sd">        as old_preds.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_preds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">:</span>
                <span class="n">out_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">out_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">out_preds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="n">out_preds</span>
            <span class="k">return</span> <span class="mf">0.</span>

        <span class="n">out_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">:</span>
            <span class="n">out_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">out_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">out_preds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">Ao</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">)))</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">out_preds</span><span class="p">)</span>
        <span class="n">p_pos_new</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">out_preds</span><span class="p">)</span>
        <span class="n">p_pos_old</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span><span class="p">)</span>
        <span class="n">Ae</span> <span class="o">=</span> <span class="mf">2.</span><span class="o">*</span><span class="n">p_pos_new</span><span class="o">*</span><span class="n">p_pos_old</span> <span class="o">-</span> <span class="n">p_pos_new</span> <span class="o">-</span> <span class="n">p_pos_old</span> <span class="o">+</span> <span class="mf">1.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="n">out_preds</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">Ao</span> <span class="o">-</span><span class="n">Ae</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="n">Ae</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="UnlabelledAgreement.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledAgreement.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simply returns Cohen&#39;s kappa as a function of the number</span>
<span class="sd">        of active learning iterations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span></div>

    
<div class="viewcode-block" id="UnlabelledAgreement.reset_data">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledAgreement.reset_data">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the data in the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="kc">None</span></div>
</div>


<div class="viewcode-block" id="UnlabelledDeltaF">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledDeltaF">[docs]</a>
<span class="k">class</span> <span class="nc">UnlabelledDeltaF</span><span class="p">(</span><span class="n">UnlabelledPredsMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric which computes the estimated change in F score on a</span>
<span class="sd">    specified unlabelled set of points for the model between successive</span>
<span class="sd">    iterations of active learning on a specified set of unlabelled points,</span>
<span class="sd">    based on the methodology of arXiv:cs/1901.09118.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of floats</span>
<span class="sd">        The entries of this status_history object will be the estimated</span>
<span class="sd">        change in F score between successive iterations of active learning</span>
<span class="sd">        on lams.</span>

<span class="sd">    old_preds : np.array(np.float32)</span>
<span class="sd">        The previous model&#39;s predictions on lams. Preserved to compare</span>
<span class="sd">        to the current model.</span>

<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential </span>
<span class="sd">        coefficients. This will be an unlabelled set of points</span>
<span class="sd">        the model will make predictions on.</span>

<span class="sd">    ds : tf.data.Dataset</span>
<span class="sd">        A Tensorflow dataset generated from lams.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred </span>
<span class="sd">        to the GPU and computed with at one time.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics</span>
<span class="sd">        traced by BFBLearner. By default this will be &#39;model_delta_F&#39;</span>

<span class="sd">    n_trials : int, default=100</span>
<span class="sd">        The number of forward passes through the network to get the</span>
<span class="sd">        predictions from Monte Carlo dropout.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams : np.array(np.float32, np.float32)</span>
<span class="sd">        A 2-D NumPy array representing sets of quartic potential </span>
<span class="sd">        coefficients. This will be an unlabelled set of points the</span>
<span class="sd">        model will make predictions on.</span>

<span class="sd">    name : str, default=&#39;delta_F&#39;</span>
<span class="sd">        The name will provide a unique identifier for the metric </span>
<span class="sd">        in the list of metrics tracked by BFBLearner-- this </span>
<span class="sd">        identifier will be &#39;model_&#39;+name.</span>

<span class="sd">    batch_size : int, default=200000</span>
<span class="sd">        The maximum size of batches of lams that will be transferred </span>
<span class="sd">        to the GPU and computed with at one time.</span>

<span class="sd">    n_trials : int, default=100</span>
<span class="sd">        The number of forward passes through the network to get the </span>
<span class="sd">        predictions from Monte Carlo dropout.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lams</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;delta_F&#39;</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">200000</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="mi">100</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">lams</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>

<div class="viewcode-block" id="UnlabelledDeltaF.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledDeltaF.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the estimated change in F score for the classifier </span>
<span class="sd">        between successive active learning iterations, on the unlabelled </span>
<span class="sd">        quartic coefficients lams. If there is no previous model (i.e., </span>
<span class="sd">        no active learning has been done), returns np.inf and saves the</span>
<span class="sd">        current model&#39;s predictions as old_preds.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">out_preds</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">:</span>
                <span class="n">out_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">out_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">out_preds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="n">out_preds</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span>

        <span class="n">out_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">ds</span><span class="p">:</span>
            <span class="n">out_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
        <span class="n">out_preds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">out_preds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">))</span>
        <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">out_preds</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="n">out_preds</span>
        <span class="k">return</span> <span class="mf">1.</span> <span class="o">-</span> <span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">))</span></div>

    
<div class="viewcode-block" id="UnlabelledDeltaF.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledDeltaF.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Simply returns the change in F score as a function of the </span>
<span class="sd">        number of active learning iterations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span></div>

    
<div class="viewcode-block" id="UnlabelledDeltaF.reset_data">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.UnlabelledDeltaF.reset_data">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Resets the data in the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="kc">None</span></div>
</div>


<div class="viewcode-block" id="ValidationMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationMetric">[docs]</a>
<span class="k">class</span> <span class="nc">ValidationMetric</span><span class="p">(</span><span class="n">ALMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class for handling metrics which measure performance </span>
<span class="sd">    of the model on a validation set. This class exists primarily to </span>
<span class="sd">    remind the user that any validation-set-based performance metrics must </span>
<span class="sd">    have their performance_check method take the inputs </span>
<span class="sd">    (tf.keras.Model, tf.data.Dataset)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sc_type</span> <span class="o">=</span> <span class="s1">&#39;val&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
    
<div class="viewcode-block" id="ValidationMetric.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationMetric.performance_check">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The performance_check method now specifies the arguments that</span>
<span class="sd">        a class inheriting from ValidationMetric should use.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : tf.keras.Model</span>
<span class="sd">            The model in a BFBLearner object.</span>
<span class="sd">        </span>
<span class="sd">        ds : tf.data.Dataset</span>
<span class="sd">            A Tensorflow dataset representing the labelled validation</span>
<span class="sd">            set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</div>


<div class="viewcode-block" id="TrainMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.TrainMetric">[docs]</a>
<span class="k">class</span> <span class="nc">TrainMetric</span><span class="p">(</span><span class="n">ALMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class for handling metrics which measure predictions</span>
<span class="sd">    of the model on newly-added training data. This class exists primarily</span>
<span class="sd">    to remind the user that any training-set-based performance metrics </span>
<span class="sd">    must have their performance_check method take the inputs </span>
<span class="sd">    (tf.keras.Model, tf.Tensor)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sc_type</span> <span class="o">=</span> <span class="s1">&#39;train&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
    
<div class="viewcode-block" id="TrainMetric.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.TrainMetric.performance_check">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">lams</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The performance_check method now specifies the arguments that</span>
<span class="sd">        a class inheriting from TrainMetric should use.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : tf.keras.Model</span>
<span class="sd">            The model in a BFBLearner object.</span>
<span class="sd">            </span>
<span class="sd">        lams : tf.Tensor(tf.float32, tf.float32)</span>
<span class="sd">            A 2-D Tensorflow tensor representing sets of quartic</span>
<span class="sd">            potential coefficients. This will be all of the points</span>
<span class="sd">            that have been newly added to the training set in a </span>
<span class="sd">            given round of active learning.</span>

<span class="sd">        labels : tf.Tensor(bool)</span>
<span class="sd">            A 1-D Tensorflow tensor of booleans representing the</span>
<span class="sd">            labels of the new training data points. The ith element</span>
<span class="sd">            of this tensor is True if the ith row of lams represents</span>
<span class="sd">            a set of quartic potential coefficients that the oracle</span>
<span class="sd">            has labelled as bounded-from-below, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</div>


<div class="viewcode-block" id="PoolMetric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetric">[docs]</a>
<span class="k">class</span> <span class="nc">PoolMetric</span><span class="p">(</span><span class="n">ALMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class for handling metrics which measure predictions </span>
<span class="sd">    of the model on the pools of candidate points from which new training </span>
<span class="sd">    data is drawn. This class exists primarily to ensure that these </span>
<span class="sd">    metrics have additional abstract methods which much be specified to </span>
<span class="sd">    implement a class of this sort.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    batch_scores : list</span>
<span class="sd">        Because the pool of candidate points are generated in discrete </span>
<span class="sd">        manageable batches, the metrics are computed over each individual </span>
<span class="sd">        batch and then combined, the precise manner of which depends on </span>
<span class="sd">        the specific metric in question. However, all pool metrics must </span>
<span class="sd">        have this attribute to act as temporary storage of the individual </span>
<span class="sd">        batch results before they can be combined.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">sc_type</span> <span class="o">=</span> <span class="s1">&#39;pool&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
<div class="viewcode-block" id="PoolMetric.record_batch">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetric.record_batch">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">record_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;An abstract method which will record an individual batch&#39;s </span>
<span class="sd">        results to batch_scores, in a manner that must be specified </span>
<span class="sd">        in a subclass.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>

    
<div class="viewcode-block" id="PoolMetric.record_score">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetric.record_score">[docs]</a>
    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">record_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The concrete record_score method of the ALMetric class </span>
<span class="sd">        must be overwritten with an abstract version,</span>
<span class="sd">        which must in turn be specified in subclasses.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">pass</span></div>
</div>




<div class="viewcode-block" id="PoolMetricReduction">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction">[docs]</a>
<span class="k">class</span> <span class="nc">PoolMetricReduction</span><span class="p">(</span><span class="n">PoolMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;An abstract class which inherits from PoolMetric, but features </span>
<span class="sd">    methods to automatically take the mean/min/max of the scores </span>
<span class="sd">    determined in record_batch. This is an abstract class which </span>
<span class="sd">    shouldn&#39;t be instantiated directly, but allows for rapid prototyping </span>
<span class="sd">    of a variety of pool metrics.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    reduction : a list containing elements of {np.mean, np.min, np.max}</span>
<span class="sd">        This is the reduction that is performed on individual batches, </span>
<span class="sd">        and finally, among the results for all batches, to produce the </span>
<span class="sd">        entries in status_history. If a list of reductions are applied, </span>
<span class="sd">        then the elements of status_history will be lists with each </span>
<span class="sd">        element being a different reduction being applied to the pool score.</span>
<span class="sd">    red_name : a list containing elements of {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;}</span>
<span class="sd">        This list of strings will contain the same information as </span>
<span class="sd">        reduction, but is used for labelling purposes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        A unique identifier for the metric in the list of metrics in a </span>
<span class="sd">        BFBLearner object.</span>
<span class="sd">    red : {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;} or a list of those values</span>
<span class="sd">        This argument specifies the reduction that is performed on </span>
<span class="sd">        individual batches, and finally, among the results for all </span>
<span class="sd">        batches, to produce the entries in status_history.</span>
<span class="sd">        If a list of reductions are applied, then the elements of </span>
<span class="sd">        status_history will be lists with each element being a different </span>
<span class="sd">        reduction being applied to the pool score.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">red</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">]):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span> <span class="o">=</span> <span class="n">_get_reduction</span><span class="p">(</span><span class="n">red</span><span class="p">)</span>
        <span class="k">if</span> <span class="s1">&#39;std&#39;</span> <span class="ow">in</span> <span class="n">red</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Do not request standard deviation for scores found from the pool of candidate points-- insufficient data is stored to compute this quantity.&#39;</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span> <span class="o">=</span> <span class="p">[]</span>
    
<div class="viewcode-block" id="PoolMetricReduction.record_batch">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.record_batch">[docs]</a>
    <span class="k">def</span> <span class="nf">record_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Records a score generated by performance_check (which must be </span>
<span class="sd">        specified in a subclass) for an individual batch in the pool of </span>
<span class="sd">        candidate points to the batch_scores list.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">performance_check</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">))</span></div>


<div class="viewcode-block" id="PoolMetricReduction.record_score">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.record_score">[docs]</a>
    <span class="k">def</span> <span class="nf">record_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combines the metrics computed for each batch into a single </span>
<span class="sd">        status_history entry, and append that entry to status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="o">.</span><span class="n">append</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">[</span><span class="n">i</span><span class="p">]([</span><span class="n">b_score</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">b_score</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">))])</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>

    
<div class="viewcode-block" id="PoolMetricReduction.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of </span>
<span class="sd">        the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (unlabelled pool) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">))</span></div>


<div class="viewcode-block" id="PoolMetricReduction.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reduction : str in self.red_name, optional</span>
<span class="sd">            If specified, get_metric will only return the values </span>
<span class="sd">            corresponding to the specified reduction. If not specified,</span>
<span class="sd">            get_metric will return the status_history object </span>
<span class="sd">            in its entirety.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.array</span>
<span class="sd">            Represents some plottable set of values from status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_check_reduction</span><span class="p">(</span><span class="n">reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">reduction</span><span class="p">)]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="PoolMetricReduction.reset_data">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.reset_data">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Reset the data in status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_data</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_scores</span> <span class="o">=</span> <span class="p">[]</span></div>

    
<div class="viewcode-block" id="PoolMetricReduction.get_legend">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolMetricReduction.get_legend">[docs]</a>
    <span class="k">def</span> <span class="nf">get_legend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_legend can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reduction : str in self.red_name, optional</span>
<span class="sd">            get_legend will return a legend consistent with the get_metric</span>
<span class="sd">            result with the same reduction argument passed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of str</span>
<span class="sd">            An argument to specify a legend in matplotlib.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">reduction</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">red</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">red</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">]</span></div>
</div>


<span class="c1"># A metric for keeping track of the estimated change in F score for successive iterations of the active learning algorithm on unlabelled data, based on arXiv:cs/1901.09118</span>
<div class="viewcode-block" id="PoolDeltaF">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolDeltaF">[docs]</a>
<span class="k">class</span> <span class="nc">PoolDeltaF</span><span class="p">(</span><span class="n">PoolMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric for keeping track of the estimated change in F score for </span>
<span class="sd">    successive iterations of the active learning algorithm on unlabelled </span>
<span class="sd">    data, based on arXiv:cs/1901.09118. Each time active learning </span>
<span class="sd">    produces a new unlabelled pool of candidate points to draw training </span>
<span class="sd">    examples from, this metric computes the model&#39;s predicted labels for </span>
<span class="sd">    all of these points, and stores both the pool of points and the </span>
<span class="sd">    predictions. Then, after another round of active learning, the metric </span>
<span class="sd">    computes the NEW model&#39;s predicted labels on the stored pool of </span>
<span class="sd">    points. Then, the two sets of predictions are compared and the </span>
<span class="sd">    estimated change in F score over the pool distribution is computed </span>
<span class="sd">    from the level of agreement between the two sets of predictions,</span>
<span class="sd">    following the procedure outlined in arXiv:cs/1901.09118. Predictions </span>
<span class="sd">    are based on Monte Carlo dropout with 100 forward passes through the </span>
<span class="sd">    neural network.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of floats</span>
<span class="sd">        A list which contains a record, for each round of active learning, </span>
<span class="sd">        of the estimated change in F score.</span>

<span class="sd">    name : str, default=&#39;delta_F&#39;</span>
<span class="sd">        A string which denotes a name for this metric. In a list of </span>
<span class="sd">        metrics passed to a BFBLearner class, the names of each member </span>
<span class="sd">        of the list should be unique.</span>

<span class="sd">    old_pool : list of np.array(np.float32, np.float32)</span>
<span class="sd">        A list of 2-D NumPy arrays, each of which represents a batch </span>
<span class="sd">        of points generated as part of the pool of candidate points </span>
<span class="sd">        in active learning. This array stores the points that made </span>
<span class="sd">        up the PREVIOUS round&#39;s pool of points, so that the current model </span>
<span class="sd">        can make predictions on them.</span>

<span class="sd">    new_pool : list of np.array(np.float32, np.float32)</span>
<span class="sd">        A list of 2-D NumPy arrays, each of which represents a batch of </span>
<span class="sd">        points generated as part of the pool of candidate points in </span>
<span class="sd">        active learning. This array stores the points that made up the </span>
<span class="sd">        CURRENT round&#39;s pool of points, so that the current model can make </span>
<span class="sd">        predictions on them. After recording the status_history value for </span>
<span class="sd">        this metric, new_pool&#39;s values are transferred to old_pool, and </span>
<span class="sd">        then new_pool is cleared.</span>

<span class="sd">    old_preds : list of np.array(np.float32)</span>
<span class="sd">        A list to contain all of the PREVIOUS model&#39;s predictions on </span>
<span class="sd">        old_pool.</span>

<span class="sd">    new_preds : list of np.array(np.float32)</span>
<span class="sd">        A list to contain all of the CURRENT model&#39;s predictions on </span>
<span class="sd">        old_pool.</span>

<span class="sd">    newer_preds : list of np.array(np.float32)</span>
<span class="sd">        A list to contain all of the CURRENT model&#39;s predictions </span>
<span class="sd">        on new_pool. After recording the status_history value for </span>
<span class="sd">        this metric, newer_preds values are transferred to old_preds, </span>
<span class="sd">        and then newer_preds and new_preds are both cleared.</span>

<span class="sd">    old_pool_iter : iter</span>
<span class="sd">        An iterator over old_pool. Replaced whenever old_pool is </span>
<span class="sd">        overwritten.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;delta_F&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
        <span class="c1"># Predictions of the last model on old_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Predictions of the current model on old_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Predictions of the current model on new_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_pool</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span><span class="p">)</span>
    
<div class="viewcode-block" id="PoolDeltaF.record_batch">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolDeltaF.record_batch">[docs]</a>
    <span class="k">def</span> <span class="nf">record_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Records newly-generated pool points and the current model&#39;s </span>
<span class="sd">        prediction on them. After the first active learning iteration, </span>
<span class="sd">        also records the current model&#39;s predictions on the corresponding </span>
<span class="sd">        element of old_pool, since after the first active learning </span>
<span class="sd">        iteration the old_pool and new_pool will always have the same </span>
<span class="sd">        number of elements.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : tf.keras.model</span>
<span class="sd">            The current Tensorflow model of a BFBLearner object.</span>

<span class="sd">        L : np.array(np.float32, np.float32)</span>
<span class="sd">            A 2-D NumPy array representing a batch of pool points </span>
<span class="sd">            proposed to the neural network as possible training points.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">scores</span><span class="p">,</span> <span class="n">pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">performance_check</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">L</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">old_scores</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="nb">next</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_pool_iter</span><span class="p">),</span> <span class="mi">1000</span><span class="p">),</span><span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">old_scores</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scores</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_pool</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">pool</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="PoolDeltaF.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolDeltaF.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">L</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the predictions of the neural network on an input </span>
<span class="sd">        batch of pool points, and returns a tuple of the predictions </span>
<span class="sd">        and the pool points.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        model : tf.keras.model</span>
<span class="sd">            The current Tensorflow model of a BFBLearner object.</span>

<span class="sd">        L : np.array(np.float32, np.float32)</span>
<span class="sd">            A 2-D NumPy array representing a batch of pool points </span>
<span class="sd">            proposed to the neural network as possible training points.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.array(np.float32)</span>
<span class="sd">            A 1-D NumPy array of model predictions on L</span>

<span class="sd">        np.array(np.float32, np.float32)</span>
<span class="sd">            The array L</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">L</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">L</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span></div>


<div class="viewcode-block" id="PoolDeltaF.record_score">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolDeltaF.record_score">[docs]</a>
    <span class="k">def</span> <span class="nf">record_score</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Combines the predictions made on individual batches </span>
<span class="sd">        in order to produce an estimate of the change in F score on </span>
<span class="sd">        old_pool, and appends this estimate onto status_history. Then, </span>
<span class="sd">        overwrites old_pool with new_pool, old_preds with newer_preds, </span>
<span class="sd">        and then resets new_pool, new_preds, and newer_preds.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        float</span>
<span class="sd">            The last element of status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="p">):</span>
            <span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span>
            <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="p">)):</span>
                <span class="n">a</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">))</span>
                <span class="n">b</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span><span class="mf">0.5</span><span class="p">))</span>
                <span class="n">c</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">))</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="mf">1.</span> <span class="o">-</span> <span class="p">((</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">a</span> <span class="o">+</span> <span class="n">b</span> <span class="o">+</span> <span class="n">c</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">new_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_pool</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span></div>

    
<div class="viewcode-block" id="PoolDeltaF.reset_data">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolDeltaF.reset_data">[docs]</a>
    <span class="k">def</span> <span class="nf">reset_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Clears all data in the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">reset_data</span><span class="p">()</span>
        <span class="c1"># Predictions of the last model on old_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Predictions of the current model on old_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_preds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="c1"># Predictions of the current model on new_pool</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">newer_preds</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">new_pool</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">old_pool_iter</span> <span class="o">=</span> <span class="nb">iter</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">old_pool</span><span class="p">)</span></div>
</div>



<span class="c1"># A metric that simply records the model.evaluate() method on a Tensorflow dataset. Generally used to check the accuracy of the model on a validation set.</span>
<div class="viewcode-block" id="ModelEvaluation">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelEvaluation">[docs]</a>
<span class="k">class</span> <span class="nc">ModelEvaluation</span><span class="p">(</span><span class="n">ValidationMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that simply records the model.evaluate() method on a </span>
<span class="sd">    labelled Tensorflow dataset (the validation set in our context). </span>
<span class="sd">    BFBrain&#39;s call to Tensorflow&#39;s evaluate method keeps track of the </span>
<span class="sd">    model accuracy, false positives, and false negatives via evaluate(). </span>
<span class="sd">    Note that this method does NOT use Monte Carlo dropout to compute </span>
<span class="sd">    these quantities, but instead approximates the mean of Monte Carlo </span>
<span class="sd">    dropout via a single pass through the network with no dropout </span>
<span class="sd">    (and all model weights divided by 1 - &lt;dropout probability&gt;).</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of lists of np.float32</span>
<span class="sd">        The entries of status_history here will be lists of the form </span>
<span class="sd">        [&lt;binary accuracy&gt;, &lt;false positives&gt;, &lt;false negatives&gt;], </span>
<span class="sd">        evaluated over the validation set.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics traced </span>
<span class="sd">        by BFBLearner. By default, this will be &#39;val_accuracy&#39;.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str, default=&#39;accuracy&#39;</span>
<span class="sd">        The name will provide a unique identifier for the metric in the </span>
<span class="sd">        list of metrics tracked by BFBLearner-- this identifier will be </span>
<span class="sd">        &#39;val_&#39;+name.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;accuracy&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

<div class="viewcode-block" id="ModelEvaluation.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelEvaluation.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This performance_check simply calls Tensorflow&#39;s </span>
<span class="sd">        model.evaluate() method, and ignores the first term (the loss)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span></div>

    
<div class="viewcode-block" id="ModelEvaluation.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelEvaluation.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s1">&#39;Validation accuracy [accuracy, false positives, false negatives]:&#39;</span></div>

    
<div class="viewcode-block" id="ModelEvaluation.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ModelEvaluation.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;For plotting, this metric simply requests the binary accuracy </span>
<span class="sd">        over the active learning iterations.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span></div>
</div>


<span class="c1"># A metric that records the binary accuracy, false positives, and false negatives evaluated with Monte Carlo dropout on a Tensorflow dataset.</span>
<div class="viewcode-block" id="MCModelEvaluation">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.MCModelEvaluation">[docs]</a>
<span class="k">class</span> <span class="nc">MCModelEvaluation</span><span class="p">(</span><span class="n">ValidationMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that records the same data as ModelEvaluation on a </span>
<span class="sd">    labelled Tensorflow dataset (the validation set in our context),</span>
<span class="sd">    but using Monte Carlo dropout with 100 forward passes through </span>
<span class="sd">    the neural network. Otherwise functions identically to ModelEvaluation.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics traced </span>
<span class="sd">        by BFBLearner. By default, this will be &#39;val_MC_accuracy&#39;.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    name : str, default=&#39;MC_accuracy&#39;</span>
<span class="sd">        The name will provide a unique identifier for the metric in the </span>
<span class="sd">        list of metrics tracked by BFBLearner-- this identifier will be </span>
<span class="sd">        &#39;val_&#39;+name.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;MC_accuracy&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

<div class="viewcode-block" id="MCModelEvaluation.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.MCModelEvaluation.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;This performance_check finds the binary accuracy, </span>
<span class="sd">        false positives, and false negatives over a validation data set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">false_pos</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">false_neg</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="n">total</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">:</span>
            <span class="n">total</span> <span class="o">+=</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
            <span class="n">false_pos</span> <span class="o">=</span> <span class="n">false_pos</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">result</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">~</span><span class="n">y</span><span class="p">))</span>
            <span class="n">false_neg</span> <span class="o">=</span> <span class="n">false_neg</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">result</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="k">return</span> <span class="p">[</span><span class="mf">1.</span><span class="o">-</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">false_pos</span> <span class="o">+</span> <span class="n">false_neg</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">total</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">false_pos</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">false_neg</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span></div>

    
<div class="viewcode-block" id="MCModelEvaluation.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.MCModelEvaluation.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="s1">&#39;MC validation accuracy [accuracy, false positives, false negatives]:&#39;</span></div>

    
<div class="viewcode-block" id="MCModelEvaluation.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.MCModelEvaluation.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">][</span><span class="mi">1</span><span class="p">:]]))</span></div>
</div>


<div class="viewcode-block" id="DecisionBoundaryScore">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.DecisionBoundaryScore">[docs]</a>
<span class="k">class</span> <span class="nc">DecisionBoundaryScore</span><span class="p">(</span><span class="n">ValidationMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric which records a &quot;decision boundary score&quot;-- for each point </span>
<span class="sd">    that the (non-MC-dropout) neural network classifies incorrectly in a </span>
<span class="sd">    validation set, this method uses gradient ascent/descent to determine </span>
<span class="sd">    the angular distance on the hypersphere of quartic coeffecients to the </span>
<span class="sd">    decision boundary. Reports the results of the mean, </span>
<span class="sd">    standard deviation, and max of these scores in radians for both </span>
<span class="sd">    false positives and false negatives, as well as the number of points </span>
<span class="sd">    in both groups which exceed some input number of radians distance from </span>
<span class="sd">    the decision boundary. This metric can be extremely computationally </span>
<span class="sd">    intensive, and generally can reflect the deterministic forward pass&#39;s </span>
<span class="sd">    tendency to occasionally be incorrect and very overconfident. </span>
<span class="sd">    However, if a user is insistent on only using a single forward pass </span>
<span class="sd">    of the neural network to evaluate a network, this method enables them </span>
<span class="sd">    to be somewhat confident that any points that are mislabelled will be </span>
<span class="sd">    close in parameter space to points which are correctly labelled.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of tuples of lists of np.float32</span>
<span class="sd">        The entries of status_history here will contain a tuple of two </span>
<span class="sd">        lists of the form [&lt;mean&gt;, &lt;std&gt;, &lt;max&gt;, # &gt; tol_dist radians], </span>
<span class="sd">        the first for false positives and the second for false negatives. </span>
<span class="sd">        The mean, standard deviation, and max values are computed from </span>
<span class="sd">        the angular distance (in radians) of the incorrectly classified </span>
<span class="sd">        points to points along the decision boundary. The final entry </span>
<span class="sd">        is the number of points for which this distance is greater than </span>
<span class="sd">        some user-specified cutoff, tol_dist.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics </span>
<span class="sd">        traced by BFBLearner. By default, this will be </span>
<span class="sd">        &#39;val_combined_false_score&#39;.</span>

<span class="sd">    tol_dist : float</span>
<span class="sd">        The maximum angular distance of an incorrectly-classified point </span>
<span class="sd">        to the decision boundary that the user considers acceptable. For </span>
<span class="sd">        small (O(0.01)) values of this angle, it roughly corresponds to </span>
<span class="sd">        the fractional degree of correction of the quartic coefficients </span>
<span class="sd">        to reach the decision boundary-- so an angular deformation of 0.01 </span>
<span class="sd">        represents approximately a 1% correction to the quartic coupling </span>
<span class="sd">        coefficients.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tol_dist : float</span>
<span class="sd">        The maximum angular distance of an incorrectly-classified point </span>
<span class="sd">        to the decision boundary that the user considers acceptable. For </span>
<span class="sd">        small (O(0.01)) values of this angle, it roughly corresponds to </span>
<span class="sd">        the fractional degree of correction of the quartic coefficients </span>
<span class="sd">        to reach the decision boundary-- so an angular deformation of 0.01 </span>
<span class="sd">        represents approximately a 1% correction to the quartic coupling </span>
<span class="sd">        coefficients.</span>

<span class="sd">    name : str, default=&#39;combined_false_score&#39;</span>
<span class="sd">        The name will provide a unique identifier for the metric in the </span>
<span class="sd">        list of metrics tracked by BFBLearner-- this identifier will be </span>
<span class="sd">        &#39;val_&#39;+name.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tol_dist</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="s1">&#39;combined_false_score&#39;</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">tol_dist</span> <span class="o">=</span> <span class="n">tol_dist</span>
    
<div class="viewcode-block" id="DecisionBoundaryScore.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.DecisionBoundaryScore.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the angular distances between incorrectly classified </span>
<span class="sd">        points and the decision boundary.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">bin_acc</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">ds</span><span class="p">,</span> <span class="n">verbose</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">if</span> <span class="n">bin_acc</span> <span class="o">&lt;</span> <span class="mf">0.99</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">],</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">inf</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">combined_false_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tol_dist</span><span class="p">)))</span></div>

    
<div class="viewcode-block" id="DecisionBoundaryScore.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.DecisionBoundaryScore.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="s1">&#39;false positive score [mean, std, max, # &gt; </span><span class="si">{}</span><span class="s1">]:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tol_dist</span><span class="p">),</span> <span class="s1">&#39;false negative score [mean, std, max, # &gt; </span><span class="si">{}</span><span class="s1">]:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tol_dist</span><span class="p">))</span></div>

    
<div class="viewcode-block" id="DecisionBoundaryScore.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.DecisionBoundaryScore.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Returns the number of false positives and false negatives </span>
<span class="sd">        greater than tol_dist radians from the decision boundary </span>
<span class="sd">        (tracked separately) for plotting over the course of active </span>
<span class="sd">        learning.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span> <span class="o">+</span> <span class="n">stat</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]]))</span></div>
</div>



<div class="viewcode-block" id="ValidationConfusionMatrix">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationConfusionMatrix">[docs]</a>
<span class="k">class</span> <span class="nc">ValidationConfusionMatrix</span><span class="p">(</span><span class="n">ValidationMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that finds the elements of the confusion matrix (correctly </span>
<span class="sd">    labelled positives, false positives, correctly labelled negatives, </span>
<span class="sd">    false negatives) for the validation set. Also calculates the confusion </span>
<span class="sd">    matrix with points which score higher than specified quantiles on </span>
<span class="sd">    some specified uncertainty metric, evaluated over all points which </span>
<span class="sd">    have the same predicted classification, omitted from the validation </span>
<span class="sd">    set. This metric in turn has all the information necessary for the </span>
<span class="sd">    extraction of binary classifier quality metrics such as precision, </span>
<span class="sd">    recall, or F score.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of tuples of lists of ints</span>
<span class="sd">        The elements status_history here are tuples of the form</span>
<span class="sd">        (&lt;true positives&gt;, &lt;false positives&gt;, &lt;true negatives&gt;, &lt;false negatives&gt;),</span>
<span class="sd">        where each element of the tuple is a list of length equal to the </span>
<span class="sd">        length of the attribute quantiles. Each element of the lists are </span>
<span class="sd">        the values of that observable assuming that we only include points </span>
<span class="sd">        with an uncertainty score (given by score_fn) less than or equal </span>
<span class="sd">        to the corresponding quantile (evaluated for all points of the </span>
<span class="sd">        same predicted class) in quantiles.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics traced </span>
<span class="sd">        by BFBLearner. By default this will be &#39;val_&lt;score_fn&gt;_confusion&#39;</span>

<span class="sd">    score_fn : callable</span>
<span class="sd">        A callable of the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).</span>
<span class="sd">        The pre-implemented functions for different uncertainty metrics </span>
<span class="sd">        can be specified in the constructor by using any of </span>
<span class="sd">        &#39;BALD&#39; (mutual information), &#39;MaxEntropy&#39; (Shannon entropy), </span>
<span class="sd">        &#39;variation_ratios&#39; (variation ratios), </span>
<span class="sd">        &#39;predictive_variance&#39; (variance of the prediction distribution),</span>
<span class="sd">        or &#39;QBDC&#39; (score*(1-score), where score is the Monte Carlo </span>
<span class="sd">        dropout-evaluated prediction for an input)</span>

<span class="sd">    tf_score_fn : jit-compiled callable</span>
<span class="sd">        Tensorflow jit-compiled version of score_fn.</span>

<span class="sd">    n_trials : int or None</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_fn : {&#39;BALD&#39;, &#39;MaxEntropy&#39;, &#39;variation_ratios&#39;, &#39;random&#39;, &#39;QBDC&#39;, &#39;predictive_variance&#39;} or callable</span>
<span class="sd">        Specifies the score function that the metric will apply to the </span>
<span class="sd">        pool of candidate points. If a callable (corresponding to a custom </span>
<span class="sd">        score function) is used, it must have the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),</span>
<span class="sd">        depending on whether or not n_trials is specified.</span>

<span class="sd">    name : str, optional</span>
<span class="sd">        Allows for a custom name of the metric. If this argument is not </span>
<span class="sd">        specified, a name will be automatically generated as </span>
<span class="sd">        &#39;val_&lt;score_fn&gt;_confusion&#39;.</span>

<span class="sd">    quantiles : list of floats, default=[0.95, 1.]</span>
<span class="sd">        The uncertainty quantiles for which the metric is tracked (see </span>
<span class="sd">        the status_history documentation)</span>

<span class="sd">    n_trials : int, optional</span>
<span class="sd">        For score_fn arguments that take a n_trials argument, which </span>
<span class="sd">        includes every pre-implemented score_fn except &#39;random&#39;, this </span>
<span class="sd">        argument can be specified here. If it is not specified, the </span>
<span class="sd">        default value for the given score_fn is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score_fn</span> <span class="o">=</span> <span class="s1">&#39;BALD&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">quantiles</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">auto_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">process_score_fn</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span> <span class="o">=</span> <span class="n">score_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="k">if</span> <span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span> <span class="o">=</span> <span class="n">quantiles</span>
        
        <span class="k">if</span> <span class="n">auto_name</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_confusion&#39;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    
<div class="viewcode-block" id="ValidationConfusionMatrix.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationConfusionMatrix.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Finds the confusion matrix (true positives, false positives, </span>
<span class="sd">        true negatives, false negatives) for the model over the validation </span>
<span class="sd">        set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">uncert</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fp_inds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">fn_inds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">pos_inds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">neg_inds</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="n">ind_displacement</span> <span class="o">=</span> <span class="mi">0</span>
        <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">:</span>
            <span class="n">uncert</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
            <span class="n">results</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">MC_call_fast</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">pos_inds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">results</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">ind_displacement</span><span class="p">)</span>
            <span class="n">neg_inds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">results</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">ind_displacement</span><span class="p">)</span>
            <span class="n">fp_inds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">results</span> <span class="o">&gt;=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="o">~</span><span class="n">y</span><span class="p">)),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">ind_displacement</span><span class="p">)</span>
            <span class="n">fn_inds</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">results</span> <span class="o">&lt;</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">y</span><span class="p">)),</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span> <span class="o">+</span> <span class="n">ind_displacement</span><span class="p">)</span>
            <span class="n">ind_displacement</span> <span class="o">+=</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">y</span><span class="p">)[</span><span class="mi">0</span><span class="p">])</span>
        
        <span class="n">uncert</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">uncert</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">pos_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">pos_inds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">neg_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">neg_inds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">fp_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">fp_inds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
        <span class="n">fn_inds</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">(</span><span class="n">fn_inds</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">p_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">uncert</span><span class="p">[</span><span class="n">pos_inds</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">neg_inds</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">n_quantiles</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">uncert</span><span class="p">[</span><span class="n">neg_inds</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)</span>
        
        <span class="k">def</span> <span class="nf">get_confusion</span><span class="p">(</span><span class="n">f_inds</span><span class="p">,</span> <span class="n">inds</span><span class="p">,</span> <span class="n">quants</span><span class="p">):</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">inds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">false</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
                <span class="n">true</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">true</span><span class="p">,</span> <span class="n">false</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">f_inds</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">true</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">uncert</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
                <span class="n">false</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
                <span class="k">return</span> <span class="n">true</span><span class="p">,</span> <span class="n">false</span>
            <span class="n">total</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">uncert</span><span class="p">[</span><span class="n">inds</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
            <span class="n">false</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">count_nonzero</span><span class="p">(</span><span class="n">uncert</span><span class="p">[</span><span class="n">f_inds</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="n">quants</span><span class="p">]</span>
            <span class="n">true</span> <span class="o">=</span> <span class="p">[</span><span class="n">total</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">-</span> <span class="n">false</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">quants</span><span class="p">))]</span>
            <span class="k">return</span> <span class="n">true</span><span class="p">,</span> <span class="n">false</span>

        <span class="n">true_pos</span><span class="p">,</span> <span class="n">false_pos</span> <span class="o">=</span> <span class="n">get_confusion</span><span class="p">(</span><span class="n">fp_inds</span><span class="p">,</span> <span class="n">pos_inds</span><span class="p">,</span> <span class="n">p_quantiles</span><span class="p">)</span>
        <span class="n">true_neg</span><span class="p">,</span> <span class="n">false_neg</span> <span class="o">=</span> <span class="n">get_confusion</span><span class="p">(</span><span class="n">fn_inds</span><span class="p">,</span> <span class="n">neg_inds</span><span class="p">,</span> <span class="n">n_quantiles</span><span class="p">)</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">true_pos</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">true_neg</span><span class="p">,</span> <span class="n">false_neg</span><span class="p">)</span></div>

        
    
<div class="viewcode-block" id="ValidationConfusionMatrix.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationConfusionMatrix.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation true positives) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation false positives) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)),</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation true negatives) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation false negatives) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)))</span></div>


<div class="viewcode-block" id="ValidationConfusionMatrix.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationConfusionMatrix.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        quantile : float in self.quantiles, optional</span>
<span class="sd">            If specified, get_metric will only return the values </span>
<span class="sd">            corresponding to the false positives and false negatives </span>
<span class="sd">            found with uncertainty scores less than or equal to the </span>
<span class="sd">            given quantile. Otherwise, all false positives and false </span>
<span class="sd">            negatives for all quantiles will be returned for plotting.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.array</span>
<span class="sd">            Represents some plottable set of values from status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quantile</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Please specify a quantile that the metric has recorded. Options are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">quantile</span><span class="p">)]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">],</span> <span class="p">[</span><span class="n">stat</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">quantile</span><span class="p">)]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="n">stat</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span></div>


<div class="viewcode-block" id="ValidationConfusionMatrix.get_legend">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationConfusionMatrix.get_legend">[docs]</a>
    <span class="k">def</span> <span class="nf">get_legend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        quantile : float in self.quantiles, optional</span>
<span class="sd">            The method will return a legend appropriate for plotting </span>
<span class="sd">            get_metric, when get_metric is given the same arguments.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of str</span>
<span class="sd">            A list of strings representing a plot legend for matplotlib.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quantile</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Please specify a quantile that the metric has recorded. Options are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">))</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;false_positives_quantile_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quantile</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;false_negatives_quantile_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quantile</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;false_positives_quantile_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;false_negatives_quantile_</span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">]</span></div>

    
    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to pickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;tf_score_fn&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>
    
    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to unpickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></div>


<span class="c1"># A metric which gives the precision, recall, and F score with various quantiles of an uncertainty metric excluded from the validation set.</span>
<div class="viewcode-block" id="ValidationFScore">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationFScore">[docs]</a>
<span class="k">class</span> <span class="nc">ValidationFScore</span><span class="p">(</span><span class="n">ValidationConfusionMatrix</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric that finds the precision, recall, and F score for the </span>
<span class="sd">    validation set. Also calculates the confusion matrix with points </span>
<span class="sd">    which score higher than specified quantiles on some specified </span>
<span class="sd">    uncertainty metric, evaluated over all points which have the same</span>
<span class="sd">    predicted classification, omitted from the validation set. This metric </span>
<span class="sd">    in turn has all the information necessary for the extraction of binary </span>
<span class="sd">    classifier quality metrics such as precision, recall, or F score.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of lists of lists of floats</span>
<span class="sd">        The elements of the status_history object here are lists of the </span>
<span class="sd">        form [&lt;precision&gt;, &lt;recall&gt;, &lt;F score&gt;], where each element of the </span>
<span class="sd">        tuple is a list of length equal to the length of the attribute </span>
<span class="sd">        quantiles. Each element of the lists are the values of that </span>
<span class="sd">        observable assuming that we only include points with an uncertainty </span>
<span class="sd">        score (given by score_fn) less than or equal to the corresponding </span>
<span class="sd">        quantile (evaluated for all points of the same predicted class) </span>
<span class="sd">        in quantiles.</span>

<span class="sd">    name : str</span>
<span class="sd">        The unique identifier for the metric in the list of metrics traced </span>
<span class="sd">        by BFBLearner. By default this will be &#39;val_&lt;score_fn&gt;_fscore&#39;</span>

<span class="sd">    score_fn : callable</span>
<span class="sd">        A callable of the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).</span>
<span class="sd">        The pre-implemented functions for different uncertainty metrics </span>
<span class="sd">        can be specified in the constructor by using any of </span>
<span class="sd">        &#39;BALD&#39; (mutual information), &#39;MaxEntropy&#39; (Shannon entropy), </span>
<span class="sd">        &#39;variation_ratios&#39; (variation ratios), </span>
<span class="sd">        &#39;predictive_variance&#39; (variance of the prediction distribution),</span>
<span class="sd">        or &#39;QBDC&#39; (score*(1-score), where score is the Monte Carlo </span>
<span class="sd">        dropout-evaluated prediction for an input)</span>

<span class="sd">    tf_score_fn : jit-compiled callable</span>
<span class="sd">        Tensorflow jit-compiled version of score_fn.</span>

<span class="sd">    n_trials : int or None</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_fn : {&#39;BALD&#39;, &#39;MaxEntropy&#39;, &#39;variation_ratios&#39;, &#39;random&#39;, &#39;QBDC&#39;, &#39;predictive_variance&#39;} or callable</span>
<span class="sd">        Specifies the score function that the metric will apply to the pool </span>
<span class="sd">        of candidate points. If a callable (corresponding to a custom </span>
<span class="sd">        score function) is used, it must have the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),</span>
<span class="sd">        depending on whether or not n_trials is specified.</span>

<span class="sd">    name : str, optional</span>
<span class="sd">        Allows for a custom name of the metric. If this argument is not </span>
<span class="sd">        specified, a name will be automatically generated as </span>
<span class="sd">        &#39;val_&lt;score_fn&gt;_fscore&#39;.</span>

<span class="sd">    quantiles : list of floats, default=[0.95, 1.]</span>
<span class="sd">        The uncertainty quantiles for which the metric is tracked </span>
<span class="sd">        (see the status_history documentation)</span>

<span class="sd">    n_trials : int, optional</span>
<span class="sd">        For score_fn arguments that take a n_trials argument, which </span>
<span class="sd">        includes every pre-implemented score_fn except &#39;random&#39;, this </span>
<span class="sd">        argument can be specified here. If it is not specified, the </span>
<span class="sd">        default value for the given score_fn is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score_fn</span> <span class="o">=</span> <span class="s1">&#39;BALD&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">quantiles</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.95</span><span class="p">,</span> <span class="mf">1.</span><span class="p">],</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">auto_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">name</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">)</span>
        <span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">process_score_fn</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">auto_name</span><span class="p">:</span>
            <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="o">+</span><span class="s1">&#39;_fscore&#39;</span><span class="p">,</span> <span class="n">quantiles</span><span class="p">,</span> <span class="n">n_trials</span><span class="p">)</span>

<div class="viewcode-block" id="ValidationFScore.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationFScore.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the precision, recall, and F score over the validation </span>
<span class="sd">        set.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">confusion</span> <span class="o">=</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">performance_check</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">)</span>
        <span class="n">prec</span> <span class="o">=</span> <span class="p">[</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">confusion</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span>
        <span class="n">rec</span> <span class="o">=</span> <span class="p">[</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">confusion</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">confusion</span><span class="p">[</span><span class="mi">0</span><span class="p">]))]</span>
        <span class="n">fscore</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2</span><span class="o">*</span><span class="n">prec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">*</span><span class="n">rec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">+</span> <span class="n">rec</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">prec</span><span class="p">))]</span>
        <span class="k">return</span> <span class="p">(</span><span class="n">prec</span><span class="p">,</span> <span class="n">rec</span><span class="p">,</span> <span class="n">fscore</span><span class="p">)</span></div>

    
<div class="viewcode-block" id="ValidationFScore.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationFScore.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation precision) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)),</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation recall) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)),</span> 
                <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (validation F score) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">)))</span></div>


<div class="viewcode-block" id="ValidationFScore.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationFScore.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        quantile : float in self.quantiles, optional</span>
<span class="sd">            If specified, get_metric will only return the values </span>
<span class="sd">            corresponding to the F score found with uncertainty scores</span>
<span class="sd">            less than or equal to the given quantile. Otherwise, all </span>
<span class="sd">            F scores for all quantiles will be returned for plotting.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.array</span>
<span class="sd">            Represents some plottable set of values from status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quantile</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Please specify a quantile that the metric has recorded. Options are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">))</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">quantile</span><span class="p">)]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span></div>

        
<div class="viewcode-block" id="ValidationFScore.get_legend">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ValidationFScore.get_legend">[docs]</a>
    <span class="k">def</span> <span class="nf">get_legend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">quantile</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        quantile : float in self.quantiles, optional</span>
<span class="sd">            The method will return a legend appropriate for plotting </span>
<span class="sd">            get_metric, when get_metric is given the same arguments.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of str</span>
<span class="sd">            A list of strings representing a plot legend for matplotlib.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">quantile</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">quantile</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;Please specify a quantile that the metric has recorded. Options are </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">))</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; quantile  &lt;= </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quantile</span><span class="p">)]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; quantile &lt;= </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">quant</span><span class="p">)</span> <span class="k">for</span> <span class="n">quant</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">quantiles</span><span class="p">]</span></div>
</div>



<div class="viewcode-block" id="PoolScore">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolScore">[docs]</a>
<span class="k">class</span> <span class="nc">PoolScore</span><span class="p">(</span><span class="n">PoolMetricReduction</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric which applies the function score_fn to the pool of </span>
<span class="sd">    candidate points at every active learning iteration, before the </span>
<span class="sd">    model is trained on any new data drawn from the pool.</span>
<span class="sd">    Evaluates score_fn on the pool points and records specified reductions </span>
<span class="sd">    of these scores.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of lists of floats (or np.float32)</span>
<span class="sd">        Each entry in this status_history object has entries corresponding </span>
<span class="sd">        to the score_fn results applied to each active learning </span>
<span class="sd">        iteration&#39;s pool of candidate points, with reduction(s) specified </span>
<span class="sd">        in the constructor. If the constructor specifies multiple </span>
<span class="sd">        reductions, each entry is a list with each value&#39;s reduction </span>
<span class="sd">        (so an entry will be [&lt;mean&gt;, &lt;max&gt;, &lt;min&gt;], for example).</span>

<span class="sd">    name : str</span>
<span class="sd">        A string which denotes a name for this metric. In a list of </span>
<span class="sd">        metrics passed to a BFBLearner class, the names of each member </span>
<span class="sd">        of the list should be unique. By default will be &#39;pool_&lt;score_fn&gt;&#39;</span>

<span class="sd">    score_fn : callable</span>
<span class="sd">        A callable of the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).</span>
<span class="sd">        The pre-implemented functions for different uncertainty metrics </span>
<span class="sd">        can be specified in the constructor by using any of </span>
<span class="sd">        &#39;BALD&#39; (mutual information), &#39;MaxEntropy&#39; (Shannon entropy), </span>
<span class="sd">        &#39;variation_ratios&#39; (variation ratios), </span>
<span class="sd">        &#39;predictive_variance&#39; (variance of the prediction distribution),</span>
<span class="sd">        or &#39;QBDC&#39; (score*(1-score), where score is the Monte Carlo </span>
<span class="sd">        dropout-evaluated prediction for an input)</span>

<span class="sd">    tf_score_fn : jit-compiled callable</span>
<span class="sd">        Tensorflow jit-compiled version of score_fn.</span>

<span class="sd">    n_trials : int or None</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_fn : {&#39;BALD&#39;, &#39;MaxEntropy&#39;, &#39;variation_ratios&#39;, &#39;random&#39;, &#39;QBDC&#39;, &#39;predictive_variance&#39;} or callable</span>
<span class="sd">        Specifies the score function that the metric will apply to the </span>
<span class="sd">        pool of candidate points. If a callable (corresponding to a custom </span>
<span class="sd">        score function) is used, it must have the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),</span>
<span class="sd">        depending on whether or not n_trials is specified.</span>

<span class="sd">    name : str, optional</span>
<span class="sd">        Allows for a custom name of the metric. If this argument is not </span>
<span class="sd">        specified, a name will be automatically generated as </span>
<span class="sd">        &#39;pool_&lt;score_fn&gt;&#39;.</span>

<span class="sd">    reduction : {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;} or a list of these values, default=[&#39;mean&#39;,&#39;min&#39;,&#39;max&#39;]</span>
<span class="sd">        Specifies what reductions should be done on the scores computed </span>
<span class="sd">        for the pool candidate points. If a list is specified, all </span>
<span class="sd">        reductions in the list are computed.</span>

<span class="sd">    n_trials : int, optional</span>
<span class="sd">        For score_fn arguments that take a n_trials argument, which </span>
<span class="sd">        includes every pre-implemented score_fn except &#39;random&#39;, this </span>
<span class="sd">        argument can be specified here. If it is not specified, the </span>
<span class="sd">        default value for the given score_fn is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score_fn</span> <span class="o">=</span> <span class="s1">&#39;BALD&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">process_score_fn</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="n">reduction</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span> <span class="o">=</span> <span class="n">score_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="k">if</span> <span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
<div class="viewcode-block" id="PoolScore.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.PoolScore.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;performance_check for this metric records the score function </span>
<span class="sd">        evaluated on a pool of candidate points, subject to the </span>
<span class="sd">        reduction(s) specified in the constructor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        *args : (tf.keras.Model, tf.tensor(tf.float32, tf.float32)) or tf.tensor(tf.float32)</span>
<span class="sd">            If the class&#39;s score_fn were already evaluated as part of </span>
<span class="sd">            active learning (namely, if the score_fn corresponds to the </span>
<span class="sd">            one used as the acquisition function in active learning),</span>
<span class="sd">            then this method can take an already-evaluated Tensorflow </span>
<span class="sd">            tensor consisting of a list of scores. If not, then we can </span>
<span class="sd">            pass the arguments appropriate for score_fn in order to </span>
<span class="sd">            evaluate the results directly.</span>
<span class="sd">            </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of np.float32</span>
<span class="sd">            A list of the specified reductions in the score function for </span>
<span class="sd">            a batch of pool candidate points. These are then combined into </span>
<span class="sd">            a single entry into status_history using the methods in the </span>
<span class="sd">            parent class.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">Model</span><span class="p">):</span>
            <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">score</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">red</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">red</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">]</span></div>

    
    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to pickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;tf_score_fn&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>
    
    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to unpickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="NewDataScore">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.NewDataScore">[docs]</a>
<span class="k">class</span> <span class="nc">NewDataScore</span><span class="p">(</span><span class="n">TrainMetric</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A metric which applies the function score_fn to the set of points </span>
<span class="sd">    that are added to the training set at every active learning iteration, </span>
<span class="sd">    before the model is trained on the new data. Evaluates score_fn on </span>
<span class="sd">    these points and records specified reductions of these scores.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    status_history : list of lists of floats (or np.float32)</span>
<span class="sd">        Each entry in this status_history object has entries corresponding </span>
<span class="sd">        to the score_fn results applied to each active learning </span>
<span class="sd">        iteration&#39;s new training data, with reduction(s) specified in the </span>
<span class="sd">        constructor. If the constructor specifies multiple reductions, </span>
<span class="sd">        each entry is a list with each value&#39;s reduction (so an entry </span>
<span class="sd">        will be [&lt;mean&gt;, &lt;max&gt;, &lt;min&gt;], for example).</span>

<span class="sd">    name : str</span>
<span class="sd">        A string which denotes a name for this metric. In a list of </span>
<span class="sd">        metrics passed to a BFBLearner class, the names of each member </span>
<span class="sd">        of the list should be unique. By default will be &#39;train_&lt;score_fn&gt;&#39;</span>

<span class="sd">    score_fn : callable</span>
<span class="sd">        A callable of the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32).</span>
<span class="sd">        The pre-implemented functions for different uncertainty metrics </span>
<span class="sd">        can be specified in the constructor by using any of </span>
<span class="sd">        &#39;BALD&#39; (mutual information), &#39;MaxEntropy&#39; (Shannon entropy), </span>
<span class="sd">        &#39;variation_ratios&#39; (variation ratios), </span>
<span class="sd">        &#39;predictive_variance&#39; (variance of the prediction distribution),</span>
<span class="sd">        or &#39;QBDC&#39; (score*(1-score), where score is the Monte Carlo </span>
<span class="sd">        dropout-evaluated prediction for an input)</span>

<span class="sd">    tf_score_fn : jit-compiled callable</span>
<span class="sd">        Tensorflow jit-compiled version of score_fn.</span>

<span class="sd">    n_trials : int or None</span>

<span class="sd">    reduction : a list containing elements of {np.mean, np.min, np.max}</span>
<span class="sd">        This is the reduction that is performed on the scores to produce </span>
<span class="sd">        the entries in status_history. If a list of reductions are </span>
<span class="sd">        applied, then the elements of status_history will be lists </span>
<span class="sd">        with each element being a different reduction being applied </span>
<span class="sd">        to the scores.</span>

<span class="sd">    red_name : a list containing elements of {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;}</span>
<span class="sd">        This list of strings will contain the same information as </span>
<span class="sd">        reduction, but is used for labelling purposes.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    score_fn : {&#39;BALD&#39;, &#39;MaxEntropy&#39;, &#39;variation_ratios&#39;, &#39;random&#39;, &#39;QBDC&#39;, &#39;predictive_variance&#39;} or callable</span>
<span class="sd">        Specifies the score function that the metric will apply to the </span>
<span class="sd">        pool of candidate points. If a callable (corresponding to a </span>
<span class="sd">        custom score function) is used, it must have the signature </span>
<span class="sd">        (tf.keras.model, tf.tensor(tf.float32, tf.float32))-&gt; tf.tensor(tf.float32) </span>
<span class="sd">        or (tf.keras.model, tf.tensor(tf.float32, tf.float32), int)-&gt; tf.tensor(tf.float32),</span>
<span class="sd">        depending on whether or not n_trials is specified.</span>

<span class="sd">    name : str, optional</span>
<span class="sd">        Allows for a custom name of the metric. If this argument is not </span>
<span class="sd">        specified, a name will be automatically generated as </span>
<span class="sd">        &#39;train_&lt;score_fn&gt;&#39;.</span>

<span class="sd">    red : {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;} or a list of these values, default=[&#39;mean&#39;,&#39;min&#39;,&#39;max&#39;]</span>
<span class="sd">        Specifies what reductions should be done on the scores computed </span>
<span class="sd">        for the new training data. If a list is specified, all reductions </span>
<span class="sd">        in the list are computed.</span>

<span class="sd">    n_trials : int, optional</span>
<span class="sd">        For score_fn arguments that take a n_trials argument, which </span>
<span class="sd">        includes every pre-implemented score_fn except &#39;random&#39;, this </span>
<span class="sd">        argument can be specified here. If it is not specified, </span>
<span class="sd">        the default value for the given score_fn is used.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">score_fn</span> <span class="o">=</span> <span class="s1">&#39;BALD&#39;</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">red</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="s1">&#39;min&#39;</span><span class="p">,</span> <span class="s1">&#39;max&#39;</span><span class="p">],</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span> <span class="o">=</span> <span class="n">_get_reduction</span><span class="p">(</span><span class="n">red</span><span class="p">)</span>
        <span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span> <span class="o">=</span> <span class="n">process_score_fn</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span> <span class="o">=</span> <span class="n">score_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span>
        <span class="k">if</span> <span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
    
<div class="viewcode-block" id="NewDataScore.performance_check">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.NewDataScore.performance_check">[docs]</a>
    <span class="k">def</span> <span class="nf">performance_check</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">lams</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes score_fn on the points added to the training set with </span>
<span class="sd">        each active learning iteration, and then records the specified </span>
<span class="sd">        reductions.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">score</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">red</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="k">for</span> <span class="n">red</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">]</span></div>

    
<div class="viewcode-block" id="NewDataScore.perf_message">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.NewDataScore.perf_message">[docs]</a>
    <span class="k">def</span> <span class="nf">perf_message</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;The perf_message method labels any printed output of the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39; (new queried data) </span><span class="si">{}</span><span class="s1">:&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">))</span></div>


<div class="viewcode-block" id="NewDataScore.get_metric">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.NewDataScore.get_metric">[docs]</a>
    <span class="k">def</span> <span class="nf">get_metric</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_metric can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reduction : str in self.red_name, optional</span>
<span class="sd">            If specified, get_metric will only return the values </span>
<span class="sd">            corresponding to the specified reduction. If not specified, </span>
<span class="sd">            get_metric will return the status_history object in its </span>
<span class="sd">            entirety.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        np.array</span>
<span class="sd">            Represents some plottable set of values from status_history.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">_check_reduction</span><span class="p">(</span><span class="n">reduction</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="n">stat</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">reduction</span><span class="p">)]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">]]))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span></div>

        
<div class="viewcode-block" id="NewDataScore.get_legend">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.NewDataScore.get_legend">[docs]</a>
    <span class="k">def</span> <span class="nf">get_legend</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;In this subclass, get_legend can take a keyword argument.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        reduction : str in self.red_name, optional</span>
<span class="sd">            get_legend will return a legend consistent with the get_metric </span>
<span class="sd">            result with the same reduction argument passed.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        list of str</span>
<span class="sd">            An argument to specify a legend in matplotlib.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">reduction</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">reduction</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="p">[</span><span class="n">red</span> <span class="o">+</span> <span class="s1">&#39;_&#39;</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="k">for</span> <span class="n">red</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">red_name</span><span class="p">]</span></div>

    
    <span class="k">def</span> <span class="nf">__getstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to pickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
        <span class="k">del</span> <span class="n">state</span><span class="p">[</span><span class="s1">&#39;tf_score_fn&#39;</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">state</span>
    
    <span class="k">def</span> <span class="nf">__setstate__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Used to unpickle the metric.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="vm">__dict__</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">n_trials</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_trials</span><span class="p">),</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">tf_score_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">score_fn</span><span class="p">,</span> <span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span></div>


<div class="viewcode-block" id="StoppingCondition">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.StoppingCondition">[docs]</a>
<span class="k">class</span> <span class="nc">StoppingCondition</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A generic class for implementing early stopping conditions </span>
<span class="sd">    for active learning. A StoppingCondition object is called each round </span>
<span class="sd">    immediately after the metric it follows is evaluated. Then, if the </span>
<span class="sd">    call returns True, the active learning loop is terminated.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track.</span>

<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index </span>
<span class="sd">        as input and returns True if the stopping condition has been met, </span>
<span class="sd">        and False otherwise. Note that if one wishes to use the method</span>
<span class="sd">        find_stopping_index, the metric_func function MUST be capable of</span>
<span class="sd">        accommodating the optional integer argument. If this argument</span>
<span class="sd">        won&#39;t be called, it&#39;s acceptable to use an existing argument. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>
<span class="sd">        </span>
<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index as </span>
<span class="sd">        input and returns True if the stopping condition has been met, </span>
<span class="sd">        and False otherwise.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_func</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span> <span class="o">=</span> <span class="n">metric_name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">metric_func</span> <span class="o">=</span> <span class="n">metric_func</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics_dict</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Calling the StoppingCondition class on a dictionary of metrics </span>
<span class="sd">        (of the form, {metric.name : metric}) will make it perform its </span>
<span class="sd">        function on the metric it is following.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        metrics_dict : dict</span>
<span class="sd">            A dictionary relating the names of ALMetric objects (or rather </span>
<span class="sd">            child classes of this class) to the objects themselves.</span>

<span class="sd">        ind : int, optional</span>
<span class="sd">            If specified, the StoppingCondition object only considers </span>
<span class="sd">            status_history[:ind] instead of the full status_history. This </span>
<span class="sd">            is useful for retroactively determining if a stopping </span>
<span class="sd">            condition would have eliminated unnecessary active learning </span>
<span class="sd">            iterations.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        bool</span>
<span class="sd">            True if the StoppingCondition determines we should stop active </span>
<span class="sd">            learning, False otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">metric_in</span> <span class="o">=</span> <span class="n">metrics_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">]</span>
        <span class="k">except</span> <span class="ne">KeyError</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;metric_name is not within the metrics being recorded by ActiveLearning. Must be one of </span><span class="si">{}</span><span class="s1">.&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">metrics_dict</span><span class="o">.</span><span class="n">keys</span><span class="p">())))</span>
        <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_func</span><span class="p">(</span><span class="n">metric_in</span><span class="p">,</span> <span class="n">ind</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">metric_func</span><span class="p">(</span><span class="n">metric_in</span><span class="p">)</span>
    
<div class="viewcode-block" id="StoppingCondition.find_stopping_index">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.StoppingCondition.find_stopping_index">[docs]</a>
    <span class="k">def</span> <span class="nf">find_stopping_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metrics_dict</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Computes the index (active learning iteration) at which this </span>
<span class="sd">        StoppingCondition WOULD have stopped active learning if it were </span>
<span class="sd">        applied to the metrics for an already-trained BFBLearner object.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        metrics_dict : dict</span>
<span class="sd">            A dictionary relating the names of ALMetric objects (or rather </span>
<span class="sd">            child classes of this class) to the objects themselves, </span>
<span class="sd">            extracted from a trained BFBLearner object.</span>
<span class="sd">        </span>
<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        int</span>
<span class="sd">            An integer representing the active learning round at which </span>
<span class="sd">            the StoppingCondition would have stopped active learning, if </span>
<span class="sd">            it had been implemented during training. If the condition </span>
<span class="sd">            would not have been met, returns -1.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">metric</span> <span class="o">=</span> <span class="n">metrics_dict</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">metric_name</span><span class="p">]</span>
        <span class="k">for</span> <span class="n">ind</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>
            <span class="k">if</span> <span class="bp">self</span><span class="p">(</span><span class="n">metrics_dict</span><span class="p">,</span> <span class="n">ind</span><span class="p">):</span>
                <span class="k">return</span> <span class="n">ind</span>
        <span class="k">return</span> <span class="o">-</span><span class="mi">1</span></div>
</div>


<div class="viewcode-block" id="ScoreNotDecreasing">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.ScoreNotDecreasing">[docs]</a>
<span class="k">class</span> <span class="nc">ScoreNotDecreasing</span><span class="p">(</span><span class="n">StoppingCondition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A stopping condition based on when an uncertainty score (in </span>
<span class="sd">    particular BALD or variation ratios) is not decreasing over some data </span>
<span class="sd">    set (usually the pool of candidate points proposed by the classifier </span>
<span class="sd">    or the set of training points added as training data). Because </span>
<span class="sd">    mutual information, variation ratios, and predictive variance are all </span>
<span class="sd">    in theory metrics of epistemic uncertainty (or in the case of the </span>
<span class="sd">    second, at least highly sensitive to it), some measurement of </span>
<span class="sd">    these scores should be decreasing as more data is added. If it&#39;s not, </span>
<span class="sd">    then the network probably reached close to the highest performance</span>
<span class="sd">    it&#39;s capable of attaining.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>

<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index </span>
<span class="sd">        as input and returns True if the stopping condition has been met, </span>
<span class="sd">        and False otherwise. In this case, metric_func checks to see if </span>
<span class="sd">        a specified uncertainty score on some set of points hasn&#39;t </span>
<span class="sd">        achieved a new minimum over some specified number of rounds.</span>

<span class="sd">    reduction : {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;, &#39;std&#39;}</span>
<span class="sd">        Must be some reduction over the score that the metric specified </span>
<span class="sd">        by metric_name has evaluated. This is the specific quantity that </span>
<span class="sd">        the stopping condition monitors.&#39;</span>

<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new minimum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track.</span>
<span class="sd">    </span>
<span class="sd">    reduction : {&#39;mean&#39;, &#39;min&#39;, &#39;max&#39;, &#39;std&#39;}</span>
<span class="sd">        Must be some reduction over the score that the metric specified </span>
<span class="sd">        by metric_name has evaluated. This is the specific quantity that </span>
<span class="sd">        the stopping condition monitors.&#39;</span>
<span class="sd">    </span>
<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new minimum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">reduction</span> <span class="o">=</span> <span class="s1">&#39;mean&#39;</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reduction</span> <span class="o">=</span> <span class="n">reduction</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="k">def</span> <span class="nf">metric_func</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="s1">&#39;red_name&#39;</span><span class="p">))</span> <span class="ow">or</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="s1">&#39;score_fn&#39;</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;The specified metric is not a scoring metric, and so this stopping condition is not applicable.&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">red_index</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">red_name</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reduction</span><span class="p">)</span>
            <span class="n">min_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="n">red_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]])</span>
            <span class="n">min_score_arg</span> <span class="o">=</span> <span class="p">[</span><span class="n">stat</span><span class="p">[</span><span class="n">red_index</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">min_score</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">min_score_arg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span><span class="n">ind</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">last_status_history</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span><span class="n">ind</span><span class="p">]</span>
            <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">elem</span><span class="p">[</span><span class="n">red_index</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">min_score</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">last_status_history</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_func</span><span class="p">)</span></div>


<div class="viewcode-block" id="AccuracyNotImproving">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.AccuracyNotImproving">[docs]</a>
<span class="k">class</span> <span class="nc">AccuracyNotImproving</span><span class="p">(</span><span class="n">StoppingCondition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A stopping condition that monitors either a ModelEvaluation or </span>
<span class="sd">    MCModelEvaluation metric and stops the active learning after some </span>
<span class="sd">    number of rounds have passed without achieving a new maximum accuracy.</span>
<span class="sd">    </span>
<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>

<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index as </span>
<span class="sd">        input and returns True if the stopping condition has been met, and </span>
<span class="sd">        False otherwise. In this case, metric_func checks to see if the </span>
<span class="sd">        accuracy entry for a ModelEvaluation or MCModelEvaluation metric</span>
<span class="sd">        hasn&#39;t achieved a new maximum over some specified number of rounds.</span>

<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track.</span>

<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="k">def</span> <span class="nf">metric_func</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ModelEvaluation</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">MCModelEvaluation</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;The specified metric is not a ModelEvaluation or MCModelEvaluation metric, and so this stopping condition is not applicable.&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            
            <span class="n">max_accuracy</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]])</span>
            <span class="n">last_status_history</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span><span class="n">ind</span><span class="p">]</span>
            <span class="n">max_accuracy_arg</span> <span class="o">=</span> <span class="p">[</span><span class="n">stat</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">max_accuracy</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">max_accuracy_arg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span><span class="n">ind</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">elem</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;=</span> <span class="n">max_accuracy</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">last_status_history</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_func</span><span class="p">)</span></div>


<div class="viewcode-block" id="FScoreNotImproving">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.FScoreNotImproving">[docs]</a>
<span class="k">class</span> <span class="nc">FScoreNotImproving</span><span class="p">(</span><span class="n">StoppingCondition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A stopping condition that monitors a ValidationConfusionMatrix or </span>
<span class="sd">    ValidationFScore metric and stops the active learning after some </span>
<span class="sd">    number of rounds have passed without achieving a new maximum F score.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>

<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index </span>
<span class="sd">        as input and returns True if the stopping condition has been met, </span>
<span class="sd">        and False otherwise. In this case, metric_func checks to see if </span>
<span class="sd">        the F score evaluated over some uncertainty quantile </span>
<span class="sd">        (see ValidationConfusionMatrix and ValidationFScore documentation </span>
<span class="sd">        for details) hasn&#39;t achieved a new maximum in patience rounds.</span>

<span class="sd">    quant : float, default=1.0</span>
<span class="sd">        The uncertainty quantile that the stopping condition should check. </span>
<span class="sd">        Default is 1.0, meaning the entire validation set is considered.</span>
<span class="sd">    </span>
<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>

<span class="sd">    quant : float, default=1.0</span>
<span class="sd">        The uncertainty quantile that the stopping condition should check. </span>
<span class="sd">        Default is 1.0, meaning the entire validation set is considered.</span>
<span class="sd">    </span>
<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates </span>
<span class="sd">        before halting active learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">quant</span> <span class="o">=</span> <span class="mf">1.0</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">quant</span> <span class="o">=</span> <span class="n">quant</span>
        <span class="k">def</span> <span class="nf">metric_func</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ValidationConfusionMatrix</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;The specified metric is not ValidationConfusionMatrix, and so this stopping condition is not applicable.&#39;</span><span class="p">)</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="n">q_index</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">quantiles</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">quant</span><span class="p">)</span>
            <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;the specified quantile is not recorded in the metric. Please specify one of </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">quantiles</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ValidationFScore</span><span class="p">):</span>
                <span class="n">fscore</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">true_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
                <span class="n">false_pos</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
                <span class="n">false_neg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="n">stat</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">])</span><span class="o">.</span><span class="n">T</span>
                <span class="n">prec</span> <span class="o">=</span> <span class="n">true_pos</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_pos</span> <span class="o">+</span> <span class="n">false_pos</span><span class="p">)</span>
                <span class="n">rec</span> <span class="o">=</span> <span class="n">true_pos</span> <span class="o">/</span> <span class="p">(</span><span class="n">true_pos</span> <span class="o">+</span> <span class="n">false_neg</span><span class="p">)</span>
                <span class="n">fscore</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">prec</span><span class="o">*</span><span class="n">rec</span> <span class="o">/</span> <span class="p">(</span><span class="n">prec</span> <span class="o">+</span> <span class="n">rec</span><span class="p">)</span>

            <span class="n">max_fscore</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">fscore</span><span class="p">[</span><span class="n">q_index</span><span class="p">][:</span><span class="n">ind</span><span class="p">])</span>
            <span class="n">max_fscore_arg</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">fscore</span><span class="p">[</span><span class="n">q_index</span><span class="p">][:</span><span class="n">ind</span><span class="p">])</span>
            <span class="n">last_status_history</span> <span class="o">=</span> <span class="n">fscore</span><span class="p">[</span><span class="n">q_index</span><span class="p">][</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span><span class="n">ind</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">max_fscore_arg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span><span class="n">ind</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">last_status_history</span> <span class="o">&lt;=</span> <span class="n">max_fscore</span><span class="p">)</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_func</span><span class="p">)</span></div>



<div class="viewcode-block" id="DeltaFNotDecreasing">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.AL_Metrics.DeltaFNotDecreasing">[docs]</a>
<span class="k">class</span> <span class="nc">DeltaFNotDecreasing</span><span class="p">(</span><span class="n">StoppingCondition</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A stopping condition that monitors a PoolDeltaF or UnlabelledDeltaF</span>
<span class="sd">    metric and stops active learning once the classifier&#39;s estimated </span>
<span class="sd">    change in F score has not decreased for a specified number of rounds.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track.</span>

<span class="sd">    metric_func : callable</span>
<span class="sd">        A callable which takes a metric and an (optional) integer index </span>
<span class="sd">        as input and returns True if the stopping condition has been met, </span>
<span class="sd">        and False otherwise. In this case, metric_func checks to see if </span>
<span class="sd">        the estimated change in F score has not achieved a new minimum </span>
<span class="sd">        in patience rounds.</span>
<span class="sd">    </span>
<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    metric_name : str</span>
<span class="sd">        Denotes the name of the performance metric (that is, the ALMetric </span>
<span class="sd">        object&#39;s name str) that the StoppingCondition should track</span>
<span class="sd">    </span>
<span class="sd">    patience : int, default=5</span>
<span class="sd">        The number of rounds without achieving a new maximum for its </span>
<span class="sd">        monitored quantity that the stopping condition tolerates before </span>
<span class="sd">        halting active learning.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">metric_name</span><span class="p">,</span> <span class="n">patience</span> <span class="o">=</span> <span class="mi">5</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">patience</span> <span class="o">=</span> <span class="n">patience</span>
        <span class="k">def</span> <span class="nf">metric_func</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">ind</span> <span class="o">=</span> <span class="kc">None</span><span class="p">):</span>
            <span class="k">if</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">PoolDeltaF</span><span class="p">))</span> <span class="ow">and</span> <span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">metric</span><span class="p">,</span> <span class="n">UnlabelledDeltaF</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s1">&#39;The specified metric is not a PoolDeltaF metric, and so this stopping condition is not applicable.&#39;</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">ind</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">ind</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="n">min_score</span> <span class="o">=</span> <span class="nb">min</span><span class="p">([</span><span class="n">stat</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]])</span>
            <span class="n">min_score_arg</span> <span class="o">=</span> <span class="p">[</span><span class="n">stat</span> <span class="k">for</span> <span class="n">stat</span> <span class="ow">in</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[:</span><span class="n">ind</span><span class="p">]]</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">min_score</span><span class="p">)</span>
            <span class="n">last_status_history</span> <span class="o">=</span> <span class="n">metric</span><span class="o">.</span><span class="n">status_history</span><span class="p">[</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">:</span><span class="n">ind</span><span class="p">]</span>
            <span class="k">if</span> <span class="n">min_score_arg</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">ind</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">patience</span><span class="p">,</span><span class="n">ind</span><span class="p">):</span>
                <span class="k">return</span> <span class="kc">False</span>
            <span class="k">return</span> <span class="nb">all</span><span class="p">([</span><span class="n">elem</span> <span class="o">&gt;=</span> <span class="n">min_score</span> <span class="k">for</span> <span class="n">elem</span> <span class="ow">in</span> <span class="n">last_status_history</span><span class="p">])</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">metric_name</span><span class="p">,</span> <span class="n">metric_func</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">bfbrain</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial.html">Tutorial and User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">BFBrain</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, George Wojcik.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
    </div>

    

    
  </body>
</html>