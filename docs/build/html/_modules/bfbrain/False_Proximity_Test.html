<!DOCTYPE html>

<html lang="en" data-content_root="../../">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>bfbrain.False_Proximity_Test &#8212; bfbrain 1.0 documentation</title>
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=b3523f8e" />
    <link rel="stylesheet" type="text/css" href="../../_static/alabaster.css?v=039e1c02" />
    <script src="../../_static/documentation_options.js?v=f2a433a1"></script>
    <script src="../../_static/doctools.js?v=888ff710"></script>
    <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
   
  <link rel="stylesheet" href="../../_static/custom.css" type="text/css" />
  
  
  <meta name="viewport" content="width=device-width, initial-scale=0.9, maximum-scale=0.9" />

  </head><body>
  

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          

          <div class="body" role="main">
            
  <h1>Source code for bfbrain.False_Proximity_Test</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;These are a series of functions used to score models based on how </span>
<span class="sd">distant their false positives and false negatives over some data set are </span>
<span class="sd">from the model&#39;s decision boundary. The only function used externally is </span>
<span class="sd">combined_false_score, which discusses how the scoring is done. All other </span>
<span class="sd">functions in this file are only used internally by combined_false_score </span>
<span class="sd">and the functions that it calls.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
    
<div class="viewcode-block" id="combined_false_score">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.False_Proximity_Test.combined_false_score">[docs]</a>
<span class="k">def</span> <span class="nf">combined_false_score</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">,</span> <span class="n">dist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.05</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A method to evaluate how &quot;wrong&quot; the model&#39;s predictions of the </span>
<span class="sd">    validation set actually are, based on how far false positives and </span>
<span class="sd">    false negatives are from the decision boundary. Returns two sets </span>
<span class="sd">    of information for the false positives and the false negatives.</span>
<span class="sd">    For false positives (negatives), uses _find_accurate_points to find </span>
<span class="sd">    nearby sets of coefficients that are correctly classified as </span>
<span class="sd">    negative (positive). The angular distance between these new points</span>
<span class="sd">    and the corresponding false positive (negative) points is then </span>
<span class="sd">    computed in radians. The function returns the mean, </span>
<span class="sd">    standard deviation, and maximum of these distances for both </span>
<span class="sd">    false positives and negatives, as well as the number of points for </span>
<span class="sd">    which the angular distance exceeds a specified angle in radians.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>

<span class="sd">    ds : tf.data.Dataset</span>
<span class="sd">        A labelled Tensorflow dataset of sets of quartic potential </span>
<span class="sd">        coefficients.</span>

<span class="sd">    dist : tf.float32</span>
<span class="sd">        A maximum angular distance in radians between an incorrectly </span>
<span class="sd">        classified point and the classifier&#39;s decision boundary that the </span>
<span class="sd">        user deems acceptable. For small values of dist, this corresponds </span>
<span class="sd">        to the maximum difference in a (normalized) quartic potential </span>
<span class="sd">        coefficient between an incorrectly classified point and a </span>
<span class="sd">        correctly classified one.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple of lists of floats.</span>
<span class="sd">        Each list contains the mean, standard deviation, and maximum of </span>
<span class="sd">        the angular distance between incorrectly classified points in ds </span>
<span class="sd">        and correctly classified ones generated with </span>
<span class="sd">        _find_accurate_points. The final element of each list gives the </span>
<span class="sd">        number of incorrectly classified points that are greater than </span>
<span class="sd">        dist radians away from a correctly classified one. </span>
<span class="sd">&quot;&quot;&quot;</span>
    <span class="c1">#Find the false positives and false negatives from the dataset.</span>
    <span class="n">false_positives</span><span class="p">,</span> <span class="n">false_negatives</span> <span class="o">=</span> <span class="n">get_false_pos_and_neg_tf</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">)</span>

    <span class="c1"># Create tf.Variable objects representing the false positives and </span>
    <span class="c1"># false negatives, so that we can deform them to create new instances </span>
    <span class="c1"># which cross the decision boundary.</span>
    <span class="n">neighbors_fp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">false_positives</span><span class="p">))</span>
    <span class="n">neighbors_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">false_negatives</span><span class="p">))</span>
    <span class="c1"># Also create two more identical tf.Variable tensors. These will keep </span>
    <span class="c1"># track of the initial states of the false positives and </span>
    <span class="c1"># false negatives and be used as contrapoints when finding the </span>
    <span class="c1"># decision boundary of the neural network.</span>
    <span class="n">init_fp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">false_positives</span><span class="p">))</span>
    <span class="n">init_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">false_negatives</span><span class="p">))</span>

    <span class="c1">#Now generate points near these points which the neural network </span>
    <span class="c1"># correctly classifies.</span>
    <span class="n">_find_accurate_points</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">neighbors_fp</span><span class="p">,</span> <span class="n">init_fp</span><span class="p">,</span> <span class="n">false_pos</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="kc">True</span><span class="p">),</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">10000</span><span class="p">),</span> <span class="n">init_rot</span> <span class="o">=</span> <span class="n">dist</span><span class="o">/</span><span class="mf">50.</span><span class="p">)</span>
    <span class="n">_find_accurate_points</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">neighbors_fn</span><span class="p">,</span> <span class="n">init_fn</span><span class="p">,</span> <span class="n">false_pos</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="kc">False</span><span class="p">),</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">10000</span><span class="p">),</span> <span class="n">init_rot</span> <span class="o">=</span> <span class="n">dist</span><span class="o">/</span><span class="mf">50.</span><span class="p">)</span>

    <span class="c1"># Compute the angular distance between the false positives </span>
    <span class="c1"># and the correctly labelled points.</span>
    <span class="n">results_fp</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">acos</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">false_positives</span><span class="o">*</span><span class="n">neighbors_fp</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
    <span class="n">results_fn</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">acos</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">false_negatives</span><span class="o">*</span><span class="n">neighbors_fn</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">))</span>
    <span class="c1">#Return information about the minimum distances between falsely </span>
    <span class="c1"># classified points and correctly classified bounded-from-below points.</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">results_fp</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">results_fp</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">results_fp</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">results_fp</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">results_fp</span><span class="p">,</span> <span class="n">dist</span><span class="p">))))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()],</span> <span class="p">[</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">results_fn</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_std</span><span class="p">(</span><span class="n">results_fn</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_max</span><span class="p">(</span><span class="n">results_fn</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">results_fn</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">results_fn</span><span class="p">,</span> <span class="n">dist</span><span class="p">))))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">()]</span></div>



<span class="k">def</span> <span class="nf">_tf_flatten</span><span class="p">(</span><span class="n">t</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A method which returns a flattened tensor.</span>
<span class="sd">    </span>
<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    t : tf.Tensor</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.Tensor</span>
<span class="sd">        A tensor with the same content as t, but flattened to be </span>
<span class="sd">        one-dimensional.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">shape</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="n">jit_compile</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_model_grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A convenience function to compute the gradient of the model </span>
<span class="sd">    prediction as a function of the inputs. Used to help validate </span>
<span class="sd">    the accuracy of the model.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable object which holds a 2-D tensor representing </span>
<span class="sd">        sets of quartic potential coefficients.</span>
<span class="sd">    </span>
<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.tensor(tf.float32, tf.float32), tf.tensor(tf.float32, tf.float32)</span>
<span class="sd">        Two Tensorflow tensors: A tensor representing the model output </span>
<span class="sd">        evaluated at lams_var, and a 2-D Tensorflow tensor representing </span>
<span class="sd">        the gradient of the model prediction on a batch of inputs.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">(</span><span class="n">watch_accessed_variables</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">tape</span><span class="o">.</span><span class="n">watch</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_rand_rotate</span><span class="p">(</span><span class="n">lams</span><span class="p">,</span> <span class="n">rot_dist</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A function which randomly rotates a given set of quartic potential </span>
<span class="sd">    coefficients by a specified angular distance on the unit hypersphere.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams : tf.Variable</span>
<span class="sd">        A 2-D tf.Variable which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network</span>
<span class="sd">          labels as either false positives or false negatives.</span>

<span class="sd">    rot_dist : float</span>
<span class="sd">        A float that determines how far (in radians) each quartic </span>
<span class="sd">        coefficient should be rotated.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.Tensor(tf.float32, tf.float32)</span>
<span class="sd">        A tf.Tensor obtained by rotating each set of quartic coefficients </span>
<span class="sd">        in lams by rot_dist in random directions.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1">#Generate an ensemble of random unit vectors that are orthogonal to lams</span>
    <span class="n">orth_rands</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">lams</span><span class="p">))</span>
    <span class="n">orth_rands</span> <span class="o">=</span> <span class="n">orth_rands</span> <span class="o">/</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">orth_rands</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
    <span class="n">orth_rands</span> <span class="o">=</span> <span class="p">(</span><span class="n">orth_rands</span> <span class="o">-</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">orth_rands</span> <span class="o">*</span> <span class="n">lams</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)[:,</span><span class="n">np</span><span class="o">.</span><span class="n">newaxis</span><span class="p">]</span><span class="o">*</span><span class="n">lams</span><span class="p">)</span>
    <span class="n">orth_rands</span> <span class="o">=</span> <span class="n">orth_rands</span> <span class="o">/</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">orth_rands</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
    
    <span class="c1">#Rotate lams in the direction of orth_rands by the angle rot_dist</span>
    <span class="k">return</span> <span class="n">orth_rands</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">rot_dist</span><span class="p">))</span> <span class="o">+</span> <span class="n">lams</span><span class="o">*</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">rot_dist</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_one_step_validation</span><span class="p">(</span><span class="n">lams_var</span><span class="p">,</span> <span class="n">grad_array</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A convenience function to help in finding sets of quartic </span>
<span class="sd">    coefficients that are correctly labelled in the vicinity of points </span>
<span class="sd">    which are incorrectly labelled. Given a tf.Variable lams_var, follows </span>
<span class="sd">    the direction of steepest descent (ascent) in the model prediction </span>
<span class="sd">    for false positives (negatives) in order to locate a point very close </span>
<span class="sd">    by that is correctly labelled by the neural network.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable object which holds a 2-D tensor representing </span>
<span class="sd">        sets of quartic potential coefficients.</span>
<span class="sd">    </span>
<span class="sd">    grad_array : tf.tensor(tf.float32, tf.float32)</span>
<span class="sd">        A Tensorflow tensor that holds the gradient of the model output </span>
<span class="sd">        with respect to the input quartic coefficients.</span>
<span class="sd">    </span>
<span class="sd">    stepsize : tf.Tensor(tf.float32)</span>
<span class="sd">        Controls how rapidly to follow the direction of steepest descent </span>
<span class="sd">        or ascent for each point. Automatically computed by </span>
<span class="sd">        _estimate_step_size.</span>
<span class="sd">    </span>
<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the function will assume that lams_var are points in the </span>
<span class="sd">        vicinity of false positives, and so should be looking for points </span>
<span class="sd">        that the network classifies as negative. Otherwise, the function </span>
<span class="sd">        will assume that lams_var are points in the vicinity of </span>
<span class="sd">        false negatives, and so should be looking for points that the </span>
<span class="sd">        network classifies as positive.</span>

<span class="sd">    mask : tf.Tensor(bool)</span>
<span class="sd">        A 1-dimensional tensor of booleans. The function will only </span>
<span class="sd">        update indices of lams_var where mask is True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Follow the gradient to produce nearby points which the network classifies as more negative (positive) for false positives (negatives).</span>
    <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_sub</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">stepsize</span><span class="o">*</span><span class="p">(</span><span class="n">grad_array</span><span class="p">),</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">))))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">stepsize</span><span class="o">*</span><span class="p">(</span><span class="n">grad_array</span><span class="p">),</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">))))</span>
    <span class="c1"># Now project the result back onto the unit hypersphere.</span>
    <span class="n">lams_var</span><span class="o">.</span><span class="n">assign</span><span class="p">((</span><span class="n">lams_var</span><span class="o">.</span><span class="n">value</span><span class="p">())</span><span class="o">/</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">lams_var</span><span class="o">.</span><span class="n">value</span><span class="p">(),</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">_find_prediction_boundary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">converged</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A convenience function for finding how far misclassified points </span>
<span class="sd">    are from the decision boundary. Uses gradient ascent/descent to modify </span>
<span class="sd">    quartic coefficients of false positives (negatives) until the neural </span>
<span class="sd">    network classifies them as negative (positive). Updates the values </span>
<span class="sd">    in a tf.Variable object representing sets of quartic coupling </span>
<span class="sd">    coefficients, and returns an array that describes whether or not the </span>
<span class="sd">    attempt to locate all decision boundaries was successful.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable  which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network </span>
<span class="sd">        labels as either false positives or false negatives.</span>
<span class="sd">    </span>
<span class="sd">    stepsize : float</span>
<span class="sd">        Governs how rapidly the function follows the gradient of the </span>
<span class="sd">        model prediction.</span>

<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the function assumes that lams_var are false positives. </span>
<span class="sd">        If False, assumes they are false negatives.</span>

<span class="sd">    converged : tf.Tensor(bool)</span>
<span class="sd">        A Tensorflow tensor of Boolean values that determine whether or </span>
<span class="sd">        not a given set of quartic coefficients in lams_var has been </span>
<span class="sd">        sufficiently changed to cross the decision boundary.</span>
<span class="sd">        When this function is called, every element should be False.</span>

<span class="sd">    maxiter : int</span>
<span class="sd">        The maximum number of gradient ascent/descent iterations to perform.</span>

<span class="sd">    init_rot : float</span>
<span class="sd">        A parameter for randomly rotating coefficients that have zero </span>
<span class="sd">        gradient, to avoid encountering local extrema that aren&#39;t past </span>
<span class="sd">        the decision boundary.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.Tensor(bool)</span>
<span class="sd">        A Tensorflow tensor that labels whether the quartic coefficients </span>
<span class="sd">        in a given index of lams_var have been sufficiently changed to </span>
<span class="sd">        cross the decision boundary. If the function is successful in</span>
<span class="sd">        locating all decision boundaries, every element should be True.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="k">while</span> <span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">))):</span>
        <span class="c1"># If any points have zero gradient and aren&#39;t past the decision boundary, fix them by randomly perturbing until they have nonzero gradients.</span>
        <span class="n">_fix_zero_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">,</span> <span class="o">~</span><span class="n">converged</span><span class="p">)</span>
        <span class="c1"># Now compute the model value and the gradient at lams_var.</span>
        <span class="n">model_val</span><span class="p">,</span> <span class="n">grad_array</span> <span class="o">=</span> <span class="n">_model_grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">)</span>
        <span class="c1"># Determine if any new points have converged.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">model_val</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">model_val</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">))</span>
        <span class="c1"># Estimate the step size for the optimization step using backtracking</span>
        <span class="n">stepsize</span> <span class="o">=</span> <span class="n">_estimate_step_size</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">model_val</span><span class="p">,</span> <span class="n">grad_array</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="o">~</span><span class="n">converged</span><span class="p">)</span>
        <span class="n">_one_step_validation</span><span class="p">(</span><span class="n">lams_var</span><span class="p">,</span> <span class="n">grad_array</span><span class="p">,</span> <span class="n">stepsize</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="o">~</span><span class="n">converged</span><span class="p">)</span>
        <span class="n">i</span> <span class="o">=</span> <span class="n">i</span> <span class="o">+</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">converged</span>

<span class="k">def</span> <span class="nf">_tf_scatter_nd_mask</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">mask</span><span class="p">,</span> <span class="n">update</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Updates a tensor&#39;s values according to an update tensor, only for </span>
<span class="sd">    indices where a a mask is not true.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tensor : tf.Tensor</span>
<span class="sd">        Some input tensor</span>

<span class="sd">    mask : tf.Tensor(bool)</span>
<span class="sd">        A tensor of booleans which should be &quot;True&quot; for indices where the </span>
<span class="sd">        values of tensor should be replaced with update.</span>

<span class="sd">    update : tf.Tensor</span>
<span class="sd">        A tensor of the same shape and dtype as tensor.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.Tensor</span>
<span class="sd">        A tf.Tensor which has the values of update where mask is True, </span>
<span class="sd">        and tensor where mask is False.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">indices</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">mask</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">tensor_scatter_nd_update</span><span class="p">(</span><span class="n">tensor</span><span class="p">,</span> <span class="n">indices</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">update</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">indices</span><span class="p">)))</span>

<span class="k">def</span> <span class="nf">_estimate_step_size</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">model_val</span><span class="p">,</span> <span class="n">grad_array</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Estimate the optimal size for each gradient descent step using </span>
<span class="sd">    backtracking. Note that we don&#39;t use the backtracking for projected </span>
<span class="sd">    gradient descent here, since the neural network already automatically </span>
<span class="sd">    projects the input onto the unit hypersphere before evaluation, so the </span>
<span class="sd">    result using the simpler unconstrained backtracking strategy will be </span>
<span class="sd">    the same as the projected gradient result.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>

<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable  which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network </span>
<span class="sd">        labels as either false positives or false negatives.</span>

<span class="sd">    model_val : tf.Tensor(tf.float32)</span>
<span class="sd">        The model predictions on the initial value of lams_var.</span>

<span class="sd">    grad_array : tf.Tensor(tf.float32, tf.float32)</span>
<span class="sd">        A Tensorflow tensor that holds the gradient of the model output </span>
<span class="sd">        with respect to the initial value of lams_var</span>
<span class="sd">    </span>
<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the points in lams_var denote false positives. </span>
<span class="sd">        Otherwise, they denote false negatives.</span>

<span class="sd">    mask : tf.Tensor(bool)</span>
<span class="sd">        A boolean mask. The method will only increment the step size </span>
<span class="sd">        estimate for indices where mask is True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tf.Tensor(tf.float32)</span>
<span class="sd">        A tf.Tensor of step sizes.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">stepsize</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="mi">1</span><span class="p">),</span> <span class="n">dtype</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
    <span class="n">squared_grads</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">square</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">grad_array</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">))</span>
    <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span> <span class="o">-</span> <span class="n">stepsize</span><span class="o">*</span><span class="n">grad_array</span><span class="p">)</span><span class="o">-</span><span class="n">model_val</span><span class="p">,</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">stepsize</span><span class="o">*</span><span class="n">squared_grads</span><span class="p">)))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span> <span class="o">+</span> <span class="n">stepsize</span><span class="o">*</span><span class="n">grad_array</span><span class="p">)</span><span class="o">-</span><span class="n">model_val</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">stepsize</span><span class="o">*</span><span class="n">squared_grads</span><span class="p">)))</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">),</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">25</span><span class="p">):</span>
        <span class="n">stepsize</span> <span class="o">=</span> <span class="n">_tf_scatter_nd_mask</span><span class="p">(</span><span class="n">stepsize</span><span class="p">,</span> <span class="o">~</span><span class="n">converged</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">stepsize</span><span class="p">)</span>
        <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span> <span class="o">-</span> <span class="n">stepsize</span><span class="o">*</span><span class="n">grad_array</span><span class="p">)</span><span class="o">-</span><span class="n">model_val</span><span class="p">,</span> <span class="o">-</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">stepsize</span><span class="o">*</span><span class="n">squared_grads</span><span class="p">)))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_or</span><span class="p">(</span><span class="o">~</span><span class="n">mask</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater_equal</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span> <span class="o">+</span> <span class="n">stepsize</span><span class="o">*</span><span class="n">grad_array</span><span class="p">)</span><span class="o">-</span><span class="n">model_val</span><span class="p">,</span> <span class="mf">0.5</span><span class="o">*</span><span class="n">stepsize</span><span class="o">*</span><span class="n">squared_grads</span><span class="p">)))</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">clip_by_value</span><span class="p">(</span><span class="mf">2.</span><span class="o">*</span><span class="n">stepsize</span><span class="p">,</span> <span class="mf">1e-8</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">)</span>

    
<span class="k">def</span> <span class="nf">_fix_zero_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A method to deal with the possibility of points in the model that </span>
<span class="sd">    have a gradient of exactly zero (so that it isn&#39;t suitable to use </span>
<span class="sd">    gradient descent/ascent to find nearby points with the appropriate </span>
<span class="sd">    label). This method finds such points and randomly rotates them a </span>
<span class="sd">    small angle until the gradient is nonzero.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>

<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        Represents sets of quartic potential coefficients in the vicinity </span>
<span class="sd">        of points that the neural network labels as either false positives </span>
<span class="sd">        or false negatives.</span>

<span class="sd">    init_rot : float</span>
<span class="sd">        The initial angular distance which variables with zero gradient </span>
<span class="sd">        should be rotated to find points with nonzero gradient. If this </span>
<span class="sd">        angular distance fails to find points with nonzero gradients, </span>
<span class="sd">        progressively larger rotations will be attempted until a nonzero </span>
<span class="sd">        gradient is found.</span>
<span class="sd">    </span>
<span class="sd">    mask : tf.Tensor(bool)</span>
<span class="sd">        A mask denoting which zero gradients should be &quot;fixed&quot;. Used to </span>
<span class="sd">        avoid randomly rotating points that have already been deformed </span>
<span class="sd">        past the decision boundary.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">init_lams</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">lams_var</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>
    <span class="n">_</span><span class="p">,</span> <span class="n">init_grads</span> <span class="o">=</span> <span class="n">_model_grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">)</span>
    <span class="n">zero_grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">init_grads</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">),</span> <span class="mf">1e-7</span><span class="p">),</span> <span class="n">mask</span><span class="p">)</span>
    <span class="n">rot_dist</span> <span class="o">=</span> <span class="n">init_rot</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="n">zero_grad</span><span class="p">):</span>
        <span class="c1"># increase rot_dist if too many iterations have gone by without fixing all the zero-gradient points.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">floormod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)))):</span>
            <span class="n">rot_dist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">rot_dist</span>
        <span class="c1"># Update the lams_var to randomly rotate those points at which the model has zero gradient.</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero_grad</span><span class="p">),</span> <span class="n">_rand_rotate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">lams_var</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero_grad</span><span class="p">))),</span> <span class="n">rot_dist</span><span class="p">))</span>
        <span class="c1"># Check to see whether the updated points still have zero gradient.</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">init_grads</span> <span class="o">=</span> <span class="n">_model_grad</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">)</span>
        <span class="n">zero_grad</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">init_grads</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span> <span class="o">==</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">mask</span><span class="p">)</span>
        <span class="c1"># If there are still points with zero gradient, reset these points to their initial values so we can rotate them randomly again in the next iteration.</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero_grad</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">init_lams</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">zero_grad</span><span class="p">))))</span>
        <span class="c1"># Increment a counter of how many loops have been performed.</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">_random_rot_search</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A method to deal with points that still haven&#39;t been deformed past </span>
<span class="sd">    the decision boundary by the gradient descent/ascent strategy.</span>
<span class="sd">    This function randomly rotates these points until points that are past </span>
<span class="sd">    the decision boundary are found.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>

<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable  which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network </span>
<span class="sd">        labels as either false positives or false negatives.</span>

<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the function will assume that lams_var are points in the </span>
<span class="sd">        vicinity of false positives, and so should be looking for points </span>
<span class="sd">        that the network classifies as negative. Otherwise, the function </span>
<span class="sd">        will assume that lams_var are points in the vicinity of </span>
<span class="sd">        false negatives, and so should be looking for points that the </span>
<span class="sd">        network classifies as positive.</span>

<span class="sd">    init_rot : float</span>
<span class="sd">        The initial angular distance which variables should be rotated to </span>
<span class="sd">        find points across the decision boundary. If this angular distance </span>
<span class="sd">        fails to find valid points, progressively larger rotations will be </span>
<span class="sd">        attempted until a point across the decision boundary is found.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Keep track of the positions of the variables before rotation.</span>
    <span class="n">init_lams</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">lams_var</span><span class="o">.</span><span class="n">value</span><span class="p">())</span>

    <span class="c1"># Determine which points are not yet deformed across the </span>
    <span class="c1"># decision boundary.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">)</span>
    <span class="n">rot_dist</span> <span class="o">=</span> <span class="n">init_rot</span>
    <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">):</span>
        <span class="c1"># increase rot_dist if too many iterations have gone by </span>
        <span class="c1"># without converging for all points.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">floormod</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">0</span><span class="p">)))):</span>
            <span class="n">rot_dist</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">2.</span><span class="p">)</span><span class="o">*</span><span class="n">rot_dist</span>
        <span class="c1"># Update the lams_var to randomly rotate those points </span>
        <span class="c1"># at which the model has zero gradient.</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">),</span> <span class="n">_rand_rotate</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">lams_var</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">))),</span> <span class="n">rot_dist</span><span class="p">))</span>
        <span class="c1"># Check to see whether the updated points are now </span>
        <span class="c1"># across the decision boundary.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="c1"># If there are still points that aren&#39;t past the decision boundary, </span>
        <span class="c1"># reset these points to their initial values so we can rotate them </span>
        <span class="c1"># randomly again in the next iteration.</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">init_lams</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">))))</span>
        <span class="c1"># Increment a counter of how many loops have been performed.</span>
        <span class="n">i</span> <span class="o">+=</span> <span class="mi">1</span>
    
<span class="nd">@tf</span><span class="o">.</span><span class="n">function</span>
<span class="k">def</span> <span class="nf">_find_accurate_points</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">lams_init</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">maxiter</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mi">10000</span><span class="p">),</span> <span class="n">init_rot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">1e-3</span><span class="p">)):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A function which, given tf.Variables of points in the quartic </span>
<span class="sd">    potential which the neural network classifies incorrectly as </span>
<span class="sd">    false positives (negatives), deforms them into nearby points across </span>
<span class="sd">    the neural network&#39;s decision boundary. Used to validate the neural </span>
<span class="sd">    network by determining how far away an incorrectly classified point </span>
<span class="sd">    is from the decision boundary. The strategy employed here is to </span>
<span class="sd">    follow the direction of steepest descent (ascent) of the neural </span>
<span class="sd">    networks&#39; prediction function with respect to the quartic coefficients </span>
<span class="sd">    to find points across the decision boundary, and then use bisection </span>
<span class="sd">    root-finding methods to deformed points to be as near to the decision </span>
<span class="sd">    boundary as possible.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable  which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network </span>
<span class="sd">        labels as either false positives or false negatives.</span>

<span class="sd">    lams_init : tf.Variable</span>
<span class="sd">        Another tf.Variable that initially carries identical values to </span>
<span class="sd">        lams_var. This will be updated as part of the bisection search </span>
<span class="sd">        for the decision boundary.</span>

<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the function will assume that lams_var are </span>
<span class="sd">        false positives, and so should be looking for points that </span>
<span class="sd">        the network classifies as negative. Otherwise, the function will </span>
<span class="sd">        assume that lams are false negatives, and so should be looking for </span>
<span class="sd">        points that the network classifies as positive.</span>

<span class="sd">    maxiter : int</span>
<span class="sd">        An integer which controls how long to continue iterating in order </span>
<span class="sd">        to find correctly labelled points in the vicinity of </span>
<span class="sd">        false positives or negatives. This value should be large, and the </span>
<span class="sd">        number of iterations should generally never approach it, but </span>
<span class="sd">        this ensures that the program will not run indefinitely.</span>

<span class="sd">    init_rot : float</span>
<span class="sd">        A parameter that governs how far to rotate points which have </span>
<span class="sd">        exactly zero gradient, as in _fix_zero_gradients, as well </span>
<span class="sd">        as for the search based on random rotations for points for which </span>
<span class="sd">        the gradient ascent/descent-based strategy fails.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># If any points have zero gradient, randomly rotate them by small </span>
    <span class="c1"># angles until they don&#39;t.</span>
    <span class="n">_fix_zero_gradients</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">lams_var</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">))</span>
    <span class="c1"># Consider points as &quot;converged&quot; if they are on the other </span>
    <span class="c1"># side of the decision boundary from the initial point.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">),</span> <span class="mf">0.5</span><span class="p">))</span>
    <span class="c1"># Perform the gradient descent/ascent search for points past </span>
    <span class="c1"># the decision boundary. The array converged keeps track of </span>
    <span class="c1"># whether this attempt was successful.</span>
    <span class="n">converged</span> <span class="o">=</span> <span class="n">_find_prediction_boundary</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">converged</span><span class="p">,</span> <span class="n">maxiter</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">)</span>

    <span class="c1"># If the gradient descent strategy was unsuccessful, randomly rotate </span>
    <span class="c1"># the unconverged points until they are past the decision boundary.</span>
    <span class="k">if</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">)):</span>
        <span class="n">_random_rot_search</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">init_rot</span><span class="p">)</span>
    <span class="c1"># Finally, refine the deformed points in lams_var to as close to </span>
    <span class="c1"># the decision boundary as possible using bisection. The parameter </span>
    <span class="c1"># init_rot, which by default will already be at least an order of </span>
    <span class="c1"># magnitude lower than the accuracy tolerance of the active learning </span>
    <span class="c1"># program, will also serve as the tolerance for the bisection root </span>
    <span class="c1"># finding algorithm.</span>
    <span class="n">_bisection_method</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">lams_init</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">init_rot</span><span class="o">/</span><span class="mf">10.</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_bisection_method</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">lams_var</span><span class="p">,</span> <span class="n">lams_init</span><span class="p">,</span> <span class="n">false_pos</span><span class="p">,</span> <span class="n">tol</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A method that, given sets of points lams_var and lams_init that </span>
<span class="sd">    are on either side of the decision boundary, updates all elements </span>
<span class="sd">    of lams_var to have its model prediction be within tol of 0.5, </span>
<span class="sd">    the decision boundary. It accomplishes this by repeatedly iterating </span>
<span class="sd">    bisections (projected onto the unit hypersphere) between lams_var </span>
<span class="sd">    and lams_init.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">    </span>
<span class="sd">    lams_var : tf.Variable</span>
<span class="sd">        A tf.Variable which represents sets of quartic potential </span>
<span class="sd">        coefficients in the vicinity of points that the neural network </span>
<span class="sd">        labels as either false positives or false negatives.</span>

<span class="sd">    lams_init : tf.Variable</span>
<span class="sd">        A tf.Variable which represents sets of quartic potential </span>
<span class="sd">        coefficients that ARE false positives or false negatives.</span>

<span class="sd">    false_pos : bool</span>
<span class="sd">        If True, the function will assume that lams_init are </span>
<span class="sd">        false positives, and so lams_var should be points </span>
<span class="sd">        which are classified as negative. Otherwise, the function </span>
<span class="sd">        will assume that lams_init are false negatives, and so </span>
<span class="sd">        lams_var should be points which are classified as positive.</span>

<span class="sd">    tol : float</span>
<span class="sd">        The level of closeness to the decision boundary that lams_var </span>
<span class="sd">        should be deformed to reach, without crossing.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Assess which points are not yet converged to values within </span>
    <span class="c1"># tol from the decision boundary, but across it.</span>
    <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tol</span><span class="p">)</span>
    <span class="c1"># As long as some lams_var elements are more than tol away </span>
    <span class="c1"># from the decision boundary, perform bisection root finding iterations.</span>
    <span class="k">while</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_any</span><span class="p">(</span><span class="o">~</span><span class="n">converged</span><span class="p">):</span>
        <span class="c1"># Locate the midpoints between each lams_var and lams_init, </span>
        <span class="c1"># and project it onto the unit hypersphere.</span>
        <span class="n">bisection</span> <span class="o">=</span> <span class="n">lams_var</span> <span class="o">+</span> <span class="p">((</span><span class="n">lams_init</span> <span class="o">-</span> <span class="n">lams_var</span><span class="p">)</span><span class="o">/</span><span class="mf">2.</span><span class="p">)</span>
        <span class="n">bisection</span> <span class="o">=</span> <span class="n">bisection</span> <span class="o">/</span> <span class="n">tf</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="n">bisection</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span> <span class="o">=</span> <span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Update each element of lams_var and lams_init to the corresponding </span>
        <span class="c1"># value of the midpoint, depending on which side of the decision boundary </span>
        <span class="c1"># the midpoint is on.</span>
        <span class="k">if</span><span class="p">(</span><span class="n">false_pos</span><span class="p">):</span>
            <span class="n">init_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">bisection</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="o">~</span><span class="n">converged</span><span class="p">))</span>
            <span class="n">var_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">bisection</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="o">~</span><span class="n">converged</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">init_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">bisection</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="o">~</span><span class="n">converged</span><span class="p">))</span>
            <span class="n">var_update</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">bisection</span><span class="p">)),</span> <span class="mf">0.5</span><span class="p">),</span> <span class="o">~</span><span class="n">converged</span><span class="p">))</span>
        <span class="n">lams_init</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">init_update</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">bisection</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">init_update</span><span class="p">)))</span>
        <span class="n">lams_var</span><span class="o">.</span><span class="n">scatter_nd_update</span><span class="p">(</span><span class="n">var_update</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">bisection</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">var_update</span><span class="p">)))</span>
        <span class="c1"># Update converged.</span>
        <span class="n">converged</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">lams_var</span><span class="p">))</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">),</span> <span class="n">tol</span><span class="p">)</span>


<div class="viewcode-block" id="get_false_pos_and_neg_tf">
<a class="viewcode-back" href="../../bfbrain.html#bfbrain.False_Proximity_Test.get_false_pos_and_neg_tf">[docs]</a>
<span class="k">def</span> <span class="nf">get_false_pos_and_neg_tf</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">ds</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;A function which extracts all sets of quartic coefficients in a </span>
<span class="sd">    Tensorflow dataset that the neural network classifies incorrectly, </span>
<span class="sd">    either false positives (points it incorrectly classifies as </span>
<span class="sd">    bounded-from-below) or false negatives (points it incorrectly </span>
<span class="sd">    classifies as NOT bounded-from-below).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    model : tf.keras.Model</span>
<span class="sd">    </span>
<span class="sd">    ds: tf.data.Dataset</span>
<span class="sd">        A Tensorflow dataset representing labelled sets of quartic </span>
<span class="sd">        potential coefficients.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    tuple of tf.Tensors</span>
<span class="sd">        Two 2-D tensors representing the sets of false positive and false </span>
<span class="sd">        negative quartic coefficients, respectively.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">false_pos</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">false_neg</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">ds</span><span class="p">:</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">training</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>
        <span class="n">false_pos</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)),</span> <span class="o">~</span><span class="n">y</span><span class="p">)))))</span>
        <span class="n">false_neg</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">_tf_flatten</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">logical_and</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">less_equal</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">constant</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)),</span> <span class="n">y</span><span class="p">)))))</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">false_pos</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">),</span> <span class="n">tf</span><span class="o">.</span><span class="n">concat</span><span class="p">(</span><span class="n">false_neg</span><span class="p">,</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span></div>

</pre></div>

          </div>
          
        </div>
      </div>
      <div class="sphinxsidebar" role="navigation" aria-label="main navigation">
        <div class="sphinxsidebarwrapper">
<h1 class="logo"><a href="../../index.html">bfbrain</a></h1>








<h3>Navigation</h3>
<p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../usage.html">Usage</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorial.html">Tutorial and User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">BFBrain</a></li>
</ul>

<div class="relations">
<h3>Related Topics</h3>
<ul>
  <li><a href="../../index.html">Documentation overview</a><ul>
  <li><a href="../index.html">Module code</a><ul>
  </ul></li>
  </ul></li>
</ul>
</div>
<div id="searchbox" style="display: none" role="search">
  <h3 id="searchlabel">Quick search</h3>
    <div class="searchformwrapper">
    <form class="search" action="../../search.html" method="get">
      <input type="text" name="q" aria-labelledby="searchlabel" autocomplete="off" autocorrect="off" autocapitalize="off" spellcheck="false"/>
      <input type="submit" value="Go" />
    </form>
    </div>
</div>
<script>document.getElementById('searchbox').style.display = "block"</script>








        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer">
      &copy;2023, George Wojcik.
      
      |
      Powered by <a href="http://sphinx-doc.org/">Sphinx 7.2.6</a>
      &amp; <a href="https://github.com/bitprophet/alabaster">Alabaster 0.7.13</a>
      
    </div>

    

    
  </body>
</html>