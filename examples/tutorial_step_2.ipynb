{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook contains code for executing the tasks described (and depicted) in\n",
    "# Tutorial Step 2: Initializing the Classifier\n",
    "\n",
    "# First, replicate the steps of Tutorial Step 1:\n",
    "import sympy as sym\n",
    "from sympy import I\n",
    "from sympy.physics.quantum.dagger import Dagger\n",
    "\n",
    "from bfbrain import DataManager\n",
    "\n",
    "   # Write a SymPy function representing the scalar potential.\n",
    "def V_2HDM(phi, lam):\n",
    "    Phi1 = sym.Matrix([0, phi[0]])\n",
    "    Phi2 = sym.Matrix([phi[1] + I*phi[3], phi[2] + I*phi[4]])\n",
    "    phi1sq = Dagger(Phi1).dot(Phi1)\n",
    "    phi2sq = sym.simplify(Dagger(Phi2).dot(Phi2))\n",
    "    phi12 = sym.simplify(Dagger(Phi1).dot(Phi2))\n",
    "    phi21 = sym.simplify(Dagger(Phi2).dot(Phi1))\n",
    "\n",
    "    QVec = (sym.Matrix([(phi1sq**2)/2, (phi2sq**2)/2,\n",
    "                 phi1sq*phi2sq, phi12*phi21, \n",
    "                 (phi12**2 + phi21**2)/2,\n",
    "                 I*(phi12**2 - phi21**2)/2,\n",
    "                 phi1sq*(phi12 + phi21),\n",
    "                 I*phi1sq*(phi12 - phi21),\n",
    "                 phi2sq*(phi12 + phi21),\n",
    "                 I*phi2sq*(phi12-phi21)])).applyfunc(sym.simplify)\n",
    "    return QVec.dot(lam)\n",
    "\n",
    "# Initialize a DataManager object which will handle \n",
    "# data generation and oracle labelling.\n",
    "dm = DataManager.from_func(V_2HDM, 5, 10, niter = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating training data...\n",
      "recompiling vectorized_minTest...\n",
      "done!\n",
      "creating validation data...\n",
      "recompiling vectorized_minTest...\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Now initialize the BFBLearner object with 5 hidden layers, 128 neurons in each hidden layer,\n",
    "# 1000 initial training points, and monitoring two performance metrics, the\n",
    "# F score on a labelled validation set and the estimated change in F score between active learning\n",
    "# iterations on a larger but unlabelled set.\n",
    "from bfbrain import BFBLearner, ValidationFScore, UnlabelledDeltaF\n",
    "\n",
    "# Running this line should take a few minutes, due to the need to label the validation set.\n",
    "AL = BFBLearner.init_for_first_run(dm, 5, 128, [ValidationFScore(), UnlabelledDeltaF(dm.create_random_lambdas(1000000, validation = True))], 1000)\n",
    "\n",
    "# For later use, save AL as a saved BFBLearner. A version of this saved object is included in the examples folder already.\n",
    "AL.save_AL_state('saved_AL_untrained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate loading and adjusting hyperparameters here.\n",
    "from bfbrain import MCModelEvaluation\n",
    "\n",
    "# Load the BFBLearner we just saved. It should be a copy of AL.\n",
    "loaded_AL = BFBLearner.from_file('saved_AL_untrained')\n",
    "\n",
    "# Redefine the model to feature 3 layers of 256 neurons instead of 5 layers of 128 neurons.\n",
    "loaded_AL.redefine_model(3, 256)\n",
    "\n",
    "# Adjust the prior length scale l (weights have a Bayesian prior of N(0, 1/l**2))\n",
    "loaded_AL.set_l_constant(0.01)\n",
    "\n",
    "# Add a new performance metric.\n",
    "loaded_AL.add_metrics(MCModelEvaluation())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Usage: Custom Performance Metrics\n",
    "\n",
    "# This is an example of a custom performance metric, which may be included in the list of\n",
    "# performance metrics when initializing a BFBLearner. For more information, see\n",
    "# the relevant section of the tutorial.\n",
    "\n",
    "from bfbrain import TrainMetric\n",
    "import numpy as np\n",
    "\n",
    "class TrainPosFraction(TrainMetric):\n",
    "    \"\"\"\n",
    "    Implement a new metric which records the fraction of\n",
    "    each newly-added set of training points that the\n",
    "    oracle labels as positive.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, name = 'pos_fraction'):\n",
    "        super().__init__(name = name)\n",
    "\n",
    "    def performance_check(self, model, lams, labels):\n",
    "        \"\"\"The class overwrites the superclass's abstract \n",
    "        performance_check method with a concrete\n",
    "        computation. This is the value that is recorded\n",
    "        in the performance metric's status_history object.\n",
    "        Notice that although not all arguments are used in the\n",
    "        computation of this result, the arguments of\n",
    "        performance_check are set by the parent class.\n",
    "        \"\"\"\n",
    "        return np.count_nonzero(labels) / len(labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
